# Context-Guided Dynamic Retrieval for Improving Generation Quality in RAG Models

**Authors**: Jacky He, Guiran Liu, Binrong Zhu, Hanlu Zhang, Hongye Zheng, Xiaokai Wang

**Published**: 2025-04-28 02:50:45

**PDF URL**: [http://arxiv.org/pdf/2504.19436v1](http://arxiv.org/pdf/2504.19436v1)

## Abstract
This paper focuses on the dynamic optimization of the Retrieval-Augmented
Generation (RAG) architecture. It proposes a state-aware dynamic knowledge
retrieval mechanism to enhance semantic understanding and knowledge scheduling
efficiency in large language models for open-domain question answering and
complex generation tasks. The method introduces a multi-level perceptive
retrieval vector construction strategy and a differentiable document matching
path. These components enable end-to-end joint training and collaborative
optimization of the retrieval and generation modules. This effectively
addresses the limitations of static RAG structures in context adaptation and
knowledge access. Experiments are conducted on the Natural Questions dataset.
The proposed structure is thoroughly evaluated across different large models,
including GPT-4, GPT-4o, and DeepSeek. Comparative and ablation experiments
from multiple perspectives confirm the significant improvements in BLEU and
ROUGE-L scores. The approach also demonstrates stronger robustness and
generation consistency in tasks involving semantic ambiguity and multi-document
fusion. These results highlight its broad application potential and practical
value in building high-quality language generation systems.

## Full Text


<!-- PDF content starts -->

Context-GuidedDynamicRetrievalforImproving
GenerationQualityinRAGModels
JackyHe
CornellUniversity
NewYork,USA
BinrongZhu
SanFrancisco,USA
HanluZhang
StevensInstituteofTechnology
Hoboken,USA
HongyeZheng
TheChineseUniversityofHongKong
HongKong,China
XiaokaiWang*
SantaClaraUniversity
SantaClara,USA
Keywords-dynamicretrieval;generativemodel;RAGstructure;
knowledgeenhancement
I.INTRODUCTION
WiththewidespreadapplicationofLargeLanguageModels
(LLMs)innaturallanguageprocessing,theyhave
demonstratedoutstandingperformanceintaskssuchastext
generation,questionanswering,anddialogueunderstanding.
However,akeyissuewiththesemodelsliesintheirclosed
knowledge.Sincethemodelparametersarefixedaftertraining,
updatingknowledgerequiresretrainingorfine-tuning.This
becomesparticularlyinadequateinscenarioswhere
informationchangesrapidlyordomainknowledgeevolves
continuously[1].Toovercomethislimitation,researchers
proposedtheRetrieval-AugmentedGeneration(RAG)
framework.Thisframeworkintegratesadocumentretrieval
modulewithagenerationmodel,allowingthemodelto
dynamicallyaccessexternalknowledgebasesduring
generation.Thisintegrationsignificantlyimprovesfactualaccuracyandtimeliness,makingitacrucialdirectionfor
enhancinglanguagemodelcapabilities[2].
TraditionalRAGstructuresmainlyrelyonstaticretrieval
mechanisms.Afterreceivinganinputquery,theyretrieve
relevantdocumentsfromapre-builtvectorindexandfeedthem
intothegenerationmodelascontext.Althoughthisapproach
partiallyalleviatestheissueofoutdatedknowledge,itsfixed
retrievalstrategystrugglestomeetcomplexandevolving
semanticneeds.Thislimitationaffectsboththereasoning
capacityandexpressionprecisionofthegenerationmodel.In
particular,taskssuchascomplexquestionanswering,multi-
turndialogues,orcross-domaininformationintegrationoften
requirehigh-qualityanddynamicknowledgesupport,which
staticretrievalfailstoprovide.Therefore,buildingamore
flexible,efficient,andadaptiveretrievalmechanismhas
becomekeytofurtherdevelopingRAGstructures[3].
Theintroductionofdynamicknowledgeretrievalbrings
newopportunitiesforimprovingRAGstructures.Unlike
traditionalmethods,dynamicmechanismsemphasizeupdating
theretrievalstrategycontinuouslyduringgeneration[4-6].
Theyadjustretrievalgoalsandsemanticvectorspacesinreal
time,basedonthecurrentgenerationstate,contextual
information,andknowledgegaps.Thisapproachimprovesthe
accuracyofknowledgeutilizationandenhancesthemodel's
interactivityandsemanticunderstanding.Incutting-edge
applicationssuchasmultimodalgeneration[7],domain-
specificgeneration[8],recommendationsystems[9],andzero-
shotlearning[10],dynamicretrievalhasthepotentialtogreatly
expandtheapplicabilityandqualityoflanguagemodels[11].
Thus,exploringhowtoeffectivelyintegratedynamicretrieval
mechanismsintotheRAGframeworkisboththeoretically
meaningfulandpracticallyvaluable.
Atthesametime,currentmainstreamRAGsystemsstill
sufferfromadegreeofdisconnectionbetweenretrievaland
generation.Althoughtheretrievalmodulecanprovidehighly
relevantexternaldocuments,thegenerationmodulemayfailto
fullyleveragetheretrievedcontent.Thisresultsinredundancy,
ambiguity,orevendistortioninthegeneratedoutput.To
addressthisissue,anefficientmechanismforknowledge Abstract-This paper focuses on the dynamic optimization of the Retrieval-Augmented Generation (RAG) architecture. It proposes a state-aware dynamic knowledge retrieval mechanism to enhance semantic understanding and knowledge scheduling efficiency in large language models for open-domain question answering and complex generation tasks. The method introduces a multi-level perceptive retrieval vector construction strategy and a differentiable document matching path. These components enable end-to-end joint training and collaborative optimization of the retrieval and generation modules. This effectively addresses the limitations of static RAG structures in context adaptation and knowledge access. Experiments are conducted on the Natural Questions dataset. The proposed structure is thoroughly evaluated across different large models, including GPT-4, GPT- 4o, and DeepSeek. Comparative and ablation experiments from multiple perspectives confirm the significant improvements in BLEU and ROUGE-L scores. The approach also demonstrates stronger robustness and generation consistency in tasks involving semantic ambiguity and multi-document fusion. These results highlight its broad application potential and practical value in building high-quality language generation systems.San Francisco State UniversitySan Francisco, USASan Francisco State University����������

selection,fusion,anddynamicfeedbackisurgentlyneeded[12].
Suchamechanismwouldenabletruecollaborative
optimizationintheretrieval-generationloop.Inaddition,
existingRAGmodelsarelimitedbystaticinputrepresentations.
Theylacktheabilitytoflexiblyperceiveuserintentandadapt
toshiftingknowledgedemands.Therefore,improvingRAG
withdynamicknowledgeretrievalisexpectedtoplayakey
roleinenhancingsemanticunderstanding,contextualreasoning,
andgenerationaccuracy[13].
Insummary,theRAGframeworkhaslaidthefoundation
forenhancingtheopenknowledgeacquisitioncapabilitiesof
languagemodels.Introducingdynamicknowledgeretrieval
furtherdrivestheframeworktowardgreaterefficiency,
intelligence,andpersonalization.AsAIsystemsmovetoward
large-scaleapplications,complexinteractions,andknowledge-
intensivetasks[14-16],dynamicallyimprovingtheRAG
architectureholdssignificanttheoreticalandpractical
importance.Thisstudyaimstoexploreandimplementa
dynamicRAGapproachtailoredforcomplexgenerationtasks.
Itfocusesonsolvingcoreissuesinknowledgeutilization
efficiency,contextualadaptability,andqualitycontrol,
providingboththeoreticalgroundingandtechnicalsupportfor
buildingmoreintelligentandgeneral-purposelanguage
generationsystems.
II.METHOD
Thisstudyintroducesadynamicknowledgeretrieval
mechanismbasedontheclassicRAGframeworktoachieve
real-timecallandadaptiveschedulingofexternalknowledge
duringthegenerationprocess.Themodelarchitectureisshown
inFigure1.
Figure1.Overallmodelarchitecture
Themodelarchitecturediagramillustratesanenhanced
Retrieval-AugmentedGeneration(RAG)structure
incorporatingadynamicknowledgeretrievalmechanism.
Inspiredbythehierarchicalsemanticencodingstrategies
proposedbyCaietal.[17],themodelemploysamulti-level
perceptiveretrievalvectorconstruction,enablingfine-grained
documentunderstandingandcontext-sensitiveretrieval.To
ensuretightcouplingbetweenretrievalandgeneration,we
adoptadifferentiabledocumentmatchingpaththatallowsgradientflowacrossmodules,drawingontechniquesvalidated
byYuetal.[18]injointretrievalandgenerationframeworks
forimprovedsemanticconsistency.Thisdifferentiability
supportsend-to-endjointtraining,encouragingretrieval
vectorstoevolvealongsidegenerationobjectives.Additionally,
thedynamicschedulingofretrievalstepsisinformedbythe
modelcompressionandtuningtechniquesoutlinedbyKai,Zhu,
andGong[19],whichhelpbalanceretrievalqualityandlatency
underlarge-scaledeploymentscenarios.Theseelements
collectivelyformthebasisofourimprovedRAGstructure.The
overallprocessstartswiththequeryvectorq,generatesastate-
awareretrievalvector'
tqthroughMLPanddynamicmodules,
andretrievesthemostrelevantdocumentvectorsetfromthe
externaldatabase.Subsequently,theretrievalscoreiguides
thedocumentfusiontoformacontextembeddingic,whichis
jointlyinputintotheTransformerwiththeLLMgeneration
historytooutputtheprobabilitydistributionofthecurrent
generatedword.Thisstructureachievesdynamiccoupling
betweenretrievalandgenerationthroughthedifferentiable
retrievalpath,attentioncontrolmechanismandgenerator
collaborativeoptimization,effectivelyimprovingtheefficiency
ofknowledgeretrievalandgenerationquality.
WesettheinputasthequeryvectordRq.Thegoalis
todynamicallyselecttherelevantdocumentset DDq
fromtheknowledgebase },...,,{21 NdddD throughthe
retrievalmoduleandfuseitintothegenerationmodelfortext
generation.First,wedesignastate-awareretrievalcontroller
toadjusttheretrievalvector'
tqaccordingtothecurrent
contextstateth.Thevectorisobtainedbyjointlymodeling
theoriginalqueryvectorandthegeneratedcontext:
]);(['
t t hqMLP q
Amongthem,];[thq representsvectorconcatenation,
MLPisamulti-layerperceptronmodule,andtheoutputisan
enhancedsemanticvector,whichisusedtofurtherimprove
thedynamicperceptionabilityofknowledgefragments.
Intheretrievalstage,weuseadifferentiablesimilarity
estimationmethodfordocumentmatching[20],andcalculate
therelevancescorebetweenvector'
tqanddocument
representationidbyscaleddot-productattention:
N
j jtit
iddqddq
1''
)/ exp()/ exp(
Whereirepresentstheretrievalprobabilityofthei-th
document,d
iRdisthepre-encodeddocumentvector,and

thecontextdocumentembeddingiii t d c isobtained
byvectorweightingtoguidesubsequentgeneration.
Thegenerationmoduleadoptsaconditionallanguage
modelingstrategy,whichcombinesthecurrentlygenerated
hiddenstatethandtheretrievedknowledgecontexttcat
eachgenerationsteptojointlypredicttheprobability
distributionofthenextword.Thegeneratorisimplemented
throughtheTransformerstructure,andthecoreprediction
processisasfollows:
)),( ( softmax ),,|(tt o t t cyr Transforme W DqyyP   
Wheretyisthepreviouslygeneratedwordsequence
andoWistheoutputmappingmatrix.Byintroducingthe
dynamicretrievalrepresentationtc,themodelhastheability
todynamicallyadjusttheknowledgeinputaccordingtothe
generationhistory,avoidingthecontextdriftcausedbystatic
documentinput.
Inordertoachieveend-to-endoptimizationoftheretrieval
moduleandthegenerationmodule,wedesignedajoint
traininglossfunction,whichconsistsofagenerationloss
genLandaretrievalcontrastlossretL.Thegenerationloss
usesthestandardcrossentropyform,whiletheretrievalloss
usesacontrastivelearningframeworktomodelpositiveand
negativedocumentpairs.Thejointobjectivefunctionisas
follows:
ret gen total L LL   
Thehyperparametercontrolstheweightbalanceofthe
twolosses.Throughjointoptimization,themodelcannotonly
learnstrongertextgenerationcapabilities,butalsoimprove
theabilitytoselectknowledgeunderdifferentsemanticstates,
achievingefficientcollaborationbetweenretrievaland
generation.
III.EXPERIMENT
A.Datasets
ThisstudyselectsNaturalQuestions(NQ)astheprimary
experimentaldataset.ReleasedbyGoogle,NQisdesignedfor
open-domainquestionansweringtasks.Itcontainsalarge
numberofrealuserqueriesfromsearchengines,eachpaired
withcorrespondingWikipediadocumentsandbothshortand
longanswers.ThestructureofNQcloselyreflectsreal-world
scenariosofretrieval-augmentedgeneration.Iteffectivelytests
amodel'sabilityincomplexsemanticunderstandingand
knowledgeretrieval.
Inthiswork,wetreatthequestionsinNQasinputqueriesq,
andtheassociatedWikipediapassagesastheexternal
knowledgebaseD.Theprovidedgoldpassageisusedasthe
supervisionsignal.WeuseaDPR-basedretrievertoinitialize
thevectorindexfordocumentpre-encoding.Thisensures
semanticconsistencyindocumentrepresentations.Our
dynamicretrievalmechanismisthenappliedtoupdatevectors
andmodeltheirmatchingprocess.Tobettersupportlong-formgenerationandmulti-passagefusion,wesegmenttheoriginal
textsandunifytheencodingformat.
Thedatasetencompassesawiderangeofqueryintents,
extensivedocumentspans,andsubstantialnoise.These
characteristicsposesignificantchallengesinevaluating
retrieval-augmentedgenerationsystemsinrealisticscenarios.
Toensurereproducibilityandcomparabilityofresults,we
strictlyadheretotheofficialtrain,validation,andtestsplits
providedbyNQ.Additionally,thisverificationprocess
validatestheeffectivenessandgeneralizabilityofourproposed
dynamicRAGstructureinopen-domainQAtasks.
B.ExperimentalResults
Toassesstheperformanceofthedynamicretrieval-
augmentedgeneration(RAG)structureacrossvariouslarge
languagemodels(LLMs),weconductamodelcapability
comparisonexperiment.Wemaintainthesameretrieval
mechanismandinputparameterswhileintroducingseveral
prominentLLMsasthegenerationmodule.Theseinclude
GPT-3.5,GPT-4,Qwenmax,DeepSeek,andthemostrecent
GPT-4o.Bycomparingthegenerationquality,answer
accuracy,andknowledgeintegrationontheNaturalQuestions
dataset,weanalyzeeachmodel'sresponsecapabilityand
generationrobustnessduringdynamicknowledgeaccess.This
revealshowdifferentmodelsbehaveunderthesameretrieval-
enhancedconditions.Inparticular,GPT-4o,asanew-
generationmultimodalmodel,showsstrongperformancein
handlingcomplexqueriesandlong-contextstructures.It
provideshigheraccuracyandbetterconsistency.Thisoffers
solidsupportforapplyingdynamicRAGstructuresinreal-
worldscenarios,andtheactualresultsareshowninTable1.
Table1.Comparativetestresultsofdifferentlargemodels
Model BLEU ROUGE-LAverageresponse
time(ms)
GPT-3.5[21] 34.2 47.5 920
Qwenmax[22] 38.9 52.3 980
Deepseek[23] 39.1 53.5 890
GPT4[21] 40.2 54.3 1010
GPT4o[21] 41.7 55.1 990
Theexperimentalresultsshowthatalllargelanguage
modelsdemonstraterelativelystablegenerationperformance
underthedynamicRAGstructure.BothBLEUandROUGE-L
scorestendtoincreasewithmodelcapability.GPT-3.5,asan
earlierversion,showsweakerperformance,withaBLEUscore
of34.2andaROUGE-Lscoreof47.5,significantlylowerthan
thelatermodels.Incontrast,QwenmaxandDeepSeek,two
mid-sizedemergingmodels,performwellingenerationquality.
Notably,DeepSeekachievesaROUGE-Lscoreof53.5,
indicatingstrongabilitiesinsemanticpreservationand
contextualcontinuity.
GPT-4andGPT-4o,asmoreadvancedmodels,show
furtherimprovementsinoverallperformance.GPT-4oachieves
thebestresultsonbothBLEU(41.7)andROUGE-L(55.1),
highlightingitsstrengthincomplexqueryunderstandingand
languagegeneration.ItisworthnotingthatwhileGPT-4scores
slightlylowerthanGPT-4o,itsaverageresponsetimereaches

1010ms,thehighestamongallmodels.Thissuggestsalarger
inferencelatency,possiblyduetomodelcomplexityor
resourceschedulingbottlenecks.
Overall,GPT-4ostrikesagoodbalancebetweengeneration
qualityandresponseefficiency.Itproducesmoreaccurateand
consistentoutputs,whilealsooutperformingGPT-4and
Qwenmaxinaverageresponsetime.Thisindicatesthatunder
dynamicknowledgeretrieval,bothreasoningabilityandreal-
timeresponsivenessjointlyaffectthefinalgenerationquality.
Therefore,inpracticaldeployment,modelperformance,
resourceconsumption,andinteractionspeedshouldallbe
consideredtoselectthemostsuitablegenerationengineforthe
targetapplicationscenario.
Atthesametime,thispaperalsogivestheexperimental
resultsofanalyzingtheimpactofdifferentretrievalvector
constructionmethodsonthegenerationquality,andthe
experimentalresultsareshowninFigure2.
Figure2.Histogramoftheexperiment"Analysisoftheimpact
ofdifferentretrievalvectorconstructionmethodsongeneration
quality"
Theexperimentalresultsinthefigureshowaconsistent
improvementinmodelperformanceonBLEUandROUGE-L
scoresastheconstructionofretrievalvectorsbecomesmore
advanced.Thebasicstaticquerymethodachievesthelowest
scores,with34.5onBLEUand45.1onROUGE-L.This
indicatesclearlimitationsinsemanticexpressionand
contextualconsistency,makingitdifficulttomeettheneedsof
dynamicgeneration.
Whenhistoricalinformationandcontextualembeddingsare
incorporated,themodel’sabilitytounderstandthesemanticsof
thequeryisnoticeablyenhanced.Thisimprovementis
reflectedintheupwardtrendofBLEUandROUGE-Lscores.
Theresultsindicatethatrichersemanticrepresentations
providestrongersupportforgeneratingmorecoherentand
contextuallyappropriateoutputs.Specifically,theQuery+
ContextEmbeddingapproachdemonstratesadistinct
advantageinmaintainingsemanticcontinuityacrossthe
generatedcontent.ThisisparticularlyevidentintheROUGE-L
score,whichshowsaclearimprovementcomparedtoother
settings.Themethodproposedinthisstudy(Ours)buildsuponthese
insightsbyintroducinganattention-basedfusionmechanismto
constructretrievalvectors.Thisdesignallowsthemodelto
effectivelyintegratebothquerysemanticsandcontextual
signalswhenretrievingexternaldocuments.Asaresult,it
achievesthehighestperformanceacrossbothevaluation
metrics,withaBLEUscoreof41.0andaROUGE-Lscoreof
53.0.Theseresultsvalidatetheproposedmethod’sstrengthin
modelingcontextualrelevanceanddynamicallyscheduling
knowledgethroughoutthegenerationprocess.Byenabling
moreprecisecontroloverwhatinformationisretrievedand
howitisused,thisapproachsignificantlyenhancesthe
accuracy,fluency,andoverallqualityofthegeneratedtext.
Finally,thispaperpresentstheexperimentalresultsof
dynamicRAGrobustnessevaluationonadatasubsetbasedon
queryambiguity,andtheexperimentalresultsareshownin
Figure3.
Figure3.RobustnessEvaluationofDynamicRAGunder
DifferentQueryAmbiguityLevels
Theexperimentalresultsshowthatasqueryambiguity
increases,thedynamicRAGmodelexhibitsanoticeable
declineinbothgenerationqualityandrobustness.Inlow-
ambiguityscenarios,themodelcanfullyunderstandthequery
intent.BLEUandROUGE-Lscoresreach42.1and54.2,
respectively,withrobustnessat92.3%.Thisindicatesthatthe
generationsystemcanreliablyaccessexternalknowledgeand
produceaccurateoutputsunderclearqueryconditions.
Whenambiguityrisestoamoderatelevel,model
performancestartstodecline.BLEUdropsto39.3,ROUGE-L
fallsto50.8,androbustnessdecreasesto87.5%.Thissuggests
thatunderlessexplicitintentorsemanticambiguity,the
retrievalmodulestrugglestoselectpreciseknowledge
segments.Asaresult,thestabilityandcoherenceofthe
generatedtextarecompromised.
Inhigh-ambiguityscenarios,thescoresdeclinefurther.
BLEUdropsto35.4,androbustnessfallsto81.2%.These
resultsshowthatthecurrentdynamicretrievalmechanism
remainssensitivetosemanticuncertainty.Althoughitoffers
someadaptivecapacity,itstilllacksstrongcontextawareness
andeffectivedisambiguationstrategies.Enhancingthese

aspectsisessentialforimprovingrobustnessandgeneration
consistencywhendealingwithvagueorambiguousqueries.
IV.CONCLUSION
Thisstudyfocusesonthedynamicretrievalmechanism
withintheRetrieval-AugmentedGeneration(RAG)
architecture.Thegoalistoimprovetheefficiencyof
knowledgeutilizationandsemanticadaptabilityinlarge
languagemodelsduringgenerationtasks.Byintroducinga
state-awareretrievalvectorconstructionmethodanda
differentiabledocumentmatchingpathway,theretrievaland
generationprocessesarejointlyoptimized.Experiments
conductedontheNaturalQuestionsdatasetprovidea
comprehensiveevaluation,confirmingthesuperiorityofthe
proposeddynamicRAGstructureinhandlingcomplex
semanticqueries,multi-documentfusion,andgeneration
consistency.Inparticular,comparativeexperimentswith
variouslargelanguagemodelsdemonstratethatincorporatinga
dynamicretrievalstrategysignificantlyboostskeymetricssuch
asBLEUandROUGE-L,enhancingthemodel'srobustness
andoutputqualityinreal-worldscenarios.
Additionally,ablationstudiesontheretrievalvector
constructionandrobustnessassessmentsunderambiguous
queriesfurtherhighlightthegeneralityandadaptabilityofthe
proposedmethod.Undercomplexcontextsandvague
intentions,thedynamicRAGstructuremaintainshighresponse
accuracyandcontentcoherence.Thisindicatesstrong
capabilitiesinsemanticcomprehensionanddynamic
coordination.Inconclusion,thisworknotonlydeepensthe
theoreticalunderstandingofdynamicretrievalmechanisms
withintheRAGframeworkbutalsoprovidesasolidtechnical
foundationandexperimentalevidenceforbuildingmore
intelligentandreal-timegenerativesystems.
REFERENCES
[1]Z.Hei,etal.,“Dr-rag:Applyingdynamicdocumentrelevanceto
retrieval-augmentedgenerationforquestion-answering,”arXivpreprint
arXiv:2406.07348,2024.
[2]W.Su,etal.,“DRAGIN:DynamicRetrievalAugmentedGeneration
basedontheInformationNeedsofLargeLanguageModels,”arXiv
preprintarXiv:2403.10081,2024.
[3]Y.Wu,Y.FangandL.Liao,“RetrievalAugmentedGenerationfor
DynamicGraphModeling,”arXivpreprintarXiv:2408.14523,2024.
[4]W.Huang,J.Zhan,Y.Sun,X.Han,T.AnandN.Jiang,“Context-
AwareAdaptiveSamplingforIntelligentDataAcquisitionSystems
UsingDQN,”arXivpreprintarXiv:2504.09344,2025.
[5]F.Guo,X.Wu,L.Zhang,H.LiuandA.Kai,“ASelf-SupervisedVision
TransformerApproachforDermatologicalImageAnalysis,”Journalof
ComputerScienceandSoftwareApplications,vol.5,no.4,2025.
[6]Y.Deng,“AReinforcementLearningApproachtoTrafficSchedulingin
ComplexDataCenterTopologies,”JournalofComputerTechnology
andSoftware,vol.4,no.3,2025.
[7]J.Zhan,“Single-DeviceHumanActivityRecognitionBasedon
SpatiotemporalFeatureLearningNetworks,”Transactionson
ComputationalandScientificMethods,vol.5,no.3,2025.[8]S.Wang,Z.LiuandB.Peng,"ASelf-trainingFrameworkfor
AutomatedMedicalReportGeneration,"Proceedingsofthe2023
ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pp.
16443-16449,December2023.
[9]L.Zhu,“DeepLearningforCross-DomainRecommendationwith
Spatial-ChannelAttention,”JournalofComputerScienceandSoftware
Applications,vol.5,no.4,2025.
[10]Z.Liu,M.Wu,B.Peng,Y.Liu,Q.PengandC.Zou,"Calibration
LearningforFew-shotNovelProductDescription,"Proceedingsofthe
46thInternationalACMSIGIRConferenceonResearchand
DevelopmentinInformationRetrieval,pp.1864-1868,July2023.
[11]J.Kim,D.KoandG.Kim,“DynamicER:ResolvingEmergingMentions
toDynamicEntitiesforRAG,”arXivpreprintarXiv:2410.11494,2024.
[12]X.Yan,J.Du,L.Wang,Y.Liang,J.HuandB.Wang,"TheSynergistic
RoleofDeepLearningandNeuralArchitectureSearchinAdvancing
ArtificialIntelligence",Proceedingsofthe2024International
ConferenceonElectronicsandDevices,ComputationalScience
(ICEDCS),pp.452-456,Sep.2024.
[13]Y.Shi,etal.,“Enhancingretrievalandmanagingretrieval:Afour-
modulesynergyforimprovedqualityandefficiencyinragsystems,”
arXivpreprintarXiv:2407.10670,2024.
[14]X.Li,Y.Peng,X.Sun,Y.Duan,Z.FangandT.Tang,“Unsupervised
DetectionofFraudulentTransactionsinE-commerceUsingContrastive
Learning,”arXivpreprintarXiv:2503.18841,2025.
[15]Y.Zhang,“SocialNetworkUserProfilingforAnomalyDetectionBased
onGraphNeuralNetworks,”arXivpreprintarXiv:2503.19380,2025.
[16]A.Liang,“AGraphAttention-BasedRecommendationFrameworkfor
SparseUser-ItemInteractions,”JournalofComputerScienceand
SoftwareApplications,vol.5,no.4,2025.
[17]G.Cai,J.Gong,J.Du,H.LiuandA.Kai,“InvestigatingHierarchical
TermRelationshipsinLargeLanguageModels,”JournalofComputer
ScienceandSoftwareApplications,vol.5,no.4,2025.
[18]Z.Yu,S.Wang,N.Jiang,W.Huang,X.HanandJ.Du,“Improving
HarmfulTextDetectionwithJointRetrievalandExternalKnowledge,”
arXivpreprintarXiv:2504.02310,2025.
[19]A.Kai,L.ZhuandJ.Gong,“EfficientCompressionofLargeLanguage
ModelswithDistillationandFine-Tuning,”JournalofComputer
ScienceandSoftwareApplications,vol.3,no.4,pp.30–38,2023.
[20]J.Wei,Y.Liu,X.Huang,X.Zhang,W.LiuandX.Yan,"Self-
SupervisedGraphNeuralNetworksforEnhancedFeatureExtractionin
HeterogeneousInformationNetworks",20245thInternational
ConferenceonMachineLearningandComputerApplication(ICMLCA),
pp.272-276,2024.
[21]P.A.Massey,C.MontgomeryandA.S.Zhang,“Comparisonof
ChatGPT–3.5,ChatGPT-4,andorthopaedicresidentperformanceon
orthopaedicassessmentexaminations,”JAAOS-Journalofthe
AmericanAcademyofOrthopaedicSurgeons,vol.31,no.23,pp.1173–
1179,2023.
[22]L.Zhang,etal.,“Qwen-IG:AQwen-basedInstructionGeneration
ModelforLLMFine-tuning,”Proceedingsofthe202413th
InternationalConferenceonComputingandPatternRecognition,2024.
[23]A.Liu,etal.,“Deepseek-v3technicalreport,”arXivpreprint
arXiv:2412.19437,2024.