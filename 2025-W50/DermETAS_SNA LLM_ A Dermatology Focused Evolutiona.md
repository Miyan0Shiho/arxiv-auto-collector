# DermETAS-SNA LLM: A Dermatology Focused Evolutionary Transformer Architecture Search with StackNet Augmented LLM Assistant

**Authors**: Nitya Phani Santosh Oruganty, Keerthi Vemula Murali, Chun-Kit Ngan, Paulo Bandeira Pinho

**Published**: 2025-12-09 00:37:12

**PDF URL**: [https://arxiv.org/pdf/2512.08998v1](https://arxiv.org/pdf/2512.08998v1)

## Abstract
Our work introduces the DermETAS-SNA LLM Assistant that integrates Dermatology-focused Evolutionary Transformer Architecture Search with StackNet Augmented LLM. The assistant dynamically learns skin-disease classifiers and provides medically informed descriptions to facilitate clinician-patient interpretation. Contributions include: (1) Developed an ETAS framework on the SKINCON dataset to optimize a Vision Transformer (ViT) tailored for dermatological feature representation and then fine-tuned binary classifiers for each of the 23 skin disease categories in the DermNet dataset to enhance classification performance; (2) Designed a StackNet architecture that integrates multiple fine-tuned binary ViT classifiers to enhance predictive robustness and mitigate class imbalance issues; (3) Implemented a RAG pipeline, termed Diagnostic Explanation and Retrieval Model for Dermatology, which harnesses the capabilities of the Google Gemini 2.5 Pro LLM architecture to generate personalized, contextually informed diagnostic descriptions and explanations for patients, leveraging a repository of verified dermatological materials; (4) Performed extensive experimental evaluations on 23 skin disease categories to demonstrate performance increase, achieving an overall F1-score of 56.30% that surpasses SkinGPT-4 (48.51%) by a considerable margin, representing a performance increase of 16.06%; (5) Conducted a domain-expert evaluation, with eight licensed medical doctors, of the clinical responses generated by our AI assistant for seven dermatological conditions. Our results show a 92% agreement rate with the assessments provided by our AI assistant (6) Created a proof-of-concept prototype that fully integrates our DermETAS-SNA LLM into our AI assistant to demonstrate its practical feasibility for real-world clinical and educational applications.

## Full Text


<!-- PDF content starts -->

DermETAS-SNA LLM: A Dermatology Focused
Evolutionary Transformer Architecture Search
with StackNet Augmented LLM Assistant
Nitya Phani Santosh Oruganty1*[0009−0009−0491−8162], Keerthi Vemula
Murali2*[0009−0009−3868−4376], Chun-Kit Ngan1[0000−0003−2151−0459], and Paulo
Bandeira Pinho3
1Data Science Program, Worcester Polytechnic Institute, Massachusetts, USA
2Computer Science Department, Worcester Polytechnic Institute, Massachusetts, USA
3PASE Advisory Group, New Jersey, USA
Abstract. This work introduces the DermETAS-SNA LLM Assistant
that integrates Dermatology-focused Evolutionary Transformer Archi-
tecture Search (ETAS) with StackNet Augmented LLM. The assistant
dynamically learns skin-disease classifiers and provides medically informed
descriptions to facilitate clinician-patient interpretation. Contributions
include: (1) Developed an ETAS framework on the SKINCON dataset to
optimize a Vision Transformer (ViT) tailored for dermatological feature
representation and then fine-tuned binary classifiers for each of the 23
skin disease categories in the DermNet dataset to enhance classification
performance; (2) Designed a StackNet architecture that integrates multi-
ple fine-tuned binary ViT classifiers to enhance predictive robustness and
mitigate class imbalance issues; (3) Implemented a RAG pipeline, termed
Diagnostic Explanation and Retrieval Model for Dermatology, which
harnesses the capabilities of the Google Gemini 2.5 Pro LLM architecture
to generate personalized, contextually informed diagnostic descriptions
and explanations for patients, leveraging a repository of verified dermato-
logical materials; (4) Performed extensive experimental evaluations on 23
skin disease categories to demonstrate substantial performance increase,
achieving an overall F1-score of 56.30% that notably surpasses SkinGPT-4
(48.51%) by a considerable margin, representing a performance increase
of 16.06%; (5) Conducted a domain-expert evaluation, with eight licensed
medical doctors, of the clinical responses generated by our AI assistant for
seven dermatological conditions. Our results show a 92% agreement rate
with the assessments provided by our AI assistant, demonstrating superior
performance compared to SkinGPT-4 with a substantial margin (48.20%);
and (6) Created a proof-of-concept prototype that fully integrates our
DermETAS-SNA LLM into our AI assistant to demonstrate its practical
feasibility for real-world clinical and educational applications.
Keywords:Skin Disease Detection·Evolutionary Transformer Architec-
ture Design·Dermoscopic Image·Image Classification·Large Language
Models·StackNet·Retrieval-Augmented Generation
*These authors contributed equally to this workarXiv:2512.08998v1  [eess.IV]  9 Dec 2025

2 Santosh, Keerthi, et al.
1 Introduction
The skin, being the largest organ of the body, is crucial for regulating internal
temperature, retaining body fluids, and acting as the first line of defense against
harmfulpathogens.Despiteitssignificance,theincidenceofskinandsubcutaneous
diseases, including warts, actinic keratosis, eczema, seborrheic keratoses, psoriasis,
onychomycosis(nailfungus),alopecia(hairloss)andmore,isincreasingworldwide
and has been officially recognized by the World Health Assembly [1] as a major
public health issue. Atopic dermatitis (AD) is among the top 15 nonfatal global
diseases, with a higher prevalence in urban and industrialized areas [2]. Warts,
caused by HPV, affect 7–12% worldwide, especially school-aged children [3].
Actinic keratosis (AK), a precancerous lesion, impacts 14% people worldwide,
yet 85% are unaware, its treatment market is projected to rise from USD 7.95B
(2024) to USD 13.0B by 2032 [4]. Seborrheic keratosis (SK), the most common
benign skin tumor, affects almost all individuals over 60 years of age and 12% of
those aged 15-30 in the United States [5]. Nail disorders such as onychomycosis
represent 50% of nail diseases, increasing with age [6]. Skin cancer is a significant
concern with more than 5.4M US non-melanoma cases yearly, and melanoma is
projected to cause 8,430 deaths by 2025 [7].
As per the 2021 Global Burden of Disease Study [1], there were 4.69 billion new
cases of skin diseases globally, ranking them among the top ten causes of disability.
This growing burden is exacerbated by a widespread lack of understanding of
skin diseases in various communities, which often leads to delayed diagnoses and
insufficient treatment. The World Health Organization (WHO) [1] highlights
that many communities face a shortage of trained healthcare professionals and
specialists, which further hampers the effective management of skin conditions.
For instance, as of 2023, the United States had 12,120 active dermatologists,
(3.66 per 100,000 people), an increase from 10,845 in 2016. Nevertheless, the issue
of maldistribution has intensified, with 48.4% of dermatologists concentrated in
the 100 most densely populated ZIP codes, while only 0.9% cater to the 100 least
densely populated areas. Despite the growth of the workforce, the geographic
disparity is increasing, indicating an urgent need for policies aimed at enhancing
access to dermatological services in underserved communities [8].
To address the needs, the recent advances in Artificial Intelligence (AI),
including computer vision, large language models (LLMs), and multimodal
models, have resulted in a swift expansion of medical applications, particularly
in dermatology. SkinGPT-4 [9] is an interactive dermatology diagnostic system
based on multimodal LLMs that can deliver a practical solution to the global
shortage of dermatologists and accessibility challenges by enabling diagnosis
using a Vision Transformer (ViT) [10] aligned with Meta’s LLaMA-2-13B Chat
model [11]. However, SkinGPT-4 exhibits certain constraints and limitations.
First, it uses a single model for all skin disease categories, which may reduce
diagnostic precision for rare or underrepresented conditions. Second, it lacks direct
integration with authoritative dermatological knowledge repositories, like medical
documents and clinical guidelines, limiting interpretability and traceability of its

DermETAS-SNA LLM Assistant 3
responses. As with other LLM-based systems, it risks generating hallucinated,
overconfident, and clinically unsafe outputs without expert validation.
To overcome the existing limitations, we introduce our DermETAS-SNA
LLM assistant, a unified system integrating Dermatology-focused Evolutionary
Transformer Architecture Search with StackNet-Augmented LLM. Specifically,
this work presents six technical contributions:
1.We developed anEvolutionary Transformer Architecture Search(ETAS)
framework on theSKINCONdataset [12] to optimize a ViT architecture [10]
tailored for dermatological feature representation. The optimized architecture
is subsequently fine-tuned as a set of class-specific binary classifiers for each
of the 23 disease categories in theDermNetdataset [13], thereby enhancing
performance for rare and underrepresented classes.
2.WedesignedStackNet,amodularstackingensembleframeworkthatintegrates
multiple fine-tuned, class-specific binary ViT classifiers to enhance predictive
robustness and mitigate class imbalance issues.
3.We implemented aRetrieval-Augmented Generation(RAG) [14] pipeline,
termed DERM-RAG (Diagnostic Explanation and Retrieval Model for Der-
matology), which harnesses the capabilities of theGoogle Gemini 2.5 Pro
Preview-05-06[15] LLM architecture. This pipeline generates personalized,
contextually informed diagnostic descriptions and explanations for patients,
leveraging a repository of verified dermatological materials.
4.We performed extensive experimental evaluations on 23 disease categories
within the DermNet dataset. Our AI assistant demonstrates strong per-
formance, achieving an overall F1-score of 56.30% that notably surpasses
SkinGPT-4 (i.e., 48.51%) by a substantial performance increase of 16.06%.
5.We conducted a domain-expert evaluation of the clinical responses generated
by our AI assistant for seven dermatological conditions including Warts,
Actinic Keratosis, Eczema, Seborrheic Keratoses, Psoriasis, Nail Fungus, and
Hair Loss. The eight licensed medical professionals evaluated the quality
and validity of the responses using a six-question survey instrument. Our
results show a 92% agreement rate with the assessments provided by our AI
assistant, demonstrating superior performance compared to SkinGPT-4 with
a substantial margin (i.e., 48.20%). This outcome highlights the effectiveness
of our AI assistant in providing accurate dermatological decision support.
6.We created a proof-of-concept prototype that fully integrates our DermETAS-
SNA LLM into our unified multimodal AI assistant to demonstrate its
practical feasibility for real-world clinical and educational applications.
The remainder of this paper is structured as follows. Section 2 provides a
detailed overview ofSkinGPT-4. Section 3 describes the skin disease datasets,
medical documents, and supporting resources used in our work and experiments.
Section 4 introduces our proposed AI assistant. Section 5 presents the ETAS
approach. Section 6 details theStackNetarchitecture. Section 7 explains the
DERM-RAG pipeline. Section 8 discusses our experimental evaluations and
domain-expert assessments. Section 9 describes the proof-of-concept prototype

4 Santosh, Keerthi, et al.
implementation. Section 10 concludes the paper and outlines directions for
potential future work to further enhance the proposed system.
2 SkinGPT-4 System
Fig.1: SkinGPT-4 System Design and Interactive Diagnosis Example [9]
As shown in Fig. 1, SkinGPT-4 [9] is a multimodal LLM framework for derma-
tological diagnosis, aligning a pre-trained ViT with Meta’s LLaMA-2-13B Chat
model. It is trained in two steps: STEP 1 teaches the model to recognize and
describe clinical features using 52,929 image-concept pairs, and STEP 2 focuses
on disease-specific classification with 49,043 image-description pairs. Users can
upload skin images, which are analyzed for visual features and classified into
15 disease categories derived from the original 23 DermNet classes, grouped by
board-certified dermatologists. The model then provides interactive diagnostic
explanations and treatment recommendations, supporting real-time self-diagnosis
and doctor-patient communication.
SkinGPT-4 addresses major bottlenecks in dermatology, including long wait
times, specialist shortages, and the need for explainable AI. Evaluated on 150
real-world cases reviewed by board-certified dermatologists, it achieved over
80% diagnostic agreement and was considered informative, useful, and privacy-
conscious. It supports local deployment, making it accessible for underserved
regions. While not a replacement for physicians, SkinGPT-4 serves as a valuable
triage tool and assistant, capable of 24/7 personalized diagnostics.
SkinGPT-4 uses a single model to classify all 23 skin disease categories,
simplifying deployment but potentially compromising precision, particularly for
rare or underrepresented conditions. Diseases such as poison ivy, urticaria, atopic
dermatitis, scabies, bacterial infections such as impetigo and cellulitis, and viral
or STD-related conditions such as Herpes and HPV may suffer from a low

DermETAS-SNA LLM Assistant 5
representation in training data, leading to generalization errors, misclassification,
and lower confidence in predictions. In addition, the model does not integrate
external trusted dermatology literature or clinical guidelines, which limits the
traceability and clinical reliability of its results. This absence of authoritative
grounding increases the risk of hallucinated or overconfident diagnostic responses,
which poses significant risks when the system is used without expert oversight.
3 Skin Disease Datasets and Medical Corpus
3.1 SKINCON Dataset
TheSKINCON[12]datasetisadenselyannotateddermatologicaldatasetdesigned
to support fine-grained model interpretability and debugging. It consists of
3,230 images from the Fitzpatrick17k dataset and 656 images from the Diverse
Dermatology Images (DDI) dataset, making a total of 3,886 images. Each image
is labeled with 48 clinical concepts, including Vesicle, Papule, Macule, Plaque,
Abscess, and more features related to pigmentation, texture, shape and lesion
morphology. These annotations were developed by board-certified dermatologists
using a standardized lexicon derived fromDermatology by Bolognia et al. (2017).
This dataset enables training concept bottleneck models, probing representations,
and generating concept-based explanations.
3.2 DermNet Dataset
The DermNet dataset [13] is a comprehensive collection of clinical dermatology
images designed for multi-class classification tasks. It consists of 19,500 images
meticulously categorized into 23 distinct skin disease categories, including Acne,
Actinic Keratosis, Atopic Dermatitis, Cellulitis, Exanthems & Drug Eruptions,
Hair Loss, Herpes, Pigmentation Disorders, Lupus, Melanoma, Nail Fungus,
Eczema, Bullous Disease, Poison Ivy, Psoriasis, Scabies, Seborrheic Keratoses,
Systemic Disease, Tinea Ringworm, Urticaria Hives, Vascular Tumors, Vasculitis,
and Warts. In this study, the DermNet dataset was used to train the StackNet
classifier and to evaluate downstream diagnostic accuracy following feature
transfer from SKINCON-trained encoders.
3.3 Medical Corpus
To supplement visual learning with textual expertise, we constructed a domain-
specific corpus by extracting relevant information from five authoritative derma-
tology sources: (1) Habif’s Clinical Dermatology: A Color Guide to Diagnosis and
Therapy [16],(2) Rook’s Textbook of Dermatology [17],(3) Textbook of Primary
Care Dermatology [18],(4) Fitzpatrick Dermatology in General Medicine [19], and
(5) The Electronic Textbook of Dermatology [20].This curated corpus served as
the knowledge base in our DERM-RAG module to generate clinically grounded
explanations for dermatology-related queries.

6 Santosh, Keerthi, et al.
4 DermETAS-SNA LLM Assistant
Uploads
Response
USER
Skin Disease
ImageInteractive Diagnosis
Fig.2: Overview of the DermETAS-SNA LLM Assistant Interaction Flow
Fig.2 shows how users interact with our application. We present a modular
and scalable framework designed to address key limitations of current derma-
tological AI systems, including architectural inefficiency, poor performance in
underrepresented classes, limited explainability, and the absence of grounded
diagnostic reasoning. Our approach comprises two tightly integrated phases: (1)
Optimized vision-based diagnosis using customized Transformer architectures
and (2) Generation of contextual explanations using DERM-RAG.
As shown in Fig.3, in the first phase, we apply ETAS on the SKINCON dataset
to obtain an optimal ViT architecture for multi-label classification, capable of
capturing fine-grained dermatological features across diverse visual patterns. This
architecture is then fine-tuned into a set of 23 class-specific binary classifiers
using the DermNet dataset, enhancing diagnostic granularity and robustness,
particularly for rare conditions often underrepresented in dermatological datasets.
In the second phase, the predictions from the visual models are forwarded to
a RAG-based pipeline to generate personalized, clinically grounded explanations.
Our knowledge source consists of curated content from standard dermatology
textbooks, parsed using the LLaMA Parser [21], and embedded via the GTE
Qwen2-1.5B Instruct model [22]. QdrantDB [23] serves as the vector store for fast
semantic retrieval, with Cohere’s Re-ranker-v3.5 [24] refining document relevance
prior to final synthesis.

DermETAS-SNA LLM Assistant 7
Fusion La yer Imag eFeatures
Predicted ClassDiagnosisSKINC ON Model
StackNet Model
DERM-RAG
Fig.3: DermETAS-SNA LLM Assistant System Pipeline
We evaluated the response generations using four backends: GPT-4o [25],
LLaMA 4 Maverick [26], Gemini 2.5 Pro [15], and a multi-LLM ensemble fused
through LLM-Blender’s [27] PairRM and GenFuser modules to determine the
most effective solution for our use case. This architecture enables trusted, context-
sensitive responses with a reduced risk of hallucination. The pipeline is deployed
in a functional prototype that supports real-time image input, symptom prompts,
and secure diagnostic feedback.
5 Evolutionary Transformer Architecture Search (ETAS)
As shown in our ETAS training pipeline in Fig.4, the genetic algorithm (GA)
evolves ViT architectures through iterative selection. Our work builds upon and
adapts the ENAS-FERNet framework proposed by Deng et al. (2023) [28], which
employs Evolutionary Neural Architecture Search (ENAS) for facial expression
recognition. We extend this approach to design an ETAS specifically tailored for
optimizing ViT architectures for multi-label skin image classification using the
SKINCON dataset.
The goal of the framework is to find the ViT architecture that achieves the
best fitness performance on a given image classification task. To apply GA in this
context, we define a genetic representation of each ViT architecture candidate.
The genetic operators work in conjunction with the evolutionary process shown
in Fig.4. Thecrossoveroperator combines architectural components from parent
models, themutationoperator introduces random variations to explore new
architectures, and theselectionoperator preserves the best-performing models
for the next generation. This iterative process continues until the convergence
criteria are met. This evolutionary process helps in finding high performing ViT
architectures that serve as our base orStep-1 model, providing the foundation
for further fine-tuning and application in subsequent modules of our framework.
The complete evolutionary process is formalized in Algorithm 1, which de-
scribes the core optimization loop where ViT architectures are iteratively gener-

8 Santosh, Keerthi, et al.
SKINCON Dataset
Preprocessing
No
Stopping  
CriteriaYes
SKINCON ModelPopulation Initialization
Fitness Evaluation
Parent Selection
Crossover & Mutation
Fitness Evaluation
(offspring)
Environment Selection
Fig.4: ETAS Training Pipeline
ated, evaluated, and selected across generations. Given that fitness evaluation
(Algorithm 2) represents a computational bottleneck in this process, we implement
a hash-based caching mechanism to store and reuse performance evaluations of
previously encountered architectures, thereby significantly reducing redundant
computation. To illustrate the mechanism of each phase in our ETAS framework,
we use the specific example of optimizing architecture for the classification of
melanoma throughout the following detailed explanation.
5.1 Mathematical Formulation
The "Individual" as a ViT Architecture:An "Individual" in the genetic
algorithm is a complete Vision Transformer architecture. Its genetic code or
"chromosome" is a set of hyperparameters that define the model: (1)Chromo-
some: A variable-length sequence of Transformer Layers and (2)Genes: The
hyperparameters of each Transformer Layer, plus the total number of layers.
An individual Ican be formally represented as a sequence of ntransformer
layer L configurations:
I= (L 1, L2, . . . , L n)(1)
, where nis the number of transformer layers, a value between a defined minimum
(e.g., 6) and maximum (e.g., 12).
Each layerL iis a tuple of its specific hyperparameters (genes):
Li= (h i, mi, di, pi)(2)
, where hidenotes the number of attention heads in the i-th transformer
layer,m iis the dimension of the multilayer perceptron (MLP) in thei-th layer,

DermETAS-SNA LLM Assistant 9
Algorithm 1:ETAS: Main Evolutionary Loop
Input:max_gens, pop_size, p cross, pmutate
Output:The ViT architecture with the highest fitness found.
// Initialization: Randomly create the first generation
1P←empty list of Individuals
2fori←1topop_sizedo
3I←new Individual()
4I.architecture←GenerateRandomArchitecture()// Random ViT layer
config
5P.append(I)
6end
7P←EvaluateFitness(P)// Train and assign fitness to initial
population using Algorithm 2
// Evolutionary Loop: Run for max_gens generations
8forg←1tomax_gensdo
9O←empty list of offspring
// Generate offspring via crossover and mutation
10fori←1topop_size/2do
11p 1, p2←TournamentSelect(P)// Select parents based on
fitness
12ifrandom()< p crossthen
13c 1, c2←SinglePointCrossover(p 1, p2)// Cross over parents to
produce new children architecture
14else
15c 1, c2←p 1, p2 // No crossover; use parent architectures
directly
16end
17ifrandom()< p mutate then
18Mutatec 1andc 2by adding/removing a layer or changing a
hyperparameter
19end
20appendc 1andc 2toO
21end
22O←EvaluateFitness(O)// Train children and assign fitness
using Algorithm 2
// Environment Selection : Choose best candidates for next
generation
23P combined ←P∪O// Merge parents and offspring
24I best←Find best individual with highest fitness inP combined
25P next←RouletteWheelSelect(P combined , pop_size)// Selection based
on fitness with high probability
26ifI best/∈Pnextthen
27Replace worst individual inP nextwithI best // Elitism: preserve
best solution
28end
29P←P next
30end
31returnIndidual with the highest fitness(P)

10 Santosh, Keerthi, et al.
Algorithm 2:Fitness Evaluation Procedure
1ProcedureEvaluateFitness(Population)
2forIinPopulationdo
3key←Hash(I.architecture)// Unique key for caching
4ifkeyis in cachethen
5I.fitness←cached_value[key]// Use stored score if
already evaluated
6else
7TrainIwith 5-fold cross-validation// Train the model on
SKINCON dataset
8I.fitness←average F1 score from training run// Evaluate
performance
9StoreI.fitnessin cache withkey// Cache for efficiency
10end
11end
12returnPopulation
direpresents the dropout rate applied in the i-th layer, and piincludes additional
layer-specific parameters. The search space parameters and their values are given
in Table 1.
Table 1: GA Settings and ViT Hyperparameter Search Space
Category Parameter Value / Search Space
Genetic Algorithm Settings
Population Population Size 5
Operators Crossover Probability 0.8
Mutation Probability 0.2
Mutation Type Probs [0.7, 0.2, 0.1] for [Add, Remove, Modify]
Evolved ViT Hyperparameters (The Search Space)
Architecture Transformer Layers Integer in [6, 12]
Layer-specific Attention Heads {8, 16}
MLP Dimension {2048, 3072, 4096}
Dropout Rate Continuous in [0.1, 0.3]
Fixed ViT Hyperparameters
Dimensions Hidden Dimension 512
Embedding Dimension 768
Input Image Size 224x224
Patch Size 16x16
The Fitness Function:The objective of the GA is to maximize a fitness
function. Here, the fitness of an individual is itsF1 scoreafter the corresponding
ViT model has been trained and evaluated using 5-fold cross-validation.

DermETAS-SNA LLM Assistant 11
Fitness(I) =1
55X
k=1F1-Score k(TrainAndEvaluate(I))(3)
The algorithm’s goal is to find the individual I∗with the maximum fitness
value of all possible architectures:
I∗= arg max
I∈S(Fitness(I))(4)
, whereSis a set of ViT architecture candidates. The choice of a relatively
small population size ( pop_size = 5) and a limited number of generations
(max_gens = 20) represents a pragmatic trade-off between computational feasi-
bility and exploratory sufficiency. The evolutionary search for optimal architec-
tures is computationally expensive, as each individual candidate in the population
must be trained and evaluated to assess its fitness. Given that the SKINCON
dataset, while densely annotated, is of a moderate size (3,886 images), an ex-
tensive search with a large population was deemed unnecessary to find a strong
local optimum. Our analysis indicated that a population of 5 individuals over
20 generations provided a sufficient diversity of architectures for the search to
converge effectively on this dataset, without incurring prohibitive computational
costs.
5.2 Illustrative Example
To demonstrate the application of our mathematical formulation, we present a
concrete example of the ETAS pipeline optimizing an architecture for melanoma
classification. The input image in Fig.2 shows a sample dermoscopic image
from the Melanoma class that would be processed through our system. The
evolutionary process unfolds as follows:
Step 1: Initialization (Algorithm 1, lines 3-7)
Input: Fig. 2 from Melanoma class
Initial Architecture (Gen 1):
I1= [(8,2048,0.2),(8,2048,0.2),(16,3072,0.1)](5)
This architecture represents a 3-layer ViT with the gene configurations
specified in Equation 2.
Step 2: Fitness Evaluation (Algorithm 2)
The architecture undergoes training and evaluation, achieving:
Fitness(I 1) = 0.72(6)
This F1-score represents the performance metric defined in Equation 3.
Step 3: Evolutionary Optimization (Algorithm 1, lines 8-30)
Through 20 generations of selection, crossover, and mutation operations:

12 Santosh, Keerthi, et al.
Final Optimized Architecture (Generation 20):
I∗= [(16,4096,0.1),(16,3072,0.2),(16,3072,0.1)](7)
This architecture maximizes the objective function in Equation 4.
Step 4: Feature Extraction
The optimized architecture extracts feature vector:
v= [Papule,Scale,Brown Hyperpigmentation](8)
This feature vectorvserves as input to both StackNet for disease classification
and DERM-RAG for evidence retrieval and explanation generation.
6 StackNet Architecture
In the second module of our framework as shown in Fig.5, we build upon the
best ViT architecture identified by ETAS on the SKINCON dataset. This model,
originally optimized for multi-label classification of dermatological features, serves
as the foundation for fine-tuning a suite of 23 binary classifiers, one dedicated to
each disease class in the DermNet dataset.
To address key challenges in Dermatological AI, including poor performance
on rare or underrepresented conditions and reduced diagnostic precision when
using a single multi-class model, we employed a two-level model for skin cancer
classification. The first level consists of training the 23 binary classifiers, allowing
each model to focus on distinguishing a specific condition from all others. The
second level involves a custom meta-classifier that synthesizes a complex set of
features, including binary predictions, multi-scale deep features extracted from a
pretrained model, and probability statistics to make a final, informed diagnosis.
Stage 1: Binary Classifier Fine-Tuning:As outlined in Algorithm 3, For each
class c∈ { 1, . . . , 23}, a dedicated binary classifier Mcis trained, by modifying
its final classification layer of a ETAS-optimized ViT model to produce a single
sigmoid-activated output, representing the probability of the image belonging to
the target disease class. To optimize performance for each specific disease class,
we employed two distinct fine-tuning strategies: (1)Full Fine-tuning with
Unfreezing (FU):The entire pre-trained model was fine-tuned, allowing all
weights to be updated for the new binary task; (2)Gradual Layer Unfreezing
(GU):Fine-tuning commenced with only the final classification layers unfrozen.
After each epoch, earlier layers were progressively unfrozen, allowing the model
to adapt more stably.
A key aspect is the creation of abalanced one-vs-all dataset Dcfor
each class. The training objective is to find the optimal hyperparameters h∗
(learning rate, momentum, batch size) from a predefined grid Hby maximizing
the accuracy using 5-fold and 10-fold cross-validation techniques. The final model
M∗
cproduces a probabilityp c(x)for an input imagex.

DermETAS-SNA LLM Assistant 13
DermNet Dataset
Preprocessing
SKINCON Model ResNet 50
Finetune
Feature Extraction
Train 23 Binary Classifiers
( 1 for each class)Model TrainingFeatures
Probabilities
StackNet
Fig.5: StackNet Architecture.
Stage 2: Meta-Classifier Feature Engineering:As detailed in Algorithm 4,
the second level employs a meta-classifier Mmetathat predicts the skin disease
class based on a comprehensive feature vector formed by concatenating the
following three components:
–Probability VectorP( x): Raw probabilities from the 23 binary classifiers.
P(x) = [p∗
1(x), p∗
2(x), . . . , p∗
23(x)]∈R23(9)
–Multi-ScaleDeepFeatureVectorD multi (x):Featuresextractedfromfour
layers of a pretrained ResNet-50 [29] and concatenated to form a hierarchical
representation:
Dmulti(x) =4M
i=1GlobalAvgPool(ResNet Li(x))∈RN(10)
–Probability Statistics VectorS( x): Summary statistics derived fromP( x)
that capture distributional characteristics:
S(x) = [µ(P), σ(P), µ(top3),(top1−top3)]∈R4(11)
The final input to the meta-classifier is the concatenated feature vector:
F(x) =P(x)⊕D multi(x)⊕S(x)(12)

14 Santosh, Keerthi, et al.
Algorithm 3:Stage 1: Binary Model Training (Per Class)
Input:Base model ViT ETAS, Dermnet datasetD, Classc, Hyperparameter
GridH, FoldF
Output:The single best-performing binary modelM∗
cfor classc
1Dbal
c←CreateBalancedBinaryDataset(D, c)// Balance dataset for class
cvs all
2best_global_f1←0
3best_global_model←None// Track best model
4forkinFoldFdo
5forparamsinHyperparameter GridHdo
6fold_f1s←[]
7forfoldink-Fold CV split ofDbal
cdo
8model←Load(ViT ETAS)// Load base ViT-ETAS
9model.classifier←nn.Linear(512,1)// Replace last layer for
binary classification
10FineTune(model, params, fold.train_data)// Train model
11f1←Evaluate(model, fold.val_data)
12fold_f1s.append(f1)
13end
14ifAverage(fold_f1s)>best_global_f1then
// Check if current model is best so far
15best_global_f1←Average(fold_f1s)
16best_global_model←best model saved during this run
17end
18end
19end
20returnbest_global_model// Return best model for classc
Algorithm 4:Stage 2: Full Prediction Pipeline with Feature Engineering
Input:Input Imagex, Binary Models{M∗
c}, Pretrained ResNet50,
Meta-ClassifierM meta
Output:Final Class Prediction
1P vec←[M∗
1(x), . . . , M∗
23(x)]// 23-dim probability vector
2D multi←ExtractMultiLayerResNetFeatures(x)// Extract deep features
from ResNet layers
3S vec←CalculateProbabilityStats(P vec)// Compute statistical features
(mean, std, etc.)
4F final←Concatenate(P vec, Dmulti, Svec)// Combine all features into
final vector
5prediction←M meta(Ffinal)// Predict final class using
meta-classifier
6returnprediction

DermETAS-SNA LLM Assistant 15
The meta-classifier is implemented as a custom 1D CNN and trained usingFocal
Lossto effectively address class imbalance and focus on hard examples.
The input image from Fig.2 and optimized ViT architecture are processed
through StackNet:
Step 1: Binary Classifier Training (Algorithm 3)
Balanced dataset: 300 Melanoma vs 300 non-Melanoma images
Fine-tuned using ViT(I∗) with sigmoid head
Best modelM∗
melpredicts:
pmel(x) =0.91(13)
Step 2: Probability Vector Construction (Algorithm 4, line 2)
P(x) = [p 1(x), p 2(x), . . . , p 23(x)]∈R23(14)
Step 3: Deep Feature Extraction (Algorithm 4, line 3)
Dmulti(x) =4M
i=1GAP(ResNet Li(x))∈R2048(15)
Step 4: Statistical Features (Algorithm 4, line 4)
S(x) =
µ(P)
σ(P)
µ(top3(P))
max(P)−µ(top3(P))
=
0.18
0.22
0.72
0.13
(16)
Step 5: Meta-Classification (Algorithm 4, lines 5-6)
F(x) =P(x)⊕D multi(x)⊕S(x)∈R2075(17)
Final Prediction=argmax(MLP(F(x))) =Melanoma (94.5%) (18)
7DERM-RAG - Diagnostic Explanation and Retrieval
Model for Dermatology Pipeline
In the DERM-RAG Module, we focus on giving users clear and trustworthy
answers usingRetrieval-Augmented Generation (RAG). As shown in
Fig.6, first we gathered around 5,000 pages of trusted skin disease information
from well-known materials likeHabif’s Clinical Dermatology,Rook’s Textbook
of Dermatology,Fitzpatrick Dermatology, and a few others. This information is
cleaned and broken into small, meaningful chunks usingLLaMA Parser. For
example, one chunk might explain“what melanoma is”and another might talk
about“treatment options”.

16 Santosh, Keerthi, et al.
Preprocessing
Embedding
Model
(Qwen2-1.5B-instruct)Vector DB
(Qdrant)
ReRank
(Cohere rerank-v3.5)LLM
(Gemini 2.5
Pro)
Knowledge  
Base
UserDocument Ingestion
User Query, Retrieval & Response GenerationQueryDocument  
Embeddings
Query & Embedded  
Query
Initial ContextPrompt  
+ 
Query
 + 
enhanced contextDocuments
Fig.6: DERM-RAG Pipeline
We then useQwen 1.5BEmbedding Model to convert each chunk into
embeddings. These embeddings are stored in an efficient semantic search engine
calledQdrantDB, allowing quick retrieval of the most relevant information
when a user submits a question. For example, if a user uploads an image, and
the system predictsMelanomaand also detects features such asPapuleand
Brown (Hyperpigmentation). Based on this, the system constructs a user-friendly
question like:
“The image analysis detected the following skin features: Papule, Brown
(HyperPigmentation). The most likely diagnosis based on our model is:
Melanoma. Please explain what this diagnosis usually means, common
symptoms, and first-line treatments in simple terms?”
This question is then embedded usingQwen 1.5B, and the most relevant
chunks are retrieved from the knowledge base. Example results might include:
(1)“Melanoma is a serious form of skin cancer that starts in pigment cells.”;
(2)“Treatments include surgery, immunotherapy, and targeted drugs like BRAF
inhibitors.”.
These chunks are passed through aCohere Re-Ranker, which reorders
them based on relevance. Subsequently, one or more advanced LLMs, such as
Gemini 2.5 Pro,GPT-4o, orLLaMA 4 Maverickgenerate a friendly and
informative response. For example:
“Melanoma is a dangerous skin cancer that comes from pigment-producing
cells. It can be treated with surgery if caught early. In later stages, treat-
ments like immunotherapy or targeted drugs may be used. Early diagnosis
is very important for a better outcome.”
To ensure these answers are accurate and safe, we involvedermatologistsin
an expert evaluation step. Multiple responses to the same question are presented
to them, and each is graded on a scale ofStrongly Agree, Agree, Neutral, Disagree,
Strongly Disagree. For example, if three dermatologists rate a response asStrongly

DermETAS-SNA LLM Assistant 17
Agree, the answer is considered highly reliable. Through this process, our system
integrates curated medical knowledge, semantic search, and advanced AI to
deliver accurate and comprehensible answers validated by domain experts.
8Experimental Evaluations and Domain-Expert
Assessment
8.1 Experimental Evaluations
The evolutionary search in the ETAS framework ran for 20 generations with
a population size of 5. Each candidate architecture was evaluated using 5-fold
cross-validation, with the average performance determining selection for the next
generation. After evolution, the best-performing model was a 12-layer transformer,
trained for 50 epochs, achieving the highest average F1-score of0.716across all
folds. To address the severe class imbalance in the DermNet dataset, we trained
23 specialized binary classifiers, one for each disease class, using the fine-tuning
strategies detailed in Section 6. Extensive experimentation was conducted with
hyperparameters such as learning rate, momentum, and batch size using both
5-fold and 10-fold cross validation to determine the best-performing model for
each class and selected for comparison against SkinGPT-4 as a baseline. Each
binary models was assessed using the performance metrics such as Accuracy,
Precision, Recall, F1-Score, and Matthews Correlation Coefficient (MCC).
The best models were selected based on both training strategies and 5-fold
and 10-fold cross-validation results. Complete class-wise performance metrics
are presented in Table 2. Among the seven classes suggested by domain experts,
several showed particularly strong performance:
1.Although Melanoma is not among the seven classes,Melanomaachieved the
highest F1 score (74.16%) by full unfreezing with 10-fold CV, demonstrating
the effectiveness of our approach for critical diagnoses.
2.Atopic DermatitisandHair Lossboth exceeded 70% F1-score, indicating
robust performance for common conditions.
3.Actinic KeratosisandSeborrheic Keratosesshowed moderate per-
formance (62.38% and 65.08% F1-score respectively), likely due to visual
similarity between these conditions.
4.PsoriasisandWartshad lower performance (44.52% and 55.74%), suggest-
ing these classes may benefit from additional training data or architectural
adjustments.
The results demonstrate that specialized binary classifiers provide more
reliable diagnoses than a unified model approach. However, due to class overlaps
and image duplication, direct aggregation of predictions from the binary classifiers
caused misclassifications. For the meta classifier, we evaluated several CNN
configurations and found the best results with a model containing three fully
connected layers (1024, 512, 256 units), trained with a learning rate of 0.0005
and batch size of 16. To benchmark our system, we implemented SkinGPT-4

18 Santosh, Keerthi, et al.
Table 2: Binary Classifier Performance
Class Best Model Accuracy F1 Score MCC
Acne and Rosacea GU - 10 Fold 0.5819 0.5956 0.1642
Actinic Keratosis GU - 5 Fold 0.5938 0.6238 0.1899
Atopic Dermatitis FU - 5 Fold 0.6707 0.7362 0.3932
Bullous Disease GU - 10 Fold 0.6018 0.5909 0.2038
Cellulitis Impetigo GU - 10 Fold 0.6027 0.6375 0.2094
Contact Dermatitis GU - 5 Fold 0.6000 0.6389 0.2048
Eczema GU - 10 Fold 0.6133 0.6490 0.2314
Exanthems GU - 10 Fold 0.6089 0.6457 0.2227
Fungal Infections GU - 10 Fold 0.5446 0.3537 0.1106
Hair Loss FU - 5 Fold 0.6083 0.7117 0.3107
Herpes FU - 5 Fold 0.6029 0.6824 0.2377
Infestations & Bites GU - 5 Fold 0.5324 0.4599 0.0673
Light Diseases GU - 5 Fold 0.5804 0.6000 0.1616
Lupus FU - 5 Fold 0.7048 0.6961 0.4102
Melanoma FU - 10 Fold 0.7026 0.7416 0.4250
Nail Fungus GU - 5 Fold 0.6820 0.6937 0.3651
Psoriasis GU - 10 Fold 0.5114 0.4452 0.0234
Seborrheic Keratoses GU - 10 Fold 0.6356 0.6508 0.2722
Systemic Diseases FU - 5 Fold 0.6053 0.6591 0.2219
Urticaria Hives FU - 10 Fold 0.6792 0.7258 0.3811
Vascular Tumors FU - 5 Fold 0.5865 0.6578 0.1904
Vasculitis FU - 10 Fold 0.5667 0.6894 0.2177
Warts GU - 10 Fold 0.6029 0.5574 0.2104
by adapting its base model trained first on SKINCON (20 epochs), then fine-
tuned on DermNet (additional 20 epochs). Table 3 compares the performance
of StackNet against SkinGPT-4 across key evaluation metrics. The comparative
analysis reveals several advantages of the StackNet architecture:
1.Superior Recall and F1-score:StackNet’s most prominent improvement
is inRecall(55.29% vs. 46.83%), representing an increase by approximately
18.06%. This indicates that our model is better at identifying true positives
and reducing false negatives, critical in medical diagnostics where missing a
disease (e.g., melanoma) can have severe consequences. The harmonized F1-
score increased by approximately 16.06%, improving from 48.51% to 56.30%,
indicating a more robust overall performance.
2.Enhanced Classification Quality:The higher Matthews Correlation
Coefficient (MCC) of 0.57 compared to 0.50 signifies a better overall quality
of binary classifications, especially important given the imbalanced nature of
the DermNet dataset.
3.Architectural Advantages:The performance gap can be attributed to the
dual-level design of StackNet. SkinGPT-4 uses a single model for all 23 classes,
whichcanstrugglewithinter-classsimilaritiesanddataimbalance.Incontrast,

DermETAS-SNA LLM Assistant 19
Table 3: Performance Comparison between StackNet and SkinGPT-4
Metric StackNet SkinGPT-4
Accuracy(%) 59.89 52.92
Precision(%) 59.25 54.57
Recall(%) 55.29 46.83
F1 Score(%) 56.30 48.51
MCC 0.57 0.50
StackNet’s first-level binary classifiers specialize in individual conditions,
learning highly discriminative features. A second-level meta-classifier then
synthesizes these expert outputs with deep features and statistical context,
yielding more nuanced and accurate predictions. This design is particularly
effective for rare or visually similar conditions that are often misclassified by
monolithic models.
8.2 Domain Expert Assessment
We conducted a clinical evaluation of all models integrated into the DermETAS-
SNA LLM pipeline. Following discussions with experts in the field, seven promi-
nent skin conditions were chosen for comprehensive clinical assessment: Warts,
Actinic Keratosis, Eczema, Seborrheic Keratoses, Psoriasis, Nail Fungus, and
Hair Loss. The following user-centered evaluation questions were used to assess
the generated responses: (1) Can you explain my diagnosis in detail, and how
certain is it that I have skin disease?; (2) What are my treatment options for
my diagnosis and possible side effects?; (3) What factors could influence my
prognosis?; (4) How will the treatment affect my daily activities and overall
quality of life?; (5) What kind of follow-up care and monitoring will be required
after treatment?
The responses were evaluated using the following six evaluation criteria: (1)
The diagnosis is correct or relevant; (2) The explanation is informative; (3)
Suggestions are useful; (4) Can help doctors with diagnosis; (5) Helps patients
understand better; (6) Willingness to use this model.
The responses are rated on a 5-point Likert scale for each criteria: Strongly
Agree, Agree, Neutral, Disagree, Strongly Disagree. The aggregated expert ratings
are shown in Table 4 and visualized in Fig.7. Below are the critical findings from
the evaluation results:
1.Superior Performance of Gemini 2.5 Pro with RAG:The Gemini 2.5
Pro model, enhanced with our curated medical text and re-ranking pipeline
(DERM-RAG), achieved the highest expert consensus with a 92% agreement
rate (67.0% Strongly Agree + 25.0% Agree). This underscores the value of
grounding LLM responses in verified, authoritative sources. By retrieving and
synthesizing content from dermatology textbooks, DERM-RAG mitigates
hallucination and delivers accurate, contextually relevant explanations aligned
with vision model outputs.

20 Santosh, Keerthi, et al.
Table 4: Clinical Agreement Rates between Dermatologists and AI Models.
ModelStrongly
Agree (%)Agree
(%)Neither
Agree nor
Disagree
(%)Disagree
(%)Strongly
Disagree
(%)
Gemini 2.5 Pro 67.0 25.0 6.0 0.3 1.8
LLM Blender -
Ensemble39.3 36.6 17.6 2.4 4.2
GPT-4o 37.8 43.5 10.7 4.2 3.9
LLaMA 4 Maverick 37.8 43.2 12.2 3.9 3.0
SkinGPT-4 32.1 16.1 6.8 7.1 37.8
0 20 40 60 80 100
Percentage/uni00A0of/uni00A0ResponsesSkinGPT/uni00AD4LLaMA/uni00A04/uni00A0MaverickGPT/uni00AD4oEnsembleGemini/uni00A02.5/uni00A0ProModel/uni00A0Performance/uni00A0Evaluation
Strongly/uni00A0Agree/uni00A0%
Agree/uni00A0%Neither/uni00A0agree/uni00A0nor/uni00A0disagree/uni00A0%
Disagree/uni00A0%Strongly/uni00A0disagree/uni00A0%
Fig.7: Comparative Performance Evaluation of Models Showing Dermatologist’s
Agreement Levels with Model-Generated Responses.
2.The Hallucination Problem in SkinGPT-4:In stark contrast, SkinGPT-
4 showed substantially lower agreement (48.2%) and the highest rate of
strong disagreement (37.8%). This performance gap highlights a fundamental
limitation: without integration to a verified knowledge base, even power-
ful multimodal LLMs are prone to generating plausible but incorrect or
generalized information.
3.Performance of Other Foundational Models:The other foundational
models (GPT-4o, LLaMA 4 Maverick) and the Ensemble approach performed
comparably, with overall agreement rates clustering around 80%. This sug-
gests that while they possess strong inherent capabilities, they still lack the
domain-specific grounding necessary for high-stakes medical dialogue. The
ensemble method did not outperform the best individual model (Gemini 2.5
Pro), indicating that simply blending outputs is less effective than a deeply
integrated RAG approach for this specialized domain.

DermETAS-SNA LLM Assistant 21
9 Proof of Concept Prototype
The prototype user interface (UI) was developed using Streamlit and deployed
on WPI’s Academic & Research Computing cluster using an Apple Mac Studio
(M2 Max, 12-core CPU, 96 GB unified memory, 38-core GPU). The stack included
Python 3.10, Streamlit 1.25.0, and GPU-accelerated inference via Apple’s Metal
API.
Fig.8 demonstrates the prototype’s workflow: (a) users can upload dermato-
logical images through an intuitive interface, (b) the system processes images
through our ETAS and StackNet models to extract visual features and generate
predictions, (c) the DERM-RAG module retrieves relevant information from
medical knowledge bases to provide comprehensive diagnostic explanations, and
(d) users engage in interactive dialogues about treatment options and side effects,
highlighting multimodal conversational capabilities.
10 Conclusions and Future Work
This study demonstrates the potential of combining LLMs with classification and
ensemble learning techniques, supported by domain expert evaluation, for effective
skin disease diagnosis. Skin diseases have become one of the most prevalent
health challenges globally, and our proposed AI assistant,DermETAS-SNA, is
designed to assist dermatologists by offering preliminary diagnostic support.
Our key contributions include: (1) Development of an Evolutionary Transformer
Architecture Search (ETAS) framework tailored for dermoscopic image analysis.
(2) Implementation of a one-vs-all binary classification strategy to address the
class imbalance present in the dataset. (3) Integration of domain-specific medical
knowledge into LLM using retrieval-augmented generation (RAG), allowing
tailored and context-aware responses.(4) Extensive experimental evaluations
on 23 disease categories demonstrating a considerable improvement (16.06%
increase in F1-score) over the SkinGPT-4 baseline. (5) Evaluation of generated
outputs through feedback from board-certified dermatologists to ensure clinical
reliability and relevance. (6) Proof-of-concept prototype that fully integrates
our DermETAS-SNA LLM into our AI assistant to demonstrate its practical
feasibility for real-world clinical and educational applications.
We acknowledge that the absolute performance (56.3% F1-score on a complex
23-class task) indicates a non-negligible error rate, positioning our system as an
assistive tool for triage and differential diagnosis generation, not a replacement
for clinical expertise. Clinically, the system reduces diagnostic wait times and
enhances doctor-patient communication through explainable AI provided by our
DERM-RAG module. Nonetheless, limitations remain. (1) Models were trained
and evaluated on a standard stratified split of the DermNet dataset. While
techniques like stratified splits and regularization were employed to mitigate over-
fitting in the one-vs-all classifiers, future work will involve rigorous cross-dataset
validation on independent, publicly available benchmarks such as HAM10000
and ISIC to assess performance across diverse skin tones and imaging conditions.

22 Santosh, Keerthi, et al.
( b )
Skin Disease Imag e
( a )
( c )
( d )
Fig.8: DermETAS-SNA Assistant Prototype Interface
(2) As with many dermatological AI studies, demographic and phenotypic di-
versity is incompletely captured; a key goal is to train on larger, multi-source,
ethically sourced datasets to ensure equitable performance.(3) Expand the RAG
pipeline’s knowledge base by incorporating authoritative medical sources (e.g.,
MedlinePlus, UMLS, UpToDate) to enhance the robustness, reliability, and clini-
cal relevance of generated responses. By addressing these directions, we aim to
further refine DermETAS-SNA into a comprehensive and reliable AI assistant
for dermatological diagnosis and decision support in clinical use.

DermETAS-SNA LLM Assistant 23
Acknowledgments
The authors would like to thank Mr.Ermal Toto, Director, Scientific Data, Applications
and Web Development in the WPI Academic & Research Computing group at Worcester
Polytechnic Institute, for providing consulting support that contributed to the results
presented in this work. We extend our thanks to Dr. Sriram Vemula, Dr. Praveen R,
Dr. Vishnukumar Subramanian, Dr. Thirumugilan B C, Dr. Saran Anand Murugan,
Dr. Infant Nishanth A, and Dr. Raaga Likhitha Musunuri for their expert evaluation of
clinical responses in this study.
References
1.World Health Organization:EB156 draft decision on skin diseases as a global
public health priority. 2025. https://cdn.who.int/media/docs/default-
source/ntds/skin-ntds/global-meeting-on-skin-related-neglected-
tropical-diseases-2025/eb156-draft-decision-on-skin-diseases-as-
a--global-public-health-priority.pdf?sfvrsn=b64f45e8_3 (accessed July 19,
2025).
2.Tian, J., Zhang, D., Yang, Y., Huang, Y., Wang, L., Yao, X., Lu, Q.:Global
epidemiology of atopic dermatitis: a comprehensive systematic analysis and modelling
study. British Journal of Dermatology190(1), 55–61 (2023). https://doi.org/10.
1093/bjd/ljad339
3.Maghiar, L.; Sandor, M.; Sachelarie, L.; Bodog, R.; Huniadi, A. Skin Lesions
Caused by HPV—A Comprehensive Review. Biomedicines 2024, 12, 2098. https:
//doi.org/10.3390/biomedicines12092098
4.George CD, Lee T, Hollestein LM, Asgari MM, Nijsten T. Global epidemiology of
actinic keratosis in the general population: a systematic review and meta-analysis.
Br J Dermatol. 2024 Mar 15;190(4):465-476. doi: 10.1093/bjd/ljad371.
5.Greco MJ, Bhutta BS. Seborrheic Keratosis. [Updated 2024 May 6]. In: StatPearls
[Internet]. Treasure Island (FL): StatPearls Publishing; 2025 Jan-. Available from:
https://www.ncbi.nlm.nih.gov/books/NBK545285/
6.Bodman MA, Syed HA, Krishnamurthy K. Onychomycosis. [Updated 2024 Jan 9].
In: StatPearls [Internet]. Treasure Island (FL): StatPearls Publishing; 2025 Jan-.
Available from:https://www.ncbi.nlm.nih.gov/books/NBK441853/
7.Siegel, R.L., Kratzer, T.B., Giaquinto, A.N., Sung, H., Jemal, A.: Cancer statistics,
2025.CA Cancer J Clin.75(1), 10–45 (2025). https://doi.org/10.3322/caac.21871
8.Shah M, Burshtein J, Zakria D, Rigel D. Analysis of trends in US dermatologist
density and geographic distribution.J Am Acad Dermatol. 2024 Aug;91(2):338–341.
doi:10.1016/j.jaad.2024.03.037. PMID: 38574771.
9.Zhou, J., He, X., Sun, L., Xu, J., Chen, X., Chu, Y., Zhou, L., Liao, X., Zhang,
B., Afvari, S., Gao, X.: Pre-trained multimodal large language model enhances
dermatological diagnosis using SkinGPT -4.Nature Communications15(1), 5649
(2024). https://doi.org/10.1038/s41467-024-50043-3
10.A. Dosovitskiy, L. Beyer, A. Kolesnikov, “An Image is Worth 16x16 Words: Trans-
formers for Image Recognition at Scale,”arXiv preprint arXiv:2010.11929, 2020.
Available:https://doi.org/10.48550/arXiv.2010.11929
11.Hugo Touvron, Louis Martin, Kevin Stone, et.alLlama 2: Open Foundation and
Fine-Tuned Chat Models, arXiv preprint arXiv:2307.09288, 2023. Available at:
https://doi.org/10.48550/arXiv.2307.09288

24 Santosh, Keerthi, et al.
12.Daneshjou, R., Yuksekgonul, M., Cai, Z., Novoa, R.A., Zou, J.: Skin-
Con: A skin disease dataset densely annotated by domain experts for fine-
grained model debugging and analysis.arXiv preprintarXiv:2302.00785 (2023).
https://doi.org/10.48550/arXiv.2302.00785
13.Goel, S.: DermNet Skin Disease Image Dataset.Kaggle(2022). https://www.
kaggle.com/datasets/shubhamgoel27/dermnet
14.Patrick Lewis, Ethan Perez, Aleksandra Piktus, et Al Retrieval -Augmented Gen-
eration for Knowledge -Intensive NLP Tasks. In *Advances in Neural Information
Processing Systems (NeurIPS)*, vol.33, pp.9459–9474, 2020. arXiv:2005.11401.
:contentReference[oaicite:1]index=1
15.Google Cloud: Gemini 2.5 Pro Preview 05–06. https://cloud.google.com/vertex-
ai/generative-ai/docs/models/gemini/2-5-pro
16.Dinulos, J.G.H., and Habif, T.P.Habif’s Clinical Dermatology: A Color Guide to
Diagnosis and Therapy. 7th ed., Edinburgh: Elsevier, 2021.
17.Paul, C.Rook’s Textbook of Dermatology, 9th edn. Edited by Christopher Grif-
fiths, Jonathan Barker, 2016; 4696 pp. ISBN: 978-1118441190.British Journal of
Dermatology, 176(6), 1676–1677, 2017. https://doi.org/10.1111/bjd.15624.
18.Buckley, D., and Pasquali, P. (Eds.).Textbook of Primary Care Dermatology. Cham:
Springer, 2021.
19.Wolff, K., Goldsmith, L., Katz, S., Gilchrest, B., Paller, A.S., and Leffell, D.
Fitzpatrick’s Dermatology in General Medicine. 7th ed., McGraw-Hill, 2008.
20.Drugge, R., Dunn, H. A., & Internet Dermatology Society.The Electronic Textbook
of Dermatology. Internet Dermatology Society, 2000.
21.LlamaIndex: LlamaParse – parse & clean your data for RAG. https://docs.
llamaindex.ai/en/stable/llama_cloud/llama_parse/
22.Li, Z., Zhang, X., Zhang, Y., Long, D., Xie, P., Zhang, M.: Towards general text
embeddings with multi-stage contrastive learning.arXiv preprintarXiv:2308.03281
(2023)
23.Qdrant developers: Qdrant: Open-source Vector Database. Version 1.5.0 (2025).
https://qdrant.tech
24.Cohere: Introducing Rerank3.5: Precise AI Search. https://cohere.com/blog/
rerank-3pt5
25. OpenAI: GPT-4o System Card.https://openai.com/index/hello-gpt-4o/
26.Meta AI: LLaMA4Maverick – Model Card. https://huggingface.co/meta-llama/
Llama-4-Maverick-17B-128E-Instruct
27.Dongfu Jiang, Xiang Ren, and Bill Yuchen Lin. LLM-Blender: Ensembling Large
Language Models with Pairwise Ranking and Generative Fusion.arXiv preprint
arXiv:2306.02561, 2023. URL:https://doi.org/10.48550/arXiv.2306.02561.
28. S. Deng, Z. Lv, E. Galván and Y. Sun, "Evolutionary Neural Architecture Search
for Facial Expression Recognition," in IEEE Transactions on Emerging Top-
ics in Computational Intelligence, vol. 7, no. 5, pp. 1405-1419, Oct. 2023, doi:
10.1109/TETCI.2023.3289974
29.N. Gaffoor and S. Soomro, "Skin Disease Detection and Classification Using
ResNet-50 and Support Vector Machine: An Effective Approach for Dermato-
logical Diagnosis," 2023 IEEE International Conference on Internet of Things and
Intelligence Systems (IoTaIS), Bali, Indonesia, 2023, pp. 140-145, doi: 10.1109/Io-
TaIS60147.2023.10346059.