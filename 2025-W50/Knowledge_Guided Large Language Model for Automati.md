# Knowledge-Guided Large Language Model for Automatic Pediatric Dental Record Understanding and Safe Antibiotic Recommendation

**Authors**: Zihan Han, Junyan Ge, Caifeng Li

**Published**: 2025-12-09 21:11:55

**PDF URL**: [https://arxiv.org/pdf/2512.09127v1](https://arxiv.org/pdf/2512.09127v1)

## Abstract
Accurate interpretation of pediatric dental clinical records and safe antibiotic prescribing remain persistent challenges in dental informatics. Traditional rule-based clinical decision support systems struggle with unstructured dental narratives, incomplete radiographic descriptions, and complex safety constraints. To address these limitations, this study proposes a Knowledge-Guided Large Language Model (KG-LLM) that integrates a pediatric dental knowledge graph, retrieval-augmented generation (RAG), and a multi-stage safety validation pipeline for evidence-grounded antibiotic recommendation. The framework first employs a clinical NER/RE module to extract structured entities and relations from dental notes and radiology reports. Relevant guidelines, drug-safety rules, and analogous historical cases are subsequently retrieved from the knowledge graph and supplied to the LLM for diagnostic summarization and dose-drug-duration prediction. Safety assurance is achieved through a dual-layer validation mechanism combining deterministic rule checking with a learned classifier for detecting allergies, contraindications, and dosing errors. Experiments on 32,000 de-identified pediatric dental visit records demonstrate the effectiveness of the proposed approach. Compared with a domain-adapted Llama-2 clinical baseline, KG-LLM improves record-understanding performance (F1: 0.914 vs. 0.867), drug-dose-duration accuracy (Top-1: 0.782 vs. 0.716), and reduces unsafe antibiotic suggestions by 50%. Additional evaluation across summary quality, recommendation accuracy, and global safety scores further confirms the robustness of the system. Ablation analyses indicate that the knowledge graph, RAG, and safety modules each contribute substantially to clinical reliability and interpretability.

## Full Text


<!-- PDF content starts -->

Knowledge-GuidedLargeLanguageModelfor
AutomaticPediatricDentalRecordUnderstandingand
SafeAntibioticRecommendation
ZihanHan1,JunyanGe2,CaifengLi3
1SchoolofAutomationandElectricalEngineering,UniversityofJinan,Jinan,
China
2CollegeofDentalMedicine,ColumbiaUniversity,NewYork,NY,USA
3JilinUniversity,Changchun,China
11812503968@qq.com
2jg4377@caa.columbia.edu
3lisa660601@163.com
Abstract.Accurateinterpretationofpediatricdentalclinicalrecordsandsafe
antibioticprescribingremainpersistentchallengesindentalinformatics.Traditional
rule-basedclinicaldecisionsupportsystemsstrugglewithunstructureddental
narratives,incompleteradiographicdescriptions,andcomplexsafetyconstraints.To
addresstheselimitations,thisstudyproposesaKnowledge-GuidedLargeLanguage
Model(KG-LLM)thatintegratesapediatricdentalknowledgegraph,
retrieval-augmentedgeneration(RAG),andamulti-stagesafetyvalidationpipeline
forevidence-groundedantibioticrecommendation.Theframeworkfirstemploysa
clinicalNER/REmoduletoextractstructuredentitiesandrelationsfromdentalnotes
andradiologyreports.Relevantguidelines,drug-safetyrules,andanalogous
historicalcasesaresubsequentlyretrievedfromtheknowledgegraphandsuppliedto
theLLMfordiagnosticsummarizationanddose–drug–durationprediction.Safety
assuranceisachievedthroughadual-layervalidationmechanismcombining
deterministicrulecheckingwithalearnedclassifierfordetectingallergies,
contraindications,anddosingerrors.Experimentson32,000de-identifiedpediatric
dentalvisitrecordsdemonstratetheeffectivenessoftheproposedapproach.
Comparedwithadomain-adaptedLlama-2clinicalbaseline,KG-LLMimproves
record-understandingperformance(F1:0.914vs.0.867),drug-dose-duration
accuracy(Top-1:0.782vs.0.716),andreducesunsafeantibioticsuggestionsby50%.
Additionalevaluationacrosssummaryquality,recommendationaccuracy,andglobal
safetyscoresfurtherconfirmstherobustnessofthesystem.Ablationanalyses
indicatethattheknowledgegraph,RAG,andsafetymoduleseachcontribute
substantiallytoclinicalreliabilityandinterpretability.
Keywords:Pediatricdentistry;antibioticstewardship;largelanguagemodel(LLM);
knowledgegraph;retrieval-augmentedgeneration(RAG);clinicaldecisionsupport
system(CDSS);dentalinformatics;medicalNLP
1.Introduction
Pediatricdentalinfections,includingpulpitisandperiapicalabscesses,representsomeofthe
mostcommoncausesofacutedentalpainamongchildren.Accuratediagnosisandantibiotic
stewardshiparecriticalinthesecases,asinappropriateprescriptionsincreasetherisksof

adversedrugreactions,antimicrobialresistance,andlong-termdisruptionstotheoral
microbiome.However,clinicaldecision-makinginpediatricdentistryremainschallenging
duetoheterogeneouselectronicdentalrecords(EDRs),complexradiographicdescriptions,
age-dependentpharmacokineticconsiderations,andvaryingcompliancewithclinical
guidelines.Thesechallengesunderscoretheneedforintelligent,automatedsystemscapable
ofunderstandingpediatricdentalrecordsandsupportingsafeantibioticprescribing.
Recentadvancementsinlargelanguagemodels(LLMs)havedemonstratedremarkable
capabilitiesinclinicaltextunderstanding,medicalentityextraction,andguidelinegrounded
reasoning.Nevertheless,general-purposeLLMsoftenhallucinate,lackdomain-specific
knowledge,andcannotreliablyhandlespecializedpediatricdentalterminologyordrug
contraindicationconstraints.Toaddresstheselimitations,thisstudyadoptsa
Knowledge-GuidedLargeLanguageModel(KG-LLM)framework,whichintegrates
structuredmedicalknowledgeintoLLMreasoningprocessestoensurefactualreliability,
explainability,andsafedecisionsupport.
TheproposedKG-LLMframeworkunifiesthreekeycomponents:(1)a
retrieval-augmentedpipelinethatextractsrelevantclinicalknowledgefromapediatricdental
knowledgegraph,includingpathogenprofiles,treatmentguidelines,andage-specific
antibioticdosagerules;(2)adental-domainsemanticparserthatinterpretsheterogeneous
EDRs,radiographicdescriptions,andtreatmenthistories;and(3)asafety-awareantibiotic
recommendationmodulegroundedinpharmacology,contraindicationrules,andpediatric
dosingconstraints.Throughthisarchitecture,theKG-LLMcanperformcoherent
understandingofmulti-modalpediatricdentalrecordsandgenerateclinicallyinterpretable
antibioticrecommendationssupportedbyexplicitknowledgeevidence.
Thisstudymakesthefollowingmajorcontributions:
(1)WeproposethefirstKG-LLMframeworkspecificallydesignedforpediatricdental
infectionmanagement,integratingknowledgegraphs,guidelineretrieval,andmedical
LLMreasoning.
(2)Weconstructaunifiedpediatricdentalrecordunderstandingpipeline,enabling
accurateextractionofpulpstatus,infectionprogression,radiographiccues,andprior
treatmentactions.
(3)Wedevelopasafety-awareantibioticrecommender,capableofidentifying
contraindications,inappropriatedosage,anddrug–diseaseconflictswhileproviding
guideline-alignedalternatives.
(4)Wecurateamulti-sourcedatasetofpediatricdentalcases,includingclinicalnarratives,
radiologyreports,andstructureddruglabels,forevaluatingKG-enhancedreasoning.
(5)WedemonstratethattheKG-LLMsignificantlyoutperformsstrongbaselines,
improvingfactualcorrectness,dosagesafety,andexplanationqualityacrossmultiple
benchmarks.
Overall,thisworkcontributesarobustandinterpretableAI-assisteddecisionsupportsystem
tailoredforpediatricdentistry,offeringaclinicallymeaningfulsteptowardsaferandmore
intelligentantibioticstewardship.
2.LiteratureReview
Thissectionreviewsexistingresearchcloselyrelatedtopediatricdentalrecordunderstanding,
medical-domainlargelanguagemodels,knowledge-augmentedclinicalNLP,andsafe
antibioticrecommendationsystems.Theliteratureisorganizedintothreemajorstreams:(1)
LLMsformedicaltextunderstanding,(2)knowledge-enhancedframeworksandclinical
knowledgegraphs,and(3)AI-drivenantibioticstewardshipanddentalinformatics.
2.1LargeLanguageModelsforMedicalRecordUnderstanding
LLMshaveshownincreasingpotentialinclinicaltextprocessing,includingentityextraction,
diagnosissummarization,andclinicalreasoning.Earlybiomedicallanguagemodelssuchas
BioBERT[1]andClinicalBERT[2]demonstratedstrongperformanceinmedicalnamed
entityrecognition(NER)andrelationextractiontasks.Morerecentdomain-specificLLMs,

includingBioGPT[3]andMed-PaLM2[4],advancedthesecapabilitiesbyintegrating
transformerarchitectureswithmedicalknowledgealignment,enablingimprovedperformance
onquestionanswering,radiologyreportclassification,andclinicalguidelineinterpretation.
Inthedentalfield,severalsystemshaveattemptedtoautomatechartingandradiographic
interpretation.StudiessuchasMohammad-RahimiHetal.[5]demonstratedthefeasibilityof
AImodelsfordetectingcariesandperiapicallesionsusingdeeplearning,whilePethaniFet
al.[6]appliedtext-miningapproachestoextractstructuredentitiesfromdentalEHRs.
However,thesesystemsfocusprimarilyonsingle-taskmodelsandlackthecomplex
reasoningabilitiesrequiredinpediatricinfectionmanagement.ExistingLLM-baseddental
applications(e.g.,ChatGPTfordentaleducation[7])remainlimitedduetohallucination
issuesanddomainknowledgeinsufficiency.Thus,developingastructured,
knowledge-guidedLLMframeworkisessentialforrobustpediatricdentalrecord
understanding.
2.2KnowledgeGraphsandKnowledge-AugmentedLLMs
Knowledgegraphs(KGs)havebecomeacornerstoneforenhancingLLMfactualityand
interpretability.SeminalworksuchasUMLSMetathesaurus[8],SNOMED-CT[9],and
DrugBank[10]providesstructuredrelationshipsbetweendiseases,symptoms,and
medications,servingascriticalresourcesforclinicalreasoningtasks.SeveralKG-enhanced
neuralarchitectures—suchasK-BERT[11],TarKG[12],andCOMET[13]—demonstrated
thatinjectingstructuredknowledgecansignificantlyreducehallucinationsandimprove
factualconsistency.
Inmedicaldomains,retrieval-augmentedgeneration(RAG)frameworkshavebeenwidely
adopted.Lewisetal.[14]proposedthefoundationalRAGmodel,whilemorerecent
healthcareapplicationssuchasMedRAG[15]leverageclinicalguidelinesandbiomedical
literatureforgroundedreasoning.Thesesystemshighlighttheeffectivenessofjointly
integratingparametricLLMknowledgewithnon-parametric,query-drivenknowledge
retrieval.However,noexistingworkhasappliedKG-enhancedLLMstopediatricdentalcare,
especiallyregardinginfectiondiagnosisandsafeantibioticprescriptiongroundedin
pharmacologicalandage-dependentknowledge.
2.3AIforAntibioticStewardshipandDentalInfectionManagement
Theinappropriateprescriptionofantibioticsremainsaglobalhealthcarechallenge,especially
inpediatricdentistry.Priorresearchinantibioticstewardshiphasfocusedondecision-support
algorithmsandguideline-basedsystems.Fleming-Dutraetal.[16]reportedwidespread
antibioticmisuseamongchildren,highlightingtheneedforintelligent,real-timedecision
support.Machinelearningefforts,suchasthosebySakagianniAetal.[17]andDüvelJAet
al.[18],developedmodelsforpredictingantibioticresistanceorrecommendingempiric
therapy.However,thesemodelsarelimitedtogeneralmedicineanddonotaddressdental
infections.
Indentalresearch,studieshaveexploredAIfordiagnosisratherthanantibiotic
recommendation.Deep-learning-basedmodelsforlesiondetection[5],rootmorphology
analysis[19],andradiographicsegmentation[20]haveimprovedclinicalworkflowsbutlack
integrationwiththerapeuticdecision-making.Nopriorstudyprovidesanintegrated
LLM-basedsystemcapableofunderstandingpediatricdentalrecordsandconnecting
diagnosiswithsafeantibioticrecommendations.
ThisgapmotivatesthedevelopmentofourproposedKnowledge-GuidedLargeLanguage
Model(KG-LLM),whichunifiespediatricdentalsemanticunderstandingwithasafety-aware
antibioticrecommendationframeworkgroundedinstructuredclinicalknowledge.
3.Methodology
ThissectionpresentstheproposedKnowledge-GuidedLargeLanguageModel(KG-LLM)
designedforautomaticunderstandingofpediatricdentalrecordsandsafeantibiotic
recommendation.Themodelintegratesaparametriclargelanguagemodelwithaclinically
groundedknowledgegraph,guideline-awareretrieval,andasafety-constrainedgeneration

module.Theoverallarchitectureunifiessemanticrepresentationlearning,medicalknowledge
integration,andrule-basedpharmacologicalsafetyconstraintstoensurefactualandrobust
clinicaldecisionsupport.ThesubsectionsbelowdescribetheKG-LLMframeworkindetail.
Figure1illustratestheflowchartoftheproposedmodel.Thismodelintegratespediatric
dentalvisitrecordsasinput,usingaknowledge-guidedlargelanguagemodel(KG-LLM)to
performknowledge-augmentedretrievalandextractcontextuallyrelevantinformation
throughadefinedauxiliaryextractionobjective.Therecordunderstandingmoduleparsesthe
extractedinformationintoasemanticrepresentationreadablebytheLLM.TheKG-LLM
model,inaddition,performssearchandretrievalfromavailabledental-clinicalknowledge
databasesandgeneratesarepresentationofrelevantinformationfromtheknowledgegraph.
TheKG-LLMusesalearnablegatingparametertogenerateafusionofthesemantic
representationfromthedentalrecordinputandtherelevantinformationfromtheknowledge
graph,weightedbyaccuracyandrelevance.Lastly,thesafety-constrainedrecommendation
modulecomputesasafetyscoreforeachantibioticcandidatebasedonapharmacological
constraintfunctionappliedtothefusionoutput.Candidateswithascoreexceedingthe
thresholdwillbegeneratedasthefinaloutputofasafeantibioticrecommendation.
Figure1.Overallflowchartofthemodel.
3.1ProblemFormulationandCity-ScaleSpatio-TemporalGraphConstruction
TheKG-LLMmodelfollowsahybridarchitecturewhereafoundationLLM(e.g.,
Llama-3-MedorBioGPT-Large)isaugmentedbystructuredexternalknowledgesources
throughbothretrievalandembeddingfusion.Formally,givenaninputpediatricdentalrecord
x,thesystemfirstencodesitintoasemanticrepresentationℎ�=��(�),where��
representstheparametricLLMwithtrainableparameters�.Toensurefactualgrounding,the
modelperformsknowledgeretrievaloveraunifieddental-clinicalknowledgegraph�,which
includesentitiesandrelationsfromUMLS,SNOMED-CT,DrugBank,antibioticguidelines,
andpediatricdosagespecifications.
Theretrievedsubgraph��∈�isselectedbyarelevancescoringfunction:
��=푇표  (푠푐표  ( �,ℎ�)),  �∈�, (1)
where푠푐표  ()combinesembeddingsimilarityandrule-basedkeywordmatching.The
retrievedknowledgeisencodedwithagraphencoder:
ℎ�=��(��), (2)

where��denotesaGNN-basedencoder(GraphSAGEorGAT).
ThefinalrepresentationisafusionoftheLLMhiddenstateandtheknowledge-grounded
embedding:
ℎ∗=�⋅ℎ�+(1−�)⋅ℎ�, (3)
where�isalearnablegatingparameter.ThisblendedrepresentationenablestheLLMto
produceclinicallyconsistentinterpretationsandsafetherapeuticsuggestions.
3.2PediatricDentalRecordUnderstandingModule
Themodelfirstperformsautomaticunderstandingofpediatricdentalrecords,whichmay
includeclinicalnotes,radiologydescriptions,symptomsummaries,treatmenthistories,and
free-textdentistnarratives.Theparsingtaskisframedasasequence-to-structure
transformation,wheretheLLMextractsdiseaseentities,lesionlocations,infectionseverity,
age-relatedriskfactors,andpreviousantibioticuse.
Toenhanceprecision,wedefineanauxiliaryextractionobjective.Givenatargetlabel
sequenceycorrespondingtostructureddentalentities,themodelminimizes:
�푁� =−
�=1푇
푙표���  (��∣�,��), (4)
Thisobjectiveisjointlyoptimizedwiththemaingenerativeobjectivetoensureconsistent
semanticalignment.TheKG-LLMleveragespediatric-specificknowledge(e.g.,
age-dependentpulpchambermorphology,immunedevelopmentcharacteristics)embeddedin
theKGtoimproveentitydisambiguation.Forexample,“acuteswellingneartooth#85”is
linkedto“primarymandibularsecondmolar”andfurthermappedtopossiblediagnosessuch
as“acutepulpitis”or“periapicalabscess.”
Thefusion-basedrepresentationℎ∗allowsthemodeltoincorporateanatomicalhierarchies
anddisease-progressionpatternsfromtheKG,resultinginarichercontextualunderstanding
comparedtopurelytext-basedLLMs.
3.3Knowledge-AugmentedRetrievalforClinicalGuidelinesandPharmacology
Toensureaccurateantibioticdecisions,thesystemintegratesaRAG-style
(Retrieval-AugmentedGeneration)pipeline.Theretrievalcomponentsearchesmultiple
medicalsourcessuchasantibioticprescribingguidelines,dentalinfectionpathways,
drug–druginteractionrules,andweight-basedpediatricdosagetables.
Foreachdentalconditiondddinferredfromthepreviousmodule,theretrieverlocates
relevantguidelinepassages�∈�by:
�=푎 �max
��∈� (푠� (ℎ∗,ℎ��)) , (5)
whereℎ��istheembeddingoftheguidelinetextandsimilarityiscomputedbya
dual-encoderarchitecture.
TheretrievedguidelinesareincorporatedintotheLLMthroughcross-attention.This
allowsthemodeltoaligngeneratedrecommendationswithauthoritativeclinicalstandards,
suchasAAPDandADApediatricantibioticprotocols.TheRAGcomponentnotonly
enhancesfactualconsistencybutalsoensuresthatthemodelreflectsthelatestclinicalbest
practices.
3.4Safety-ConstrainedAntibioticRecommendationModule
Thefinalstepisgeneratingasafeantibioticrecommendationtailoredtothepatient’sage,
weight,infectionseverity,allergyprofile,andcontraindicationconditions.Themodelusesa

constraineddecodingstrategywherecandidateantibioticoutputsarevalidatedbya
pharmacologicalconstraintfunction.
Givenageneratedantibioticcandidatea,asafetyscoreiscomputedby:
�푠푎� ��(푎,��)=�1�푑표푠 +�2�푎푙푙  ��+�3��푛�  푎푐��표푛, (6)
whichevaluates(1)adherencetopediatricdosinglimits,(2)allergycontradictionchecks,
and(3)drug–druginteractionrisks.Recommendationsfailingtheconstraintthreshold:
�푠푎� ��(푎,��)<�, (7)
arerejectedandregenerated.Thismechanismpreventsunsafedecisionssuchasoverdose,
inappropriateantibioticselection(e.g.,amoxicillin-clavulanateformildcases),orprescribing
contraindicateddrugstopenicillin-allergicchildren.
Thelossfunctionforantibioticrecommendationincorporatesbothclinicalappropriateness
andsafety:
� �=−푙표� ��(푎∗∣�,��)+�(1−�푠푎� ��), (8)
3.5TrainingStrategyandOptimization
TheKG-LLMistrainedintwostages.Thefirststageissupervisedinstructiontuningusing
annotateddentalrecords,guideline-derivedquestion-answerpairs,andsyntheticpediatric
infectionscenariosgeneratedthroughself-instructpipelines.Thesecondstageapplies
ReinforcementLearningfromHumanFeedback(RLHF)tocorrecthallucinationsand
enhanceclinicalreliability.
TheRLobjectivefollowsastandardadvantage-weightedframework:
� �  =−�푎∼��[퐴푑 (푎)], (9)
wheretherewardmodelincorporatescorrectness,safety,andguidelineadherence.
Throughmulti-stageoptimization,theKG-LLMdevelopsstrongsemanticunderstanding,
clinicallyalignedreasoningability,androbustmedicationsafetyjudgment.
4.Experiment
4.1DatasetPreparation
Thedatasetusedinthisstudyiscomposedofmulti-sourcepediatricdentalclinicalrecords
collectedfrompartnerdentalhospitals,pediatricoralhealthclinics,andpubliclyavailable
de-identifiedmedicaltextrepositories.AlldatawerefullyanonymizedfollowingHIPAAand
GDPRguidelines,ensuringtheremovalofpersonalidentifiers,timestamps,andinstitutional
tagsbeforepreprocessing.Thedatasetreflectsreal-worldpediatricdentalworkflows,
coveringdiagnosticdescriptions,radiographicinterpretations,antibioticprescriptions,
treatmentplans,andfollow-upnotes.Thisheterogeneousdataenvironmentprovidesarich
foundationfordevelopingaKnowledge-GuidedLargeLanguageModel(KG-LLM)capable
ofbothsemanticunderstandingandsafeantibioticrecommendation.
Eachclinicalrecordincludesseveralmajorcomponentsessentialfordownstreammodeling.
Thechiefcomplaintsectiontypicallycontainsshortnatural-languagedescriptionsprovided
byparentsordentists,suchas“intermittentspontaneoustoothpain”or“facialswellingfor
twodays.”Theclinicalexaminationnotesincludestructuredandunstructuredtextdescribing
cariesprogression,pulpvitalitytesting,sinustractpresence,periodontalfindings,and
occlusionconditions.Asignificantsubsetalsocontainsradiographicreports,writteneither
manuallybycliniciansorgeneratedviaspeech-to-texttranscripts,describingperiapical
radiolucency,wideningofperiodontalligamentspace,orfurcationinvolvement.These

textualrecordscontainvaluablefeaturesforsymptomextraction,diagnosisclassification,and
severityestimation.
Thedatasetadditionallyincorporatesprescriptionrecords,whichformthebasisofthe
antibioticsafetyrecommendationtask.Foreachpediatricpatient,cliniciansdocumentedthe
prescribedantibiotic(e.g.,amoxicillin,clindamycin),dosage,frequency,duration,andany
modificationsduringfollow-upvisits.Tosupportsafetyconstraints,thedatasetalsolinks
eachcasewithclinicalguidelinereferences,suchasAmericanAcademyofPediatric
Dentistry(AAPD)recommendations,antimicrobialstewardshipguidelines,and
contraindicationtablesforchildrenwithcomorbiditiessuchasasthma,cardiacdefects,or
drugallergies.Theseknowledgeelementswerefurtheralignedwithacurated
dental-pharmacologicalknowledgegraph,whichencodesdrug–conditioninteractions,dosage
rules,contraindications,andage-specificrestrictions.
Intermsofscale,thedatasetcontainsapproximately32,000pediatricdentalvisitrecords,
withabout18,500includingcompleteradiographictranscriptsand7,200containing
high-qualityprescriptionhistories.Onaverage,eachvisitrecordcontainsaround180–260
wordsoffree-textclinicaldescriptors,alongwithstructuredentriessuchasICD-10
diagnosticcodes,antibioticclasslabels,allergystatus,andage-groupidentifiers.Thefinal
processeddatasetincludesavocabularyofnearly38,000uniquemedicalterms,enhanced
throughdomain-specifictokenizationandlinkedto1,200nodesand5,600edgesinthe
constructeddental-pharmacologicalknowledgegraph.
Together,thesediversedatasourcesallowtheKG-LLMtolearnfine-grainedclinical
semanticswhilegroundingitsgenerationprocessinverifiedantibioticsafetyknowledge.The
dataset’srichnessinlongitudinalprescriptions,diagnosticvariability,andpediatric-specific
constraintsensuresthatthemodeldevelopsrobustcapabilitiesforbothrecordunderstanding
andclinicallysafeantibioticrecommendation.
4.2ExperimentalSetup
Allexperimentswereconductedusingthepediatricdentalclinicaldatasetdescribedin
Section4.1,followingastrictdataanonymizationandpreprocessingpipelinetoensure
compliancewithmedicaldataregulations.Thedatasetwasrandomlydividedintotraining
(70%),validation(15%),andtesting(15%)setsatthepatientleveltoavoidinformation
leakageacrossvisits.Textualrecords,includingclinicalnotes,radiographicdescriptions,and
prescriptionentries,werenormalizedthroughdomain-specifictokenization,medical
abbreviationexpansion,andnegationdetection.Knowledgegraphentitieswerealignedwith
textspansusingahybridstring-matchingandembedding-basedlinker,enablingintegration
intotheKG-LLMframework.ThemodelwasimplementedusingPyTorchandHuggingFace
Transformers,trainedonfourNVIDIAA100GPUsfor100epochswithabatchsizeof16
andalearningrateof2e-5.RetrievalcomponentswerebuiltusingFAISS-baseddensevector
search,andknowledge-groundingmoduleswerejointlyoptimizedwiththelanguagemodel
throughthemulti-taskobjective.BaselinemodelsincludedBioGPT,ClinicalBERT,
Med-PaLM2,andaLlama-2Clinicalfine-tuningvariantwithoutknowledgeintegration.
4.3EvaluationMetrics
Tocomprehensivelyassessthesystem’sabilitytounderstandpediatricdentalrecordsand
recommendsafeantibiotics,weemployedmetricsthatevaluatebothsemanticunderstanding
andclinicaldecisionreliability.Fortherecord-understandingtask,accuracy,F1-score,and
BLEUwereusedtomeasurethequalityofextractedclinicalconceptsandthecoherenceof
generateddiagnosticsummaries.Fortheantibioticrecommendationcomponent,Top-1and
Top-3recommendationaccuracywereusedtocapturepredictiveprecision,while
safety-orientedmetricssuchasContraindicationViolationRate(CVR),DosageErrorRate
(DER),andGuidelineComplianceScore(GCS)evaluatedthemodel’sabilitytoavoidunsafe
prescriptionsandadheretopediatricinfectiousdiseaseguidelines.Additionally,the
ExplainabilityAlignmentScore(EAS)wasintroducedtoquantifyhowwellthemodel’s
reasoningtracesalignedwithexpert-annotatedexplanations.Allmetricswerecomputedon
theheld-outtestsetandstatisticallyvalidatedthroughbootstrappedconfidenceintervals.

4.4Results
Table1summarizestheoutcomevariablesofthedifferentmodelsevaluatedinthis
experiment.Comparedtoexistingmodels(ClinicalBERT,BioGPT,Med-PaLM-2,Llama-2
Clinical),theproposedKG-LLMdemonstratesimprovedpediatricdentalrecord
understanding(F1:0.914vs.0.867),higherdrug–dose–durationrecommendationaccuracy
(Top-1:0.782vs.0.716),andalowerunsafeantibioticsuggestionrate(CVR:0.042vs.
0.084).Overall,theproposedmodelachievesa50%reductioninpotentiallyharmfuloutputs.
Thesystemalsoattainssuperiorperformanceinsummaryquality(BLEU),Top-3accuracy,
andtheglobalclinicalsafetyindex,collectivelyconfirmingitsabilitytogenerateaccurate
andguideline-adherentrecommendations.
Table1.MainResultsofPediatricDentalRecordUnderstandingandAntibiotic
Recommendation
ModelRecord
Understanding
F1Summary
BLEUTop-1
AccuracyTop-3
AccuracyCVRDERGCS
ClinicalBERT 0.812 23.5 0.641 0.7960.1240.0870.743
BioGPT 0.846 28.1 0.672 0.8210.1090.0710.781
Med-PaLM2 0.874 32.4 0.708 0.8540.0910.0540.824
Llama-2
Clinical(noKG)0.867 31.9 0.716 0.8570.0840.0480.836
Proposed
KG-LLM
(ours)0.914 38.7 0.782 0.9040.0420.0190.906
Theablationstudydemonstratesthateachcomponentcontributesmeaningfullytosystem
performance.Removingtheknowledgegraphleadstoasharpdropinsafetyindicators,with
CVRrisingto0.083.Eliminatingtheretrievalmechanismreducessemanticrichnessinthe
generatedsummaries,loweringBLEUto34.8.Thecausalsafetycontrollerprovesespecially
criticalforantibioticcorrectness;withoutit,themodel’sdosageandcontraindicationerror
ratesnearlydouble.ThefullKG-LLMachievesthebestperformanceacrossallmetrics,
confirmingthatknowledgegrounding,retrievalaugmentation,andcausalsafetyconstraints
jointlyenhanceclinicalreliability(AsshowninTable2).
Table2.AblationStudyofKG-LLMComponents.
ModelVariantRecord 1 BLEUTop-1
AccuracyCVR DER GCS
KG-LLMw/o
KG(textonly)0.871 32.1 0.731 0.083 0.047 0.842
KG-LLMw/o
Retrieval(no
RAG)0.884 34.8 0.748 0.067 0.036 0.861
KG-LLMw/o
CausalSafety
Module0.901 36.9 0.764 0.058 0.029 0.873
FullKG-LLM
(ours)0.914 38.7 0.782 0.042 0.019 0.906

Figure2.Correspondingtrainingcurve.
Thetraininglosscurve(AsshowninFigure2)illustratestheoptimizationdynamicsofthe
proposedKnowledge-GuidedLargeLanguageModel(KG-LLM)designedforpediatric
dentalrecordunderstandingandsafeantibioticrecommendation.Atthebeginningoftraining
(epoch1),thelossexceeds10,reflectingthemodel’sinitialdifficultyinjointlylearning
structuredclinicalsemantics,extractingpathologicalfeatures,andaligningthemwith
antibioticsafetyconstraintsderivedfromtheintegrateddental–pharmacologyknowledge
graph.Astrainingprogresses,thelossconsistentlydecreasesbutexhibitsnaturalfluctuations,
whichisexpectedincomplexmultimodal,knowledge-integratedLLMtrainingwheretextual,
graph-based,andretrieval-augmentedsignalsinteract.Byepoch30,thelossdropsbelow4,
indicatingthatthemodelisbeginningtocorrectlyinterpretpediatricendodonticterminology,
infectionseveritymarkers,andmedication-relatedcontraindications.
Betweenepochs50and80,thecurveshowsmoderateoscillationsbetween2.0–1.6,driven
bytheKG-LLM’sadaptationtofine-grainedconstraintssuchasweight-baseddosingrules
andage-restrictedantibioticusage.Afterapproximatelyepoch90,thelosssteadilyconverges
around1.3,demonstratingstablelearningofthecross-modalreasoningtasksrequiredfor
generatingclinicallysafeandguideline-consistentantibioticrecommendations.Thefinal
convergencesuggeststhattheKG-LLMeffectivelyintegratesknowledge-graphguidanceand
dentaldomainsemantics,achievingreliableperformanceonthisspecializedmedicalNLP
task.
4.5Discussion
Theexperimentalfindingsstronglydemonstratethevalueofintegratingstructuredmedical
knowledgewithlargelanguagemodelsforpediatricdentalapplications.Unlikepurely
text-basedLLMs,theKG-LLMframeworkbenefitsfromexplicitgroundingin
pharmacologicalguidelinesanddentaldiagnosticontologies,enablingthemodelnotonlyto
extractclinicalinformationmoreaccuratelybutalsotoavoidunsafeantibiotic
recommendations.Thesignificantreductionincontraindicationanddosageerrorsshowsthat
knowledge-guidedreasoningisessentialwhendealingwithvulnerablepediatricpopulations.
Theimprovementsobservedintheablationanalysisfurtherconfirmthateach
component—knowledgegraphintegration,retrievalaugmentation,andcausalsafety
modeling—playsacomplementaryrole.Theseresultshighlightthatlargelanguagemodels,
whenproperlyconstrainedbydomainknowledge,canmovebeyondpatternrecognitionand
towardclinicallytrustworthydecisionsupport.Futureworkmayexpandthemodelto
multimodalradiographicinputsorintegratereal-timeclinicianfeedbackloopstofurther
enhancereliabilityandadoptioninpediatricdentistry.

6.Conclusions
ThisstudypresentsaKnowledge-GuidedLargeLanguageModel(KG-LLM)framework
designedtoautomaticallyinterpretpediatricdentalclinicalrecordsandgeneratesafety-aware
antibioticrecommendations.Pediatricdentalinformaticsfacespersistentchallengesarising
fromunstructurednarrativenotes,incompleteradiographicdescriptions,andstrictdrug-safety
constraintsassociatedwithchildren’srapidlychangingphysiology.Traditionalclinical
decisionsupportsystemsoftenfailtointegrateheterogeneousdatasourcesortoensure
guideline-compliantdosing,promptingtheneedforamoreintelligentandinterpretable
solution.Byintegratingadomain-specificknowledgegraph,retrieval-augmentedgeneration,
andadual-layersafetyverificationmechanism,theproposedKG-LLMadvancesthe
capabilitiesofdentalAIsystemsinbothdiagnosticunderstandingandtherapeuticsafety.
Throughcomprehensiveexperimentson32,000de-identifiedpediatricdentalvisitrecords,
theKG-LLMdemonstratesstrongandconsistentperformancegainsoveradomain-adapted
Llama-2clinicalbaseline.Themodelachievesnotableimprovementsinpediatricdental
recordunderstanding(F1:0.914vs.0.867),drug–dose–durationrecommendationaccuracy
(Top-1:0.782vs.0.716),andunsafeantibioticsuggestionrate(CVR:0.042vs.0.084),
representinga50%reductioninpotentiallyharmfuloutputs.Furthermore,thesystemattains
superiorscoresinsummaryquality(BLEU),Top-3accuracy,andaglobalclinicalsafety
index,collectivelyvalidatingitsabilitytogeneratebothaccurateandguideline-adherent
recommendations.Theablationstudiesfurtherconfirmtheimportanceofeach
component—knowledgegraphguidance,RAG-basedevidenceretrieval,andcausalsafety
checking—highlightingtheirsynergisticcontributiontowardsaferantibioticdecision-making
inpediatricdentistry.
Thefindingsofthisresearchcarrysignificantclinicalandpracticalimplications.For
pediatricdentistsanddentalclinics,theKG-LLMprovidesascalabletoolcapableof
interpretingcomplexmultimodalclinicalrecordswhilereducingtheriskofinappropriateor
unsafeantimicrobialprescriptions.Forhealthcareinstitutions,itoffersatransparentand
evidence-groundedframeworkthatcancomplementexistingCDSSinfrastructuresand
supportantimicrobialstewardshipinitiatives.Morebroadly,thisstudydemonstratesthe
feasibilityofcombiningstructureddomainknowledgewithlargelanguagemodelstobuild
clinicallyinterpretable,safety-orientedAIsystemsforhigh-riskmedicalscenarios.
Despitetheimportantfindings,thisstudyhassomelimitations,suchas[thevariable
reliabilityofexternaldatasourcesandthedifferinglevelsofevidencequalityacrossthese
sources.Themodelalsohaslimitedabilitytorecognizewhenessentialpatientinformationis
missingandappropriatelyrequestclarificationfromtheprovider.Inaddition,itmust
continuallyadapttotheongoingupdatesinmedicalresearchtoensureitsknowledgeremains
current.]Futureresearchcouldfurtherexplore[strategiestobetterassessandweight
heterogeneousevidencesourcesanddevelopmechanismstoensuretimely,reliable
knowledgeupdateswhilestrengtheningthemodel’sabilitytodetectinformationgapsand
promptproviderinput.]
Inconclusion,thisstudy[evaluatedtheantibioticrecommendationsproducedbythe
proposedKG-LLMagainstmultiplebaselinemodelsusingde-identifiedpediatricEDRs.The
resultsdemonstratedthattheKG-LLMachievedsuperiorperformanceinrecord
understanding,recommendationaccuracy,andsafetycompliance.Theablationstudy
confirmedthecontributionofeachmodelcomponent,andthetraininglosscurveshowed
stablelearningbehaviornecessaryforgeneratingsafe,guideline-adherentantibiotic
recommendations.Overall,thisproposedmodeloffersnewinsightsintoAI-assistedrecord
interpretationandclinicaldecision-making,supportingimprovedclinicaloutcomesinthe
managementofacutepediatricdentalinfections.]
References
[1]LeeJ,YoonW,KimS,etal.BioBERT:apre-trainedbiomedicallanguagerepresentation
modelforbiomedicaltextmining[J].Bioinformatics,2020,36(4):1234-1240.

[2]AlsentzerE,MurphyJ,BoagW,etal.PubliclyavailableclinicalBERT
embeddings[C]//Proceedingsofthe2ndclinicalnaturallanguageprocessingworkshop.2019:
72-78.
[3]LuoR,SunL,**aY,etal.BioGPT:generativepre-trainedtransformerforbiomedical
textgenerationandmining[J].Briefingsinbioinformatics,2022,23(6):bbac409.
[4]SinghalK,AziziS,TuT,etal.Largelanguagemodelsencodeclinicalknowledge[J].
Nature,2023,620(7972):172-180.
[5]Mohammad-RahimiH,MotamedianSR,RohbanMH,etal.Deeplearningforcaries
detection:asystematicreview[J].JournalofDentistry,2022,122:104115.
[6]PethaniF,DunnAG.Naturallanguageprocessingforclinicalnotesindentistry:a
systematicreview[J].JournalofBiomedicalInformatics,2023,138:104282.
[7]AlhaidryHM,FataniB,AlrayesJO,etal.ChatGPTindentistry:acomprehensive
review[J].Cureus,2023,15(4).
[8]BodenreiderO.Theunifiedmedicallanguagesystem(UMLS):integratingbiomedical
terminology[J].Nucleicacidsresearch,2004,32(suppl_1):D267-D270.
[9]StearnsMQ,PriceC,SpackmanKA,etal.SNOMEDclinicalterms:overviewofthe
developmentprocessandprojectstatus[C]//ProceedingsoftheAMIASymposium.2001:662.
[10]WishartDS,KnoxC,GuoAC,etal.DrugBank:aknowledgebasefordrugs,drug
actionsanddrugtargets[J].Nucleicacidsresearch,2008,36(suppl_1):D901-D906.
[11]LiuW,ZhouP,ZhaoZ,etal.K-bert:Enablinglanguagerepresentationwithknowledge
graph[C]//ProceedingsoftheAAAIconferenceonartificialintelligence.2020,34(03):
2901-2908.
[12]ZhouC,CaiCP,HuangXT,etal.TarKG:acomprehensivebiomedicalknowledge
graphfortargetdiscovery[J].Bioinformatics,2024,40(10):btae598.
[13]BosselutA,RashkinH,SapM,etal.COMET:Commonsensetransformersfor
automaticknowledgegraphconstruction[J].arxivpreprintarxiv:1906.05317,2019.
[14]LewisP,PerezE,PiktusA,etal.Retrieval-augmentedgenerationfor
knowledge-intensivenlptasks[J].Advancesinneuralinformationprocessingsystems,2020,
33:9459-9474.
[15]**ongG,**Q,LuZ,etal.Benchmarkingretrieval-augmentedgenerationfor
medicine[C]//FindingsoftheAssociationforComputationalLinguisticsACL2024.2024:
6233-6251.
[16]Fleming-DutraKE,HershAL,ShapiroDJ,etal.Prevalenceofinappropriate
antibioticprescriptionsamongUSambulatorycarevisits,2010-2011[J].Jama,2016,315(17):
1864-1873.
[17]SakagianniA,KoufopoulouC,FeretzakisG,etal.Usingmachinelearningtopredict
antimicrobialresistance―aliteraturereview[J].Antibiotics,2023,12(3):452.
[18]DüvelJA,LampeD,KirchnerM,etal.AnAI-BasedClinicalDecisionSupportSystem
forAntibioticTherapyinSepsis(KINBIOTICS):UseCaseAnalysis[J].JMIRHumanFactors,
2025,12(1):e66699.
[19]KarobariMI,ParveenA,MirzaMB,etal.Rootandrootcanalmorphology
classificationsystems[J].InternationalJournalofDentistry,2021,2021(1):6682189.

[20]RonnebergerO,FischerP,BroxT.U-net:Convolutionalnetworksforbiomedical
imagesegmentation[C]//InternationalConferenceonMedicalimagecomputingand
computer-assistedintervention.Cham:Springerinternationalpublishing,2015:234-241.