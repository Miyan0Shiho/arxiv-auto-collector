# Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting

**Authors**: Deniz Gorur, Antoni Rago, Francesca Toni

**Published**: 2025-10-28 11:12:43

**PDF URL**: [http://arxiv.org/pdf/2510.24303v1](http://arxiv.org/pdf/2510.24303v1)

## Abstract
Judgmental forecasting is the task of making predictions about future events
based on human judgment. This task can be seen as a form of claim verification,
where the claim corresponds to a future event and the task is to assess the
plausibility of that event. In this paper, we propose a novel multi-agent
framework for claim verification, whereby different agents may disagree on
claim veracity and bring specific evidence for and against the claims,
represented as quantitative bipolar argumentation frameworks (QBAFs). We then
instantiate the framework for supporting claim verification, with a variety of
agents realised with Large Language Models (LLMs): (1) ArgLLM agents, an
existing approach for claim verification that generates and evaluates QBAFs;
(2) RbAM agents, whereby LLM-empowered Relation-based Argument Mining (RbAM)
from external sources is used to generate QBAFs; (3) RAG-ArgLLM agents,
extending ArgLLM agents with a form of Retrieval-Augmented Generation (RAG) of
arguments from external sources. Finally, we conduct experiments with two
standard judgmental forecasting datasets, with instances of our framework with
two or three agents, empowered by six different base LLMs. We observe that
combining evidence from agents can improve forecasting accuracy, especially in
the case of three agents, while providing an explainable combination of
evidence for claim verification.

## Full Text


<!-- PDF content starts -->

Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental
Forecasting
Deniz Gorur1,Antonio Rago1,2,Francesca Toni1
1Department of Computing, Imperial College London, UK
2Department of Informatics, Kingâ€™s College London, UK
{d.gorur22,a.rago,ft}@imperial.ac.uk
Abstract
Judgmental forecasting is the task of making pre-
dictions about future events based on human judg-
ment. This task can be seen as a form of claim
verification, where the claim corresponds to a fu-
ture event and the task is to assess the plausi-
bility of that event. In this paper, we propose a
novel multi-agent framework for claim verification,
whereby different agents may disagree on claim
veracity and bring specific evidence for and against
the claims, represented as quantitative bipolar ar-
gumentation frameworks (QBAFs). We then in-
stantiate the framework for supporting claim ver-
ification, with a variety of agents realised with
Large Language Models (LLMs): (1) ArgLLM agents,
an existing approach for claim verification that
generates and evaluates QBAFs; (2) RbAM agents,
whereby LLM-empowered Relation-based Argu-
ment Mining (RbAM) from external sources is used
to generate QBAFs; (3) RAG-ArgLLM agents, ex-
tending ArgLLM agents with a form of Retrieval-
Augmented Generation (RAG) of arguments from
external sources. Finally, we conduct experiments
with two standard judgmental forecasting datasets,
with instances of our framework with two or three
agents, empowered by six different base LLMs. We
observe that combining evidence from agents can
improve forecasting accuracy, especially in the case
of three agents, while providing an explainable com-
bination of evidence for claim verification.
1 Introduction
Judgmental forecasting is the task of making predictions
about future events by reasoning over incomplete, uncer-
tain, and often conflicting information Lawrenceet al.[2006];
Zellneret al.[2021]. This task can be seen as a form of claim
verification, where a future outcome is seen as a claim and the
task is to assess the plausibility of that outcome. The claim
verification task involves determining whether a given claim
is supported or refuted, often requiring the assessment of
conflicting evidence. This evidence for verifying forecasting
claims could be, for example, generated by LLMs Geet al.
[2025]; Zhenget al.[2025]; Dmonteet al.[2024] or obtainedfrom other repositories. However, despite LLMsâ€™ remarkable
capabilities across a range of tasks, they fall short here due to
the fact that they may hallucinate or provide logically incon-
sistent outputs, and they cannot faithfully explain or allow for
the contestation of their own outputs Freedmanet al.[2025].
For example, claims about future events may require up to
date knowledge that a single LLM lacks, due to its incomplete
training data, leading to unreliable or conflicting predictions
Yueet al.[2024]. One approach, which aims at targeting this
issue, uses Argumentative LLMs (ArgLLMs) Freedmanet al.
[2025], which leverage techniques from computational ar-
gumentation (see Atkinsonet al.[2017]; Baroniet al.[2018]
for overviews) to generate Quantitative Bipolar Argumenta-
tion Frameworks (QBAFs) that provide structured debates
on the claim to be verified. In doing so, ArgLLMs output a
transparent decision for the claims along with supporting and
attacking arguments acting as evidence. However, relying on
a single ArgLLM is limiting, as its output is constrained by
the knowledge and biases of its underlying LLM, potentially
omitting crucial evidence.
To overcome the limitations of a single-agent approach, we
propose a novel multi-agent framework for claim verification
that combines argumentative reasoning generated as QBAFs
from multiple, independent agents into a single, more robust
QBAF. As illustrated in Figure 1, ourMulti-Agent QBAF Com-
binatormodule aggregates the outputs from several agents
by measuring the semantic similarity Chandrasekaran and
Mago [2022] between arguments, merging similar views to
create a more robust framework.
To instantiate our Multi-Agent QBAF Combinator module
to support judgmental forecasting, we consider two novel
kinds of agents realised with LLMs, in addition to ArgLLM
agents. For these two novel kinds of agents, we leverage on
the widely acknowledged fact that the integration of Retrieval-
Augmented Generation (RAG) Zhaoet al.[2024] enhances
LLMs by incorporating external knowledge and solving issues
like hallucination Yueet al.[2024]; Geet al.[2025]. We use two
novel types of RAG-based agents: (1) using Relation-based
Argument Mining (RbAM) Goruret al.[2025b]; Carstens and
Toni [2015] to identify supporting, attacking, or neither re-
lations between retrieved evidence from sources and claims;
and (2) using the retrieved evidence from sources for gener-
ating supporting and attacking arguments, in the spirit of
ArgLLMs.
1arXiv:2510.24303v1  [cs.AI]  28 Oct 2025

Figure 1: The overall pipeline. The â€˜QBAF Generator Agentsâ€™ module can be instantiated with ArgLLM agents (baseline) or our two
RAG-based methods: Retrieval-Augmented ArgLLM agents and RbAM agents, both taking in input external sources. The â€˜Multi-Agent
QBAF Combinatorâ€™ module then takes the generated QBAFs (two in the figure, but our method applies to any number) and (1) calculates
similarity between arguments in the QBAFs, (2) combines similar arguments to obtain a single BAF Bâˆ—, and (3) aggregates the base scores of
the combined arguments to obtain base scoresğœâˆ—, leading to a combined QBAFQâˆ—.
Overall, our contributions, overviewed in Figure 1, are as
follows:
1.Multi-Agent QBAF Combinator: Introduction of a novel
method to combine multiple independently generated
QBAF outputs into a single QBAF.
2.RbAM Agent: Introduction of relation-based argument
mining to incorporate external evidence retrieved from
external sources, directly as arguments.
3.Retrieval-Augmented ArgLLM (RAG-ArgLLM) Agent: In-
troduction of an agent to augment ArgLLM prompting
with external evidence retrieved from external sources.
4.Extensive experiments on two judgmental forecasting
datasets (claims about forecasting events), demonstrat-
ing that our multi-agent framework, particularly with
three distinct agents, can improve forecasting accuracy
and provide a transparent framework for claim verifica-
tion in judgmental forecasting.
2 Preliminaries
ABipolar Argumentation Framework (BAF)Cayrol and
Lagasquie-Schiex [2005] is a triple âŸ¨X,A,SâŸ© , where: Xis a set
ofarguments; AâŠ†XÃ—X is a relationof attack; and SâŠ†XÃ—X
is a relation ofsupport, where AandSare disjoint ( Aâˆ©S=âˆ… ).
AQuantitative Bipolar Argumentation Framework (QBAF)Ba-
roniet al.[2019] is a tuple âŸ¨X,A,S,ğœâŸ© where: âŸ¨X,A,SâŸ© is
a BAF andğœâˆ¶Xâ†’[ 0,1]is a total function, with ğœ(ğ‘) the
base scoreof ğ‘âˆˆX . Arguments in QBAFs are then evaluated
usinggradual semantics, i.e. total functions often in the form
ğœâˆ¶Xâ†’[ 0,1], which assign astrengthto each argument. One
such semantics is theDiscontinuity-Free Quantitative Argu-
mentation Debate (DF-QuAD)Ragoet al.[2016], where for a
given QBAF âŸ¨X,A,S,ğœâŸ© , for anyğ‘¥âˆˆX withğ‘›â‰¥0attackers
with strengths ğ‘£1,...,ğ‘£ğ‘›,ğ‘šâ‰¥ 0supporters with strengths
ğ‘£â€²
1,...,ğ‘£â€²
ğ‘šandğœ(ğ‘¥)=ğ‘£ 0, DF-QuAD computes ğ‘¥â€™s strength
asğœ(ğ‘¥)=C(ğ‘£ 0,F(ğ‘£ 1,...,ğ‘£ğ‘›),F(ğ‘£â€²
1,...,ğ‘£â€²
ğ‘š)), where, for any
ğ‘¤1,...,ğ‘¤ğ‘˜,F(ğ‘¤ 1,...,ğ‘¤ğ‘˜)is0ifğ‘˜=0and1âˆ’âˆğ‘˜
ğ‘–=1(âˆ£1âˆ’ğ‘¤ğ‘–âˆ£)
otherwise, while Cis defined as follows: for ğ‘£ğ‘=F(ğ‘£ 1,...,ğ‘£ğ‘›)
andğ‘£ğ‘ =F(ğ‘£â€²
1,...,ğ‘£â€²
ğ‘š), ifğ‘£ğ‘=ğ‘£ğ‘ thenC(ğ‘£ 0,ğ‘£ğ‘,ğ‘£ğ‘ )=ğ‘£ 0; elseifğ‘£ğ‘>ğ‘£ğ‘ thenC(ğ‘£ 0,ğ‘£ğ‘,ğ‘£ğ‘ )=ğ‘£ 0âˆ’(ğ‘£ 0â‹…âˆ£ğ‘£ğ‘ âˆ’ğ‘£ğ‘âˆ£); otherwise
C(ğ‘£ 0,ğ‘£ğ‘,ğ‘£ğ‘ )=ğ‘£ 0+((1âˆ’ğ‘£ 0)â‹…âˆ£ğ‘£ğ‘ âˆ’ğ‘£ğ‘âˆ£).
In this paper, we adapt the notation of a BAF/QBAF for
an argument ğ‘âˆˆX from Ragoet al.[2023], as follows. For
Q=âŸ¨X,A,S,ğœâŸ© a QBAF and B=âŸ¨X,A,SâŸ© a BAF, for any
ğ›¼,ğ›½âˆˆX , let apathfrom ğ›¼toğ›½beğ‘=âŸ¨(ğ›¼ 0,ğ›¼1),...,(ğ›¼ğ‘›âˆ’1,ğ›¼ğ‘›)âŸ©
for someğ‘›>0(referred to as thelengthof ğ‘, denoted âˆ£ğ‘âˆ£)
whereğ›¼0=ğ›¼,ğ›¼ğ‘›=ğ›½and, for any1 â‰¤ğ‘–â‰¤ğ‘› ,(ğ›¼ğ‘–âˆ’1,ğ›¼ğ‘–)âˆˆ
AâˆªS . Let path(ğ›¼,ğ›½) andâˆ£path(ğ›¼,ğ›½)âˆ£ indicate the set of all
paths from ğ›¼toğ›½, and the number of paths in path(ğ›¼,ğ›½) ,
respectively. Then, for ğ›¼âˆ—âˆˆX,Q/B is aBAF/QBAF for ğ›¼âˆ—
iff (i)âˆ€ğ›¼âˆˆXpath(ğ›¼âˆ—,ğ›¼)=âˆ… ; (ii)âˆ€ğ›¼âˆˆXâˆ–{ğ›¼âˆ—}âˆ£path(ğ›¼,ğ›¼âˆ—)âˆ£=1;
(iii)âˆ€ğ›¼âˆˆXpath(ğ›¼,ğ›¼)=âˆ… . In essence, a BAF/QBAF for ğ›¼âˆ—is
essentially a tree withğ›¼âˆ—as the root, instead of a multi-tree
considered in Ragoet al.[2023].
We also usepro/conarguments in QBAFs as in Ragoet al.
[2023]. Let Qbe a QBAF for ğ›¼âˆ—. Then, thepro arguments
andcon argumentsfor Qare, respectively: Pro(Q)={ğ›¼âˆˆ
Xâˆ£âˆƒğ‘âˆˆpath(ğ›¼,ğ›¼âˆ—),whereâˆ£ğ‘âˆ©Aâˆ£is even} ;Con(Q)={ğ›¼âˆˆ
Xâˆ£âˆƒğ‘âˆˆpath(ğ›¼,ğ›¼âˆ—),whereâˆ£ğ‘âˆ©Aâˆ£is odd}.
3 Related Work
Claim verification with LLMs and RAGThe field of
claim verification has witnessed rapid advancements, partic-
ularly with LLMs, which can process extensive amounts of
information and have remarkable generative capabilities. De-
spite their strengths, LLMs encounter limitations in this task
as they may generate conflicting evidence due to their diverse
and incomplete training data Dmonteet al.[2024], which can
lead to inaccurate predictions. To address this, Zhang and
Gao [2023] use a hierarchical step-by-step prompting method
that breaks down the claim, which improves the accuracy of
news claim verification. Another solution is CRAVE Zhenget
al.[2025], which improves accuracy by first eliminating am-
biguities and retrieving evidence from external sources, and
then reasoning through two conflicting perspectives. Sim-
ilarly, Geet al.[2025] propose using RAG combined with
LLMs to resolve conflicting evidence and improve claim veri-
fication accuracy. Knowledge-based LLM approaches have
2

been developed for structured claim verification, including
generating argumentation frameworks to reason about claims
(i.e. ArgLLMs Freedmanet al.[2025]), extracting argumenta-
tion frameworks from RAG sources to reason about claims
(i.e. ArgRAG Zhuet al.[2025]), generating first order logic
representations to reason about claims Wang and Shu [2023],
and using multi-agent LLM systems for claim verification
Fenzaet al.[2025]. We build on some of this earlier work
on using LLMs to generate argumentation frameworks, but
focus on combining the agentsâ€™ generated frameworks.
LLMs and Judgmental ForecastingRecent research has
also explored the capabilities of LLMs in the context of judg-
mental forecasting, with mixed findings. Several studies have
found that using LLMs directly, without external grounding,
often fails to improve forecasting accuracy compared to hu-
man judgment Schoenegger and Park [2023]; Abolghasemi
et al.[2023]. In contrast, Halawiet al.[2024] demonstrated
that LLMs augmented with RAG can approach the perfor-
mance of expert human forecasters. Moreover, they show
that combining forecasts from humans and LLMs achieves
the best forecasting accuracy. Other work suggests that hu-
man forecasters advised by LLM-generated inputs can fur-
ther enhance performance Schoeneggeret al.[2024]. Overall,
while LLMs alone rarely outperform expert forecasters, RAG
appears promising for achieving forecasting accuracy com-
parable to humans, which motivated us to incorporate it in
our pipeline.
Combining Argumentation FrameworksIn computa-
tional argumentation, there has been some work on merg-
ing argumentation frameworks. Coste-Marquiset al.[2005,
2007] develop a merging pipeline that aligns agentsâ€™ frame-
works into a common domain, uses minimal edit distance
operators to merge attack relations, and then votes on ex-
tensions to produce group level consensus arguments. Cay-
rol and Lagasquie-Schiex [2011] generalise this by introduc-
ing weighted argumentation frameworks that embed relative
strengths of disagreement, producing a single weighted argu-
mentation framework. Leiteet al.[2015] merge argumenta-
tion frameworks using a semantic approach that selects argu-
ments and attacks of an agent that vary the least from other
agents. Delobelleet al.[2016] merge the sets of acceptable
arguments rather than merging argumentation frameworks
directly. Argumentative exchanges Ragoet al.[2023] allow
combining knowledge from argumentation agents, but in a
selected and distributed manner. In this paper, we focus on
merging QBAFs, a topic that, to our knowledge, has not been
studied before.
4 Multi-Agent Claim Verification
To verify claims using multiple agents, we propose a method
to combine the outputs of independently-generated QBAFs.
Our method produces a combined QBAF by clustering the
arguments across the independently-generated QBAFs us-
ing a similarity measure, followed by aggregating their base
scores. This allows us to capture a diverse argumentative
perspective. We assume that the independently-generated
QBAFs are such that there is no (ğ‘¥,ğ‘¦) that is an attack in oneof the QBAFs and a support in another, i.e. assuming a lingua
franca for the relations as in Ragoet al.[2023].
To determine whether arguments should be combined, we
first need a formal notion of their similarity. We thus define
a similarity function for clustering arguments.
Definition 1.Let Xbe a set of arguments. Asimilarity func-
tionÎ¨âˆ¶XÃ—Xâ†’[ 0,1]is such that, for ğ‘¥âˆˆX ,Î¨(ğ‘¥,ğ‘¥)= 1
and forğ‘¥,ğ‘¦âˆˆX,Î¨(ğ‘¥,ğ‘¦)=Î¨(ğ‘¦,ğ‘¥).
This definition ensures that the similarity of an argument
to itself is maximal and that the similarity function is inde-
pendent of the order in which arguments are compared.
To aggregate multiple base scores assigned to similar ar-
guments, we define a base score aggregation function. This
function allows for the aggregation of vectors of base scores
into a single representative value.
Definition 2.Letğ¾âˆˆN. Abase score aggregation function
w.r.t.ğ¾,ğœ”âˆ¶â‹ƒğ¾
ğ‘˜=1[0,1]ğ‘˜â†’[0,1]is such that:
1.for anyğ‘£âˆˆ[0,1]ğ‘˜, for any permutation ğ‘£â€²of the elements
ofğ‘£,ğœ”(ğ‘£â€²)=ğœ”(ğ‘£)(order-independence);
2.for anyğ‘£âˆˆ[ 0,1]ğ‘˜,min(ğ‘£)â‰¤ğœ”(ğ‘£)â‰¤max(ğ‘£)
(boundedness);
3. for anyğ‘£ ğ‘–âˆˆ[0,1],ğœ”((ğ‘£ ğ‘–,...,ğ‘£ğ‘–))=ğ‘£ğ‘–(idempotence);
4.for anyğ‘£,ğ‘£â€²âˆˆ[0,1]ğ‘˜withğ‘£=(ğ‘£ 1,...,ğ‘£ğ‘˜)andğ‘£â€²=
(ğ‘£â€²
1,...,ğ‘£â€²
ğ‘˜), ifâˆ€ğ‘–âˆˆ{1,...,ğ‘˜}(ğ‘£ğ‘–â‰¤ğ‘£â€²
ğ‘–)thenğœ”(ğ‘£)â‰¤ğœ”(ğ‘£â€²)
(monotonicity).
This definition ensures that base score aggregation func-
tions do not depend on the order in which the elements in
their input are presented, always return a number which lies
within the range of the provided base scores, if all elements
in the input are the same then the output is the common
element, and it is monotonic w.r.t. the inputs. We consider
two instantiations of the base score aggregation function ğœ”:
average aggregation, i.e. ğœ”ğ‘ğ‘£ğ‘”((ğ‘£1,...,ğ‘£ğ‘˜))=1
ğ‘˜âˆ‘ğ‘˜
ğ‘–=1ğ‘£ğ‘–; and
maximum aggregation, i.e. ğœ”ğ‘šğ‘ğ‘¥((ğ‘£1,...,ğ‘£ğ‘˜))=maxğ‘˜
ğ‘–=1ğ‘£ğ‘–. It
is easy to see that both aggregation functions satisfy Defini-
tion 2 (in particular both functions are order-independent,
bounded, idempotent, and monotonic)1.
Next, we define what it means to aggregate a set of QBAFs
into a combined QBAF, given a similarity function and a
base score aggregation function. This combined QBAF cap-
tures argument clusters, relations between them, and their
aggregated base scores.
Definition 3.Let Q1,...,Qğ‘›beğ‘›>1QBAFs, where, for ğ‘–âˆˆ
{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©. LetX=â‹ƒğ‘›
ğ‘–=1Xğ‘–,A=â‹ƒğ‘›
ğ‘–=1Ağ‘–,
andS=â‹ƒğ‘›
ğ‘–=1Sğ‘–. LetÎ¨âˆ¶XÃ—Xâ†’[ 0,1]be a similarity function,
andğ›¿âˆˆ[0,1]be a similarity threshold. Let ğœ”âˆ¶â‹ƒğ¾
ğ‘˜=1[0,1]ğ‘˜â†’
[0,1]be a base score aggregation function wrt ğ¾=âˆ£Xâˆ£ . Then,
thecombined QBAFQâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©is as follows:
â€¢Xâˆ—âŠ†2Xsatisfies the following properties:
1.âˆ€ğ‘¥âˆˆX,âˆƒ 1ğ‘¥âˆ—âˆˆXâˆ—such thatğ‘¥âˆˆğ‘¥âˆ—
2.âˆ€ğ‘¥,ğ‘¦âˆˆX ,âˆƒğ‘¥âˆ—âˆˆXâˆ—such thatğ‘¥,ğ‘¦âˆˆğ‘¥âˆ—iff (i)
âˆƒğ‘§âˆ—âˆˆXâˆ—andâˆƒğ‘§,ğ‘§â€²âˆˆğ‘§âˆ—with(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆA
or(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆS, and (ii)Î¨(ğ‘¥,ğ‘¦)â‰¥ğ›¿.
1See Appendix 8 for the proof .
3

â€¢Aâˆ—={(ğ‘¥âˆ—,ğ‘¦âˆ—)âˆ£âˆƒğ‘¥âˆˆğ‘¥âˆ—âˆƒğ‘¦âˆˆğ‘¦âˆ—such that(ğ‘¥,ğ‘¦)âˆˆA};
â€¢Sâˆ—={(ğ‘¥âˆ—,ğ‘¦âˆ—)âˆ£âˆƒğ‘¥âˆˆğ‘¥âˆ—âˆƒğ‘¦âˆˆğ‘¦âˆ—such that(ğ‘¥,ğ‘¦)âˆˆS};
â€¢âˆ€ğ‘¥âˆ—={ğ‘¥ 1,...,ğ‘¥ğ‘˜}âˆˆXâˆ—,ğœâˆ—(ğ‘¥âˆ—)=ğœ”(ğœ(ğ‘¥ 1),...,ğœ(ğ‘¥ğ‘˜)).
The first property ensures that any argument, ğ‘¥âˆˆX , is in a
unique cluster. If none of the other properties apply then the
cluster is a singleton cluster. The second property ensures that
any two arguments are in the same cluster if and only if they
both have the same relation (attack or support) towards ar-
guments in the same parent cluster and are similar according
to the similarity function and similarity threshold. Relations
are preserved in the combined QBAFs by adding relations be-
tween clusters. Then, base scores are aggregated according to
the clusters. Note that, not only each attack/support between
clusters results from lifting an attack/support between argu-
ments, but also each attack/support between arguments is
captured by some attack/support between clusters. Formally:
Lemma 4.1.Let ğ‘¥âˆ—,ğ‘¦âˆ—âˆˆXâˆ—. Then, (ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆAâˆ—(or
(ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆSâˆ—) iffâˆƒğ‘¥âˆˆğ‘¥âˆ—andâˆƒğ‘¦âˆˆğ‘¦âˆ—such thatâˆƒğ‘–âˆˆ{1,...,ğ‘›}
where(ğ‘¥,ğ‘¦)âˆˆA ğ‘–(or(ğ‘¥,ğ‘¦)âˆˆS ğ‘–, respectively).
Example 1.Given two QBAFs, Q1=âŸ¨X 1={ğ‘,ğ‘,ğ‘},A 1=
{(ğ‘,ğ‘)},S 1={(ğ‘,ğ‘)},ğœ 1(ğ‘)= 0.5,ğœ1(ğ‘)= 0.2,ğœ1(ğ‘)= 0.8âŸ©
andQ2=âŸ¨X 1={ğ‘,ğ‘â€²,ğ‘‘,ğ‘’,ğ‘’â€²},A 1={(ğ‘â€²,ğ‘)},S 1=
{(ğ‘‘,ğ‘),(ğ‘’,ğ‘â€²),(ğ‘’â€²,ğ‘â€²)},ğœ 2(ğ‘)= 0.5,ğœ2(ğ‘â€²)= 0.7,ğœ2(ğ‘‘)=
0.4,ğœ2(ğ‘’)= 0.3,ğœ(ğ‘’â€²)=0.1âŸ©. We assume a similarity function
Î¨such that Î¨(ğ‘,ğ‘â€²)= 0.9,Î¨(ğ‘’,ğ‘’â€²)= 0.6, and all other
possible argument pairs have similarity below the threshold
ğ›¿=0.5. Letğœ”be the arithmetic mean ğœ”ğ‘ğ‘£ğ‘”. We construct
the combined QBAF Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©as follows:
Xâˆ—={ğ‘¥âˆ—
1={ğ‘}(singleton, no parent argument) ;ğ‘¥âˆ—
2=
{ğ‘,ğ‘â€²} (sinceÎ¨(ğ‘,ğ‘â€²)= 0.9>ğ›¿) ;ğ‘¥âˆ—
3=
{ğ‘}(singleton, no similar arguments) ;ğ‘¥âˆ—
4 =
{ğ‘‘}(singleton, no similar arguments) ;ğ‘¥âˆ—
5 =
{ğ‘’,ğ‘’â€²}(sinceÎ¨(ğ‘’,ğ‘’â€²)=0.6>ğ›¿)} .Aâˆ—={(ğ‘¥âˆ—
2,ğ‘¥âˆ—
1)since(ğ‘,ğ‘)âˆˆ
A1,(ğ‘â€²,ğ‘)âˆˆA 2;(ğ‘¥âˆ—
5,ğ‘¥âˆ—
2)since(ğ‘’,ğ‘â€²)âˆˆA 2,(ğ‘’â€²,ğ‘â€²)âˆˆA 2}.
Sâˆ—={(ğ‘¥âˆ—
3,ğ‘¥âˆ—
1)since(ğ‘,ğ‘)âˆˆS 1;(ğ‘¥âˆ—
4,ğ‘¥âˆ—
1)since(ğ‘‘,ğ‘)âˆˆS 2}.
ğœâˆ—(ğ‘¥âˆ—
1)=ğœ”( 0.5,0.5)= 0.5;ğœâˆ—(ğ‘¥âˆ—
2)=ğœ”( 0.2,0.7)=
0.45;ğœâˆ—(ğ‘¥âˆ—
3)=0.8;ğœâˆ—(ğ‘¥âˆ—
4)=0.4;ğœâˆ—(ğ‘¥âˆ—
5)=ğœ”(0.3,0.1)=0.2.
Proposition 1.Let Q1,...,Qğ‘›be QBAFs, for ğ‘›>1, where, for
ğ‘–âˆˆ{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©. Then, the combined QBAF
Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©is a QBAF.
Proposition 2.Let Q1,...,Qğ‘›be QBAFs for the same argu-
mentğ‘“, forğ‘›>1, where, for ğ‘–âˆˆ{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©.
Then, the combined QBAF Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©is a QBAF
for{ğ‘“}.
Proposition 3.Let Q1,...,Qğ‘›be QBAFs for the same argu-
mentğ‘“, forğ‘›>1, where, for ğ‘–âˆˆ{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©.
Then, the combined QBAF Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©from Defi-
nition 3 preserves pro/con arguments in the original QBAFs,
i.e., for Pro(ğ‘„ğ‘–)(Con(ğ‘„ğ‘–)) the set of pro-arguments (con-
arguments, respectively) forQâˆ—:
âˆ€ğ‘¥âˆ—âˆˆXâˆ—(ğ‘¥âˆ—âˆˆPro(Qâˆ—)â‡”(âˆƒğ‘¥âˆˆğ‘¥âˆ—,ğ‘–âˆˆ{1,...,ğ‘›}ğ‘¥âˆˆPro(Q ğ‘–))),
and
âˆ€ğ‘¥âˆ—âˆˆXâˆ—(ğ‘¥âˆ—âˆˆCon(Qâˆ—)â‡”(âˆƒğ‘¥âˆˆğ‘¥âˆ—,ğ‘–âˆˆ{1,...,ğ‘›}ğ‘¥âˆˆCon(Q ğ‘–))).
Note that arguments without any similarities with other
arguments (e.g. ğ‘‘in Example 1) form singleton clusters (e.g.
Figure 2: The Multi-Agent QBAF Combinator takes two initial
QBAFs, Q1(top-left) and Q2(bottom-left), as input and outputs
a single, merged QBAFQâˆ—(right).
{ğ‘’}in the example). Note that we do not cluster arguments
with different parents or with the same parent but in different
relations. Thus, in Example 1, we do not cluster ğ‘andğ‘’(as
they do not share a parent) or ğ‘andğ‘‘(as they have opposite
stances for the same parent) even if they are similar. Clustered
arguments are made to share the same incoming relations
in the combined QBAF. Thus, in Example 1, ğ‘andğ‘â€²in the
cluster{ğ‘,ğ‘â€²}share supporter{ğ‘’,ğ‘’â€²}.
In the remainder of the paper, we assume that the QBAFs
are trees as in Example 1 (and thus acyclic graphs) for claim
ğ‘.
To construct a combined QBAF that satisfies the properties
in Definition 3, we define a bottom-up algorithm that clusters
arguments layer by layer, based on the similarity function.
The Multi-Agent QBAF Combinator algorithm starts from
a given claim argument ğ‘and then clusters its supporters
and attackers, recursively clustering their children, until the
maximum depth of the input QBAFs is reached. For each
cluster, the algorithm aggregates their base scores.
Lines 1-2 initialise the combined QBAF Qâˆ—with singleton
clusters for every argument in the union QBAF ğ‘¥âˆˆX . We
set the â€˜previous layerâ€™ to {ğ‘}the root, which represents the
parent arguments in the previous layer. The algorithm then
executes recursively layer by layer, Lines 4-15 merge clusters
inXâˆ—and build a set of clusters â€˜mergedâ€™ at the current depth.
Arguments are in the same cluster if they support or attack
the same parent argument and are similar. Otherwise, they
are placed in separate clusters. Lines 16-24 add the relation
between â€˜mergedâ€™ clusters to the combined QBAF, and assign
clusters their aggregated base score. Line 25 updates â€˜previous
layerâ€™ to contain all merged arguments in the previous layer,
enabling the algorithm to iterate to the next layer.
Example 2.We execute Algorithm 1 with Q1andQ2from
Example 1.
In line 1, the combined QBAF Qâˆ—is initialized with
singleton clusters of all arguments in the union QBAF:
{{ğ‘},{ğ‘},{ğ‘},{ğ‘â€²},{ğ‘‘},{ğ‘’},{ğ‘’â€²}}=Xâˆ—, and the base score
ofğ‘is set toğœâˆ—(ğ‘)=ğœ”(ğœ 1(ğ‘),...,ğœğ‘›(ğ‘)) . In line 2, the â€˜previous
4

Algorithm 1Multi-Agent QBAF Combinator
Require:ğ¹={Q 1,...,Qğ‘›}: QBAFs for claimğ‘,ğ‘›>1
Require:Î¨: similarity function
Require:ğ›¿: similarity threshold
Require:ğœ”: base score aggregation function
1:Initialize empty QBAF Qâˆ—â†âŸ¨{{ğ‘¥} âˆ£ğ‘¥âˆˆ
X},âˆ…,âˆ…,ğœâˆ—(ğ‘)=ğœ”(ğœ 1(ğ‘),...,ğœğ‘›(ğ‘))âŸ©
2:previous layerâ†{ğ‘}
3:forğ‘‘â†1to max depth level({Q 1,...,Qğ‘›})do
4:mergedâ†{}
5:forğ‘§âˆ—â†previous layerdo
6: for allpairs (ğ‘¥,ğ‘¦) whereğ‘¥,ğ‘¦âˆˆX such that
(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆA or(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆS whereğ‘§,ğ‘§â€²âˆˆ
ğ‘§âˆ—do
7:ifÎ¨(ğ‘¥,ğ‘¦)â‰¥ğ›¿then
8:mergeğ‘¥âˆ—andğ‘¦âˆ—, whereğ‘¥âˆˆğ‘¥âˆ—andğ‘¦âˆˆğ‘¦âˆ—
9:addğ‘¥,ğ‘¦to same cluster in merged
10:else
11:addğ‘¥to cluster in merged
12:addğ‘¦to another cluster in merged
13:end if
14:end for
15:end for
16:forğ‘§âˆ—â†previous layer andğ‘¥âˆ—â†mergeddo
17:setğœâˆ—(ğ‘¥âˆ—)=ğœ”(ğœ(ğ‘¥) âˆ£ğ‘¥âˆˆğ‘¥âˆ—)
18:ifâˆƒ ğ‘¥âˆˆğ‘¥âˆ—(ğ‘¥,ğ‘§)âˆˆAsuch thatğ‘§âˆˆğ‘§âˆ—then
19:add(ğ‘¥âˆ—,ğ‘§âˆ—)toAâˆ—
20:end if
21:ifâˆƒ ğ‘¥âˆˆğ‘¥âˆ—(ğ‘¥,ğ‘§)âˆˆSsuch thatğ‘§âˆˆğ‘§âˆ—then
22:add(ğ‘¥âˆ—,ğ‘§âˆ—)toSâˆ—
23:end if
24:end for
25:previous layerâ†merged
26:end for
27:returnQâˆ—: combined QBAF
layerâ€™ is set to{ğ‘}.
At depth 1, â€˜mergedâ€™ is set to {}in line 4. Lines 5-15
goes through all arguments in â€˜previous layerâ€™ ( ğ‘in depth
1). Lines 6-14 goes through (ğ‘,ğ‘â€²),(ğ‘,ğ‘‘) as(ğ‘,ğ‘),(ğ‘â€²,ğ‘)âˆˆA
and(ğ‘,ğ‘),(ğ‘‘,ğ‘)âˆˆS .Î¨(ğ‘,ğ‘â€²)>0.5so â€˜mergedâ€™= {{ğ‘,ğ‘â€²}}.
Î¨(ğ‘,ğ‘‘)< 0.5so â€˜mergedâ€™= {{ğ‘,ğ‘â€²},{ğ‘},{ğ‘‘}} . Line 8 merges
clusters in the combined QBAF,{{ğ‘,ğ‘â€²},{ğ‘},{ğ‘‘}}âŠ‚Xâˆ—.
Lines 16-24 goes through all merged clusters {ğ‘,ğ‘â€²},{ğ‘},{ğ‘‘}
and all arguments in â€˜previous layerâ€™. Then, the base scores are
added in line 17, ğœâˆ—({ğ‘,ğ‘â€²})=ğœ”(ğœ(ğ‘),ğœ(ğ‘â€²))=ğœ”( 0.5,0.5)=
0.5,ğœâˆ—({ğ‘})= 0.8,ğœâˆ—({ğ‘‘})= 0.4. Lines 18-24 adds support
(attack) relations if there is an argument in the cluster that is
supporting (attacking) an argument in the â€˜previous layerâ€™. So,
{({ğ‘,ğ‘â€²},ğ‘)}âŠ‚Aâˆ—as(ğ‘,ğ‘)âˆˆA , and{({ğ‘},ğ‘),({ğ‘‘},ğ‘)}âŠ‚
Sâˆ—as(ğ‘,ğ‘),(ğ‘‘,ğ‘)âˆˆS.
Before starting depth 2, line 25 assigns the union of all ar-
guments that were in â€˜mergedâ€™ to â€˜previous layerâ€™. â€˜Previous
layerâ€™={ğ‘,ğ‘â€²,ğ‘,ğ‘‘}.
â€˜mergedâ€™ is set to {}in line 4. Lines 5-15 goes through all
arguments in â€˜previous layerâ€™ (ğ‘,ğ‘â€²,ğ‘,ğ‘‘in depth 1). Lines 6-13
goes through (ğ‘’,ğ‘’â€²)as(ğ‘’,ğ‘â€²),(ğ‘’â€²,ğ‘â€²)âˆˆS .Î¨(ğ‘’,ğ‘’â€²)>0.5soâ€˜mergedâ€™= {{ğ‘’,ğ‘’â€²}}. Line 8 merges the clusters in the combined
QBAF,{{ğ‘’,ğ‘’â€²}}âŠ‚Xâˆ—.
Lines 16-24 goes through all merged clusters {ğ‘’,ğ‘’â€²}and all
arguments in â€˜previous layerâ€™. Then, the base scores are added in
line 17,ğœâˆ—({ğ‘’,ğ‘’â€²})=ğœ”(ğœ(ğ‘’),ğœ(ğ‘’))=ğœ”( 0.3,0.1)=0.2. Lines
18-23{({ğ‘’,ğ‘’â€²},{ğ‘,ğ‘â€²})}âŠ‚Aâˆ—as(ğ‘’,ğ‘)âˆˆS.
Then, we returnQâˆ—as the combined QBAF.
Proposition 4.Algorithm 1 terminates and returns a com-
bined QBAF in polynomial time.
5 LLM-Agents for QBAF Generation
In this section, we describe the three LLM-agent variants we
consider: ArgLLM agents, RAG-ArgLLM agents (extending
ArgLLMs with RAG, to incorporate external textual evidence
in their generative process), and RbAM agents (complemen-
tary approach, which constructs a QBAF by directly using
the external sources as arguments and classifying these ar-
guments stances towards the claim). Each of these agents
independently generates QBAFs. We use approaches based
on ArgLLMs in this paper instead of ArgRAG because the
QBAFs generated for our multi-agent framework to combine
QBAFs must be acyclic trees, while it is possible that ArgRAG
could generate a QBAF with cycles.
5.1 Argumentative LLM (ArgLLM) Agent
The ArgLLM Freedmanet al.[2025] agent extracts QBAFs
from LLMs and formally reasons over them using gradual
semantics. The ArgLLMs methodology has three components:
(1)Argument Generation, which returns a BAFBfor a given
claimğ‘, given a generative model ğº, and parameters for
argument generation ğœƒ, such as the prompt used, and the
number of arguments to be generated in depth and breadth,
denoted formally as Î“(ğ‘¥,ğº,ğœƒ)â†’B ; (2)Intrinsic Argument
Strength Attribution, which assigns base scores to the BAF B
using an evaluative function ğ¸to obtain a QBAF Q, defined
asE(B,ğ¸)â†’Q ; (3) Argument Strength Calculation, which
applies a gradual semantics ğœto the QBAF Qto obtain an
assessment for the claimğ‘, denoted asÎ£(ğ‘,Q,ğœ)â†’ğœ(ğ‘).
5.2 Retrieval-Augmented ArgLLM
(RAG-ArgLLM) Agent
To strengthen the factual grounding of generated arguments,
we extend the ArgLLM agent with RAG. In this work, ArgLLM
agents are prompted with textual evidence from external
sources, allowing it to generate more complete and informed
arguments.
Letğ‘‡={ğ‘¡ 1,...,ğ‘¡ğ‘˜}be a set of textual evidence relevant to a
claimğ‘, retrieved from a collection of sources, and let ğºbe a
generative model. We defineRetrieval-Augmented ArgLLMs
as one in which ğœƒin the argument generation function is a
modified prompt,RAG prompt for ArgLLMs, which incorpo-
rates the retrieved evidenceğ‘‡.
Figure 3 shows how RAG improves a result for a single
claim.
5.3 RbAM Agent
In addition to Retrieval-Augmented ArgLLM agents, we in-
troduce a complementary approach based on RbAM. In this
5

Figure 3: An example of how an RAG-ArgLLM agent (bottom) can
improve the results compared to an ArgLLM agent (top). The ex-
ample is taken from the Metaculus dataset and its claim is false.
The ArgLLM agent incorrectly predicts it as false whereas the RAG-
ArgLLM agent correctly predicts it.
setting, textual evidence is not used to generate new argu-
ments but is instead seen as arguments. The RbAM compo-
nent classifies the relation between each textual evidence and
the claim as support, attack, or neither, yielding a QBAF in
which the retrieved evidence supports or attacks the claim.
TheRbAM Agent, treats each retrieved evidence as an ar-
gument, and the RbAM component determines whether it is
related to the claim ğ‘“. We adopt the best performing RbAM
method from Goruret al.[2025b]: a few-shot prompt-based
classification approach using the Mixtral-8x7B Jianget al.
[2024] model, which Goruret al.[2025b] show significantly
outperforms prior baselines on the RbAM task.
6 Experimental Set-up
First, we evaluate our individual LLM-Agents introduced in
Section 5: (1) the ArgLLM agent (as a baseline), (2) the RAG-
ArgLLM agent, and (3) the RbAM agent.
Then, we evaluate our multi-agent framework by combin-
ing the outputs of these agents in various configurations: (1)
pairs of ArgLLM agents across six base models, (2) pairs of
RAG-ArgLLM agents across six base models, (3) two-agentcombinations: combining RAG-ArgLLM agents that use dif-
ferent external sources (The NYTimes and The Guardian),
(4) a three-agent combination: combining the ArgLLM agent
with the two different RAG-ArgLLM agents, each using a
different external source.
In our experiments, we use the Jina-V3 embeddings Sturua
et al.[2025] with cosine similarity for the similarity function
Î¨. This embedding model was selected due to its strong
performance on semantic similarity tasks and compact size2.
In our experiments we use the similarity thresholdğ›¿=0.53.
6.1 Datasets
All of the configurations are executed on two judgmental
forecasting datasets.
GJOpen4A forecasting arguments dataset Goruret al.
[2025a], which contains 2923 rephrased question-answer
pairs from Good Judgment Open. Each pair was converted
into a natural-language forecasting argument (claim) us-
ing the Mistral-7B-Instruct-v0.3 LLM Jianget al.[2023], fol-
lowed by manual review. The dataset covers both binary
and multiple-choice forecasting questions, and is publicly
available.
Metaculus5A subset of the Forecasting dataset from Ha-
lawiet al.[2024], which originally includes 8881 binary fore-
casting questions. We picked only the questions that have
been resolved and were open between the dates of September
2023 and September 2024, which yielded 388 forecasting ques-
tions. We converted the questions into forecasting arguments
(claims) using the Mistral-7B-Instruct-v0.3 LLM, followed by
manual review, similarly to Goruret al.[2025a].
6.2 External Sources
To support RAG, we retrieve relevant evidence from two news
article sites.
NYTimesWe collected all NYTimes article abstracts pub-
lished between January 2023 and December 2024 using the
NYTimes API.
GuardianFor each forecasting argument, we generated
five targeted search queries using GPT -4o-mini (see Ap-
pendix 8 for details). These queries were submitted to the
Guardian API to retrieve article abstracts.
Retrieval PipelineFor both sources, to optimise evidence
retrieval, we embedded each abstract using the Jina-V3 em-
bedding model Sturuaet al.[2025]. The resulting embeddings
were stored in a vector database, ChromaDB, to support real-
time retrieval. We then retrieved the top five relevant articles
for each claim, restricted to abstracts dated before the closing
date of the claim.
2At the time of experimentation, Jina-V3 ranked fourth
on the MTEB leaderboard: https://huggingface.co/spaces/mteb/
leaderboard
3In our initial experimentsğ›¿=0.5yielded the best results.
4https://www.gjopen.com/
5https://www.metaculus.com/
6

6.3 Models
We evaluate all configurations using the following LLMs: Mix-
tral (Mixtral-8x7B-Instruct-v0.1) Jianget al.[2024], Mistral
(Mistral-7B-Instruct-v0.3) Jianget al.[2023], Gemma (Gemma-
7b-it) Mesnardet al.[2024], Gemma-2 (Gemma-2-9b-it) Riv-
iereet al.[2024], Llama-3 (Meta-Llama-3-8B-Instruct) Dubey
et al.[2024], and GPT-4o (GPT-4o-mini) OpenAI [2024] mod-
els. These models were chosen to ensure their training data
cut-off dates preceded the forecasting events, thereby avoid-
ing data contamination.
7 Results
7.1 Individual Agents
ArgLLM and RAG-ArgLLM AgentsWe first evaluate the
ArgLLM and RAG-ArgLLM agents (using the NYTimes and
the Guardian as external sources) with their four variations
depth 1 (with 0.5 base score and estimated base score as-
signed to the claim) and depth 2 (with 0.5 base score and
estimated base score assigned to the claim). Table 1 (minus
the last column) reports results of the ArgLLMs and the RAG-
ArgLLMs agents, with the NYTimes and the Guardian as
external sources, on the GJOpen and Metaculus datasets.
Retrieval improves forecasting accuracy on the Metaculus
dataset in nearly all variations. The highest accuracy increase
comes when the external sources are used with Gemma-2
(with depth 1, estimated base score), accuracy improves from
68% to 81% (for both NYTimes and Guardian). The RAG-
ArgLLM agents that did not improve accuracy were already
performing well and the external sources changed the ar-
gumentative reasoning of those models. On GJOpen, the
improvement is less consistent, however, using the Guardian
seems to improve forecasting accuracy more compared to
using the NYTimes. The highest accuracy increase occurs
when using the NYTimes with Llama-3 (with depth 2, 0.5
base score) where the accuracy improves from 63% to 75%.
RbAM AgentsThe last column in Table 1 shows the results
of the RbAM agent with two external sources (the NYTimes
and the Guardian) on the two forecasting datasets.
The RbAM agent does not seem to perform that well for the
GJOpen dataset, this is because the base scores generated are
very small due to the abstracts not having a proper argumen-
tative structure. One possible solution is to prompt a language
model to extract or generate structured arguments from each
abstract, which we leave to future work. The Guardian as
an external source helped more than the NYTimes on the
GJOpen dataset. This is possibly because of its more relevant
context. On the other hand, the RbAM agent performs better
for the Metaculus datasets, although it still does not surpass
the best ArgLLM or RAG-ArgLLM agent. Therefore, we de-
cided not to combine QBAFs obtained from the RbAM agent
as the accuracy was very low.
7.2 Multi-Agent Claim Verification
ArgLLM Agent PairsWe first evaluate our multi-agent
framework across six pairs of ArgLLM agents with their four
variations depth 1 (with 0.5 base score and estimated base
score assigned to the claim) and depth 2 (with 0.5 base scoreDataset Depth Source Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o RbAM
GJOpen1W/O 67/70 65/7173/5779/7778/7574/69 -
NYTimes 61/71 65/73 71/6676/75 78/44 72/66 43/29
Guardian 61/72 66/7472/64 78/7679/7671/67 49/36
2W/O 56/69 56/6770/5679/7763/7569/68 -
NYTimes 49/67 52/6864/6375/7575/50 71/66 -
Guardian 49/68 51/6864/6377/76 74/5272/67 -
Metaculus1W/O 66/74 61/70 76/73 68/6681/6581/74 -
NYTimes 71/78 79/80 81/7381/78 81/7878/73 69/79
Guardian 69/7379/8080/76 81/7879/69 79/76 63/78
2W/O 61/7362/67 71/73 67/6678/6582/76 -
NYTimes 52/72 61/78 72/7476/7478/66 79/73 -
Guardian 55/73 66/77 68/7380/7873/6880/76 -
Table 1: Performance of individual agents on the GJOpen and Metac-
ulus datasets, across Depth 1 and Depth 2. The table compares the
baseline ArgLLM agents (W/O source) and the RAG-ArgLLM agents
(NYTimes and Guardian source) with the base LLM models as per
columns, as well as, in the last column, the RbAM agent (using the
NYTimes and the Guardian, as per respective rows). For each agent
configuration, we report accuracy of 0.5 base /estimated base scores.
Bold indicates best results for each agent configuration, with/out
the use of sources.
and estimated base score assigned to the claim). For each
variation, we apply two aggregation functions, average and
maximum, to combine argument base scores. Table 3 in Ap-
pendix 9.1 reports results for depth 1 and depth 2 for the
GJOpen and Metaculus datasets. Each ArgLLM agent inde-
pendently generates arguments and their base scores, then
our multi-agent framework combines pairs of ArgLLM agents.
The results show variation across individual ArgLLM
agents. This variation reflects differences in the agentsâ€™ ar-
gumentative reasoning capabilities. Across all variations,
the combination of argumentative reasoning produced by
the ArgLLM agents frequently outperforms at least one of
the individual models, and in several cases outperform both.
Our multi-agent framework improves performance when the
paired agents bring complementary argumentative reason-
ing. For example, Table 2 shows Llama-3 combined with the
other agent tend to improve on accuracy which could mean
that Llama-3 generates argumentative reasoning that com-
plements other agents. The instances where the multi-agent
framework does not perform well are when a base agent al-
ready performs well individually. This could suggest that the
second agent contributes less useful or redundant arguments.
For instance, Gemma-2 already performs well, so combining
it with other agents does not typically improve results.
Overall, the multi-agent framework can improve forecast-
ing performance, particularly when the base agents offer di-
verse argumentative perspectives. Average aggregation gen-
erally outperforms max aggregation, suggesting that a mod-
erate base score is more effective than selecting the strongest
base score.
RAG-ArgLLM Agent PairsNext, we evaluate our multi-
agent framework across six pairs of RAG-ArgLLM agents
with their four variations depth 1 (with 0.5 base score and es-
timated base score assigned to the claim) and depth 2 (with 0.5
base score and estimated base score assigned to the claim) and
the NYTimes and the Guardian as external sources. Table 4
7

Dataset Model Llama-3 (D=1) Llama-3 (D=2)
Avg Max Avg Max
ArgLLMGJOpenSingle 78/75 Single 63/75
Mixtral 67/70 68/75 77/75 56/69 43/74 49/75
Mistral 65/71 69/75 75/75 56/67 49/75 49/75
Gemma 73/57 73/7678 /78 50/70 70/56 50/70
Gemma-2 79/77 78/7878/78 79/77 50/70 50/70
MetaculusSingle 81/65 Single 81/65
Mixtral 66/74 66/74 66/74 61/73 66/7666/76
Mistral 61/70 61/70 61/70 62/67 61/7461/74
Gemma 76/73 68/66 76/73 76/73 71/73 68/66
Gemma-2 68/66 68/66 68/66 67/66 68/66 68/66
RAG-
ArgLLM
NY-
TimesGJOpenSingle 78/44 Single 75/50
Mixtral 61/71 61/7161/71 49/67 37/49 48/51
Mistral 59/68 65/7365/73 52/68 41/49 48/50
Gemma 71/66 76/7576/75 64/63 53/54 37/57
Gemma-2 76/75 76/75 37/57 75/75 66/71 76/75
MetaculusSingle 79/68 Single 78/66
Mixtral 71/78 71/78 71/78 52/72 41/63 52/66
Mistral 79/80 79 /80 79/80 61/78 53/67 56/65
Gemma 81/73 81 /78 81 /73 72/74 64/70 44/47
Gemma-2 81/78 81 /78 81 /78 76/74 71/70 44/47
RAG-
ArgLLM
GuardianGJOpenSingle 78/76 Single 74/52
Mixtral 61/72 61/72 61/72 46/68 36/50 51/52
Mistral 66/74 66/74 66/74 51/68 39/51 48/51
Gemma 72/64 78 /76 78/76 64/63 52/56 38/59
Gemma-2 78/76 78 /76 78/76 77/76 71/73 38/59
MetaculusSingle 79/70 Single 73/68
Mixtral 69/73 69/73 69/73 55/73 45/64 55/66
Mistral 79/80 79 /80 79/80 66/77 56/66 61/66
Gemma 80/7681/7880 /76 68/73 62/69 45/48
Gemma-2 81/78 81 /78 81/78 80/78 76/75 45/48
Table 2: Accuracy results of our multi-agent combination framework
applied to pairs of (Llama-3 and one of Mixtral, Mistral, Gemma
and Gemma-2) (i) ArgLLM agents; (ii) RAG-ArgLLM agents using
NYTimes; (iii) RAG-ArgLLM agents using the Guardian, for Depth
1 (left) and Depth 2 (right). We show accuracy results using 0.5/es-
timated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score ag-
gregations. Bold indicates improvement over both Single agents;
underline indicates improvement over one and parity with the other.
and Table 5 in Appendix 9.2 report results for the multi-agent
framework using the RAG-ArgLLM agents with the NYTimes
and the Guardian (respectively) for the GJOpen and Metacu-
lus datasets.
Results show that multi-agent framework with the RAG-
ArgLLM agents often outperforms at least one of the individ-
ual RAG-ArgLLM agents, and in some cases exceed both. This
similarly confirms combining QBAFs improve performance
when the paired agents bring complementary argumentative
reasoning, even when arguments are retrieved from the ex-
ternal sources. Notably, looking at Table 2, combinations
involving Llama-3 often improves accuracy despite Llama-
3 not performing well individually with the RAG-ArgLLM
agents, indicating its arguments remain complementary when
combined with other models. We also observe that average
aggregation typically outperforms max, aligning with ear-
lier findings for the multi-agent framework. Performance
gains are more consistent on the Metaculus dataset, where
the paired agents often match or exceed both individual mod-
els. On the other hand, improvements on the GJOpen dataset
are more dependent on the choice of the external source. The
Guardian tends to be more effective than the NYTimes, con-sistent with the findings for the single-agent RAG-ArgLLM
and RbAM agents.
Overall, multi-agent framework applied to the RAG-
ArgLLM agent pairs demonstrates that combining retrieval-
augmented models can also be beneficial, particularly when
combination is done with average aggregation and when the
base models offer diverse argumentative perspectives.
Two-Agent CombinationWe then explore the perfor-
mance of combining two different agents, analysing three
variants: combining two RAG-ArgLLM agents that use differ-
ent sources (the NYTimes and the Guardian), and combining
standard ArgLLM agents with the RAG-ArgLLM agents (us-
ing either the NYTimes or the Guardian).
Tables 6 and 7 in Appendix 9.3 show the results of combin-
ing two RAG-ArgLLM agents, where one uses the NYTimes
and the other uses the Guardian as external sources. The com-
bination of the RAG-ArgLLM agents with different sources
often yields significant improvements, particularly in depth
1. Mistral (Guardian) also proves to be a consistently strong
complementary agent in Depth 1, improving or maintaining
accuracy in most pairings across both datasets (five out of six
in both). However, performance in depth 2 is less consistent
and often leads to a degradation in accuracy. This is likely
due to the generation of irrelevant arguments in the second
layer. Nonetheless, even in depth 2 some improvement is still
observable over single agents.
Tables 8 and 9 in Appendix 9.3 present results where the
ArgLLM agents are paired with the RAG-ArgLLM agents us-
ing the NYTimes. Tables 10 and 11 in Appendix 9.3 show
similar pairings but with the Guardian as the external source.
The results indicate that this hybrid approach is highly effec-
tive. The RAG-ArgLLM agents introduce externally grounded
arguments that can complement the internal reasoning of
the ArgLLM agents. The benefit is particularly clear when
using the NYTimes as the external source. For example, Mis-
tral (NYTimes) often improved or maintained the accuracy
of its ArgLLM partner on the GJOpen dataset (five out of
six instances) for average aggregation. The Guardian source
also shows strong performance in specific pairings. However,
the RAG-ArgLLM agents using the Guardian does not seem
to improve accuracy when it is combined with the ArgLLM
agents as much.
Overall, our multi-agent framework applied to two differ-
ent agents demonstrates that combining different external
sources can be beneficial. The most significant gains are
achieved when agents leverage different external sources.
Three-Agent CombinationWe extend the analysis of our
multi-agent framework to three agents, where a standard
ArgLLM is combined with two RAG-ArgLLM agents, one
using the NYTimes and the other the Guardian. The results,
presented in Tables 12-23 in Appendix 9.4, demonstrate the
potential to increase accuracy by increasing the diversity of
argumentative reasoning.
The addition of a third agent often leads to more robust
and accurate forecasts, particularly on the GJOpen dataset.
The most consistent improvements are observed when the
base ArgLLM agent is a strong performer itself, such as with
Gemma-2 or GPT-4o. This suggests that when an agentâ€™s in-
8

ternal reasoning is strong, it provides a solid foundation that
can be effectively enhanced by complementary information
from external sources, thereby improving the forecasting ac-
curacy. While the three-agent combination does not always
outperform the best single agent in the trio, it consistently
shows a clear improvement over the other two individual
agents. On the Metaculus dataset, the benefits are also ap-
parent, although the strong individual agent performance
sometimes sets a high bar for improvement. Both aggre-
gation methods show instances of improvement. However,
average aggregation performs better than max aggregation
in most instances, supporting the evidence from previous
experiments.
Overall, the three-agent framework, by increasing the di-
versity of complementary reasoning, can improve forecasting
accuracy whether from different models or different external
data sources.
8 Conclusions and Future Work
In this paper, we introduce a novel multi-agent framework
which integrates multiple perspectives by combining QBAFs
generated by diverse LLM-based agents. We designed and
evaluated three distinct agent types: the baseline ArgLLM
agents (which relies on internal LLM knowledge), the RAG-
ArgLLM agents and the RbAM agents (which ground their
reasoning in external sources).
Our empirical evaluation on the GJOpen and Metaculus
datasets yielded several key insights. First, the RAG-ArgLLM
agents consistently outperformed the ArgLLM agents, espe-
cially on the Metaculus dataset. This confirms that ground-
ing argumentative reasoning with external evidence can im-
prove forecasting accuracy. While the RbAM agents showed
promise on the Metaculus dataset, they did not perform
well on the GJOpen dataset. Second, our multi-agent frame-
work applied to pairs of the same agent types, in some in-
stances improved forecasting accuracy. Performance gains
were most significant when the agents generated complemen-
tary argumentative perspectives. Pairing an ArgLLM agent
with a RAG-ArgLLM agent, or combining two RAG-ArgLLM
agents using different external sources (the NYTimes and the
Guardian), proved highly effective. This suggests integrating
both internal LLM reasoning and external evidence can be
beneficial. Finally, instantiating our framework with three
agents, an ArgLLM and two RAG-ArgLLMs with different
sources, yielded further improvements. By increasing the
diversity of reasoning and external sources, the three-agent
framework produced more robust reasoning. This suggests
that combining more complementary perspectives yields bet-
ter results.
Building on these findings, we plan to explore several
promising directions: (1) investigating in more depth which
models to pick while combining their argumentative reason-
ing; (2) studying whether an interactive debate could improve
forecasting accuracy (e.g. using a similar framework to Rago
et al.[2023]), and (3) experimenting with a larger number of
frameworks.Acknowledgments
This research was partially funded by the ERC under the EUâ€™s
Horizon 2020 research and innovation programme (grant
agreement no. 101020934, ADIX), by J.P. Morgan and by
the Royal Academy of Engineering, UK, under the Research
Chairs and Senior Research Fellowships scheme (grant agree-
ment no. RCSRF2021\11\45).
References
MAhdi Abolghasemi, Odkhishig Ganbold, and Kristian Ro-
taru. Humans vs large language models: Judgmental fore-
casting in an era of advanced AI.CoRR, 2023.
Katie Atkinson, Pietro Baroni, Massimiliano Giacomin, An-
thony Hunter, Henry Prakken, Chris Reed, Guillermo Ri-
cardo Simari, Matthias Thimm, and Serena Villata. Towards
artificial argumentation.AI Magazine, 38(3):25â€“36, 2017.
Pietro Baroni, Dov Gabbay, Massimiliano Giacomin, and Leen-
dert van der Torre, editors.Handbook of Formal Argumen-
tation. College Publications, 2018.
Pietro Baroni, Antonio Rago, and Francesca Toni. From fine-
grained properties to broad principles for gradual argu-
mentation: A principled spectrum.International Journal of
Approximate Reasoning, 105:252â€“286, February 2019.
Lucas Carstens and Francesca Toni. Towards relation based
argumentation mining. InProc. 2nd Workshop on Argumen-
tation Mining, ArgMining@HLT-NAACL 2015, June 4, 2015,
Denver, Colorado, USA. ACL, 2015.
Claudette Cayrol and Marie-Christine Lagasquie-Schiex. On
the acceptability of arguments in bipolar argumentation
frameworks. InECSQARU, Lecture Notes in Computer
Science. Springer, 2005.
Claudette Cayrol and Marie-Christine Lagasquie-Schiex.
Weighted argumentation systems: A tool for merging ar-
gumentation systems. InIEEE 23rd Intâ€™l Conf. on Tools
with Artificial Intelligence, ICTAI 2011, Boca Raton, FL, USA,
November 7-9, 2011. IEEE Computer Society, 2011.
Dhivya Chandrasekaran and Vijay Mago. Evolution of seman-
tic similarity - A survey.ACM Comput. Surv., 54(2):41:1â€“
41:37, 2022.
Sylvie Coste-Marquis, Caroline Devred, SÃ©bastien Konieczny,
Marie-Christine Lagasquie-Schiex, and Pierre Marquis.
Merging argumentation systems. InProceedings, The Twen-
tieth National Conference on Artificial Intelligence and the
Seventeenth Innovative Applications of Artificial Intelligence
Conference, July 9-13, 2005, Pittsburgh, Pennsylvania, USA.
AAAI Press / The MIT Press, 2005.
Sylvie Coste-Marquis, Caroline Devred, SÃ©bastien Konieczny,
Marie-Christine Lagasquie-Schiex, and Pierre Marquis. On
the merging of dungâ€™s argumentation systems.Artif. Intell.,
171(10-15):730â€“753, 2007.
JÃ©rÃ´me Delobelle, Adrian Haret, SÃ©bastien Konieczny, Jean-
Guy Mailly, Julien Rossit, and Stefan Woltran. Merging
of abstract argumentation frameworks. InPrinciples of
Knowledge Representation and Reasoning: Proceedings of
9

the Fifteenth International Conference, KR 2016, Cape Town,
South Africa, April 25-29, 2016. AAAI Press, 2016.
Alphaeus Dmonte, Roland Oruche, Marcos Zampieri, Prasad
Calyam, and Isabelle Augenstein. Claim verification in the
age of large language models: A survey.CoRR, 2024.
Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Ab-
hishek Kadian, Ahmad Al-Dahle, Aiesha Letman, Akhil
Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The
llama 3 herd of models.CoRR, 2024.
Giuseppe Fenza, Domenico Furno, Vincenzo Loia, and
Pio Pasquale Trotta. Multi-llm agents architecture for claim
verification. InProc. Joint National Conference on Cyber-
security (ITASEC & SERICS 2025), Bologna, Italy, February
03-08, 2025, CEUR Workshop Proceedings. CEUR-WS.org,
2025.
Gabriel Freedman, Adam Dejl, Deniz Gorur, Xiang Yin, An-
tonio Rago, and Francesca Toni. Argumentative large lan-
guage models for explainable and contestable claim verifi-
cation. InAAAI-25, February 25 - March 4, 2025, Philadel-
phia, PA, USA. AAAI Press, 2025.
Ziyu Ge, Yuhao Wu, Daniel Wai Kit Chin, Roy Ka-Wei Lee,
and Rui Cao. Resolving conflicting evidence in automated
fact-checking: A study on retrieval-augmented llms.CoRR,
2025.
Deniz Gorur, Antonio Rago, and Francesca Toni. Argumen-
tatively coherent judgmental forecasting. InECAI 2025 -
28th European Conference on Artificial Intelligence, October
25 to 30, 2025, Bologna, Italy, 2025.
Deniz Gorur, Antonio Rago, and Francesca Toni. Can large
language models perform relation-based argument min-
ing? InProc. 31st Intâ€™l Conf. on Computational Linguistics,
COLING 2025, Abu Dhabi, UAE, January 19-24, 2025. ACL,
2025.
Danny Halawi, Fred Zhang, Chen Yueh-Han, and Jacob Stein-
hardt. Approaching human-level forecasting with language
models. InAdvances in Neural Information Processing Sys-
tems 38: Annual Conference on Neural Information Process-
ing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada,
December 10 - 15, 2024, 2024.
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris
Bamford, Devendra Singh Chaplot, Diego de Las Casas, Flo-
rian Bressand, Gianna Lengyel, Guillaume Lample, Lucile
Saulnier, et al. Mistral 7b.CoRR, 2023.
Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur
Mensch, Blanche Savary, Chris Bamford, Devendra Singh
Chaplot, Diego de Las Casas, Emma Bou Hanna, Florian
Bressand, et al. Mixtral of experts.CoRR, 2024.
Michael Lawrence, Paul Goodwin, Marcus Oâ€™Connor, and
Dilek Ã–nkal. Judgmental forecasting: A review of progress
over the last 25 years.International Journal of Forecasting,
22(3):493â€“518, 2006.
Lucas Leite, Thiago Alves Rocha, and JoÃ£o F. L. AlcÃ¢ntara.
Merging argumentation systems. In2015 Brazilian Con-
ference on Intelligent Systems, BRACIS 2015, Natal, Brazil,
November 4-7, 2015. IEEE Computer Society, 2015.Thomas Mesnard, Cassidy Hardin, Robert Dadashi, Surya
Bhupatiraju, Shreya Pathak, Laurent Sifre, Morgane Riv-
iÃ¨re, Mihir Sanjay Kale, Juliette Love, Pouya Tafti, et al.
Gemma: Open models based on gemini research and tech-
nology.CoRR, 2024.
OpenAI. Gpt-4o mini: advancing cost-efficient intelligence,
2024.
Antonio Rago, Francesca Toni, Marco Aurisicchio, and Pietro
Baroni. Discontinuity-free decision support with quanti-
tative argumentation debates. InPrinciples of Knowledge
Representation and Reasoning: Proceedings of the Fifteenth
International Conference, KR 2016, Cape Town, South Africa,
April 25-29, 2016. AAAI Press, 2016.
Antonio Rago, Hengzhi Li, and Francesca Toni. Interactive
explanations by conflict resolution via argumentative ex-
changes. InProc. 20th Intâ€™l Conf. on Principles of Knowl-
edge Representation and Reasoning, KR 2023, Rhodes, Greece,
September 2-8, 2023, 2023.
Morgane Riviere, Shreya Pathak, Pier Giuseppe Sessa, Cassidy
Hardin, Surya Bhupatiraju, LÃ©onard Hussenot, Thomas
Mesnard, Bobak Shahriari, Alexandre RamÃ©, et al. Gemma
2: Improving open language models at a practical size.
CoRR, 2024.
Philipp Schoenegger and Peter S. Park. Large language model
prediction capabilities: Evidence from a real-world fore-
casting tournament.CoRR, 2023.
Philipp Schoenegger, Peter S. Park, Ezra Karger, and Philip E.
Tetlock. AI-augmented predictions: LLM assistants im-
prove human forecasting accuracy.CoRR, 2024.
Saba Sturua, Isabelle Mohr, Mohammad Kalim Akram,
Michael GÃ¼nther, Bo Wang, Markus Krimmel, Feng Wang,
Georgios Mastrapas, Andreas Koukounas, Nan Wang, and
Han Xiao. Jina embeddings V3: multilingual text encoder
with low-rank adaptations. InAdvances in Information Re-
trieval - 47th European Conference on Information Retrieval,
ECIR 2025, Lucca, Italy, April 6-10, 2025, Proceedings, Part V,
Lecture Notes in Computer Science. Springer, 2025.
Haoran Wang and Kai Shu. Explainable claim verification via
knowledge-grounded reasoning with large language mod-
els. InFindings of ACL: EMNLP 2023, Singapore, December
6-10, 2023. ACL, 2023.
Zhenrui Yue, Huimin Zeng, Lanyu Shang, Yifan Liu, Yang
Zhang, and Dong Wang. Retrieval augmented fact verifica-
tion by synthesizing contrastive arguments. InProc. 62nd
Annual Meeting of ACL (Volume 1: Long Papers), ACL 2024,
Bangkok, Thailand, August 11-16, 2024. ACL, 2024.
Maximilian Zellner, Ali E. Abbas, David V. Budescu, and
Aram Galstyan. A survey of human judgement and quan-
titative forecasting methods.Royal Society Open Science,
8(2):201187, 2021.
Xuan Zhang and Wei Gao. Towards llm-based fact verification
on news claims with a hierarchical step-by-step prompting
method. InProc. 13th International Joint Conference on
Natural Language Processing and the 3rd Conference of the
Asia-Pacific Chapter of ACL, IJCNLP 2023 -Volume 1: Long
Papers, Nusa Dua, Bali, November 1 - 4, 2023. ACL, 2023.
10

Penghao Zhao, Hailin Zhang, Qinhan Yu, Zhengren Wang,
Yunteng Geng, Fangcheng Fu, Ling Yang, Wentao Zhang,
and Bin Cui. Retrieval-augmented generation for ai-
generated content: A survey.CoRR, 2024.
Yingming Zheng, Xiaoliang Liu, Peng Wu, and Li Pan. CRAVE:
A conflicting reasoning approach for explainable claim
verification using llms.CoRR, 2025.
Yuqicheng Zhu, Nico Potyka, Daniel HernÃ¡ndez, Yuan He,
Zifeng Ding, Bo Xiong, Dongzhuoran Zhou, Evgeny Khar-
lamov, and Steffen Staab. Argrag: Explainable retrieval
augmented generation using quantitative bipolar argumen-
tation.CoRR, 2025.
11

Appendix
Proofs
Proposition 5.Bothğœ” avgandğœ” maxsatisfy Definition 2.
Proof. To proveğœ”avgandğœ”maxsatisfy Definition 2 we fix
ğ‘˜âˆˆ{1,...,ğ¾}andğ‘£=(ğ‘£ 1,...,ğ‘£ğ‘˜)âˆˆ[0,1]ğ‘˜.
Order-independenceFor ğœ”avg, the sumâˆ‘ğ‘˜
ğ‘–=1ğ‘£ğ‘–is invari-
ant under permutations, hence so is1
ğ‘˜âˆ‘ğ‘–ğ‘£ğ‘–. Forğœ”max, the set
{ğ‘£1,...,ğ‘£ğ‘˜}is unchanged by permutation, so its maximum is
unchanged.
BoundednessLet ğ‘š=min(ğ‘£) andğ‘€=max(ğ‘£) . For
ğœ”avg, since min(ğ‘£)â‰¤ğ‘£ ğ‘–â‰¤max(ğ‘£) for allğ‘–,ğ‘˜min(ğ‘£)â‰¤
âˆ‘ğ‘˜
ğ‘–=1ğ‘£ğ‘–â‰¤ğ‘˜max(ğ‘£) , then min(ğ‘£)â‰¤1
ğ‘˜âˆ‘ğ‘˜
ğ‘–=1ğ‘£ğ‘–â‰¤max(ğ‘£) . For
ğœ”max,ğœ”max(ğ‘£)=max(ğ‘£) , somin(ğ‘£)â‰¤ğœ” max(ğ‘£)=max(ğ‘£)â‰¤
max(ğ‘£).
IdempotenceIf ğ‘£=(ğ‘£ğ‘–,...,ğ‘£ğ‘–), thenğœ”avg(ğ‘£)=1
ğ‘˜â‹…ğ‘˜ğ‘£ğ‘–=ğ‘£ğ‘–
andğœ” max(ğ‘£)=max{ğ‘£ ğ‘–,...,ğ‘£ğ‘–}=ğ‘£ğ‘–.
MonotonicityLet ğ‘£â€²=(ğ‘£â€²
1,...,ğ‘£â€²
ğ‘˜)withğ‘£ğ‘–â‰¤ğ‘£â€²
ğ‘–for allğ‘–.
Forğœ”avg,âˆ‘ğ‘˜
ğ‘–=1ğ‘£ğ‘–â‰¤âˆ‘ğ‘˜
ğ‘–=1ğ‘£â€²
ğ‘–, then1
ğ‘˜âˆ‘ğ‘˜
ğ‘–=1ğ‘£ğ‘–â‰¤1
ğ‘˜âˆ‘ğ‘˜
ğ‘–=1ğ‘£â€²
ğ‘–. Thus
ğœ”avg(ğ‘£)â‰¤ğœ” avg(ğ‘£â€²).
Forğœ”max, since each ğ‘£ğ‘–â‰¤ğ‘£â€²
ğ‘–, letğ‘–=arg max(ğ‘£) (i.e.ğ‘£ğ‘–=
max(ğ‘£) ), by assumption ğ‘£ğ‘–â‰¤ğ‘£â€²
ğ‘–hence max(ğ‘£)=ğ‘£ ğ‘–â‰¤ğ‘£â€²
ğ‘–â‰¤
max(ğ‘£â€²). Thusğœ” max(ğ‘£)â‰¤ğœ” max(ğ‘£â€²).
All four properties hold for both aggregation functions. â–¡
Lemma 4.1.Let ğ‘¥âˆ—,ğ‘¦âˆ—âˆˆXâˆ—. Then, (ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆAâˆ—(or
(ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆSâˆ—) iffâˆƒğ‘¥âˆˆğ‘¥âˆ—andâˆƒğ‘¦âˆˆğ‘¦âˆ—such thatâˆƒğ‘–âˆˆ{1,...,ğ‘›}
where(ğ‘¥,ğ‘¦)âˆˆA ğ‘–(or(ğ‘¥,ğ‘¦)âˆˆS ğ‘–, respectively).
Proof.Let us first prove the case forAâˆ—.
(â‡’) By construction of Aâˆ—from Definition 3, since
(ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆAâˆ—, it must be the case that âˆƒ(ğ‘¥,ğ‘¦)âˆˆA , where
ğ‘¥âˆˆğ‘¥âˆ—andğ‘¦âˆˆğ‘¦âˆ—. We know from the same definition that
A=â‹ƒğ‘›
ğ‘—=1Ağ‘—, and so it must be the case that (ğ‘¥,ğ‘¦)âˆˆA ğ‘–for
someğ‘–âˆˆ{1,...,ğ‘›}.
(â‡) We know that (ğ‘¥,ğ‘¦)âˆˆA ğ‘–, for someğ‘–âˆˆ{1,...,ğ‘›} , and
so, according to property (1) in Definition 3, âˆƒ1ğ‘¥âˆ—âˆˆXâˆ—such
thatğ‘¥âˆˆğ‘¥âˆ—, andâˆƒ1ğ‘¦âˆ—âˆˆXâˆ—such thatğ‘¦âˆˆğ‘¦âˆ—. Then, also by
Definition 3, (ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆAâˆ—if(ğ‘¥,ğ‘¦)âˆˆA , which we know is
the case, asA= â‹ƒğ‘›
ğ‘—=1Ağ‘—and soAğ‘–âŠ†A.
The proof similarly follows forSâˆ—.â–¡
Proposition 1.Let Q1,...,Qğ‘›be QBAFs, for ğ‘›>1, where, for
ğ‘–âˆˆ{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©. Then, the combined QBAF
Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©is a QBAF.
Proof. By construction (from Definition 3), Xâˆ—âŠ†2Xwhere
X=â‹ƒğ‘›
ğ‘–=1Xğ‘–. Eachğ‘¥âˆˆX belongs to exactly one cluster
ğ‘¥âˆˆğ‘¥âˆ—âˆˆXâˆ—(property 1 from Definition 3). Hence, Xâˆ—
is a set of arguments. Thus, by construction of Aâˆ—from
Definition 3, Aâˆ—âŠ†Xâˆ—Ã—Xâˆ—. The proof follows similarly for
Sâˆ—âŠ†Xâˆ—Ã—Xâˆ—. Let us prove by contradiction that Aâˆ—âˆ©Sâˆ—=âˆ….
Assume that âˆƒ(ğ‘¥âˆ—,ğ‘¦âˆ—)âˆˆAâˆ—âˆ©Sâˆ—. Then, by Lemma 4.1,
âˆƒğ‘¥,ğ‘¦âˆˆX(ğ‘¥,ğ‘¦)âˆˆAâˆ©S . This cannot be the case as it contradicts
the lingua-franca assumption that no ordered pair is an attack
in one QBAF and a support in another. Hence, we have the
contradiction and Aâˆ—âˆ©Sâˆ—=âˆ…. For each cluster ğ‘¥âˆ—âˆˆXâˆ—,
ğœâˆ—(ğ‘¥âˆ—)=ğœ”(ğœ(ğ‘¥ 1),...,ğœ(ğ‘¥ğ‘˜))withğ‘¥ğ‘–âˆˆXâˆ—, by Definition 3.Since,ğœ”maps to [0,1], by Definition 2, ğœâˆ—âˆ¶Xâˆ—â†’[0,1]is a
total function. Therefore, Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©satisfies the
definition of a QBAF.â–¡
Proposition 2.Let Q1,...,Qğ‘›be QBAFs for the same argu-
mentğ‘“, forğ‘›>1, where, for ğ‘–âˆˆ{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©.
Then, the combined QBAF Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©is a QBAF
for{ğ‘“}.
Proof. We know from Proposition 1 that Qâˆ—is a QBAF, thus
we only need to show that Qâˆ—is a QBAF for {ğ‘“}, so we take
the three conditions for this in turn.
(i) Let us prove by contradiction that âˆ€ğ‘¥âˆ—âˆˆXâˆ—path({ğ‘“},ğ‘¥)=âˆ… .
Assume that âˆƒğ‘¥âˆ—âˆˆXâˆ—path({ğ‘“},ğ‘¥âˆ—)â‰ âˆ… . Then, it must be the
case thatâˆƒğ‘¥âˆ—âˆˆXâˆ—({ğ‘“},ğ‘¥âˆ—)âˆˆAâˆ—âˆªSâˆ—. Then, by Lemma 4.1,
âˆƒğ‘¥âˆˆX(ğ‘“,ğ‘¥)âˆˆAâˆªS . However, we know that this cannot be
the case as âˆ€ğ‘¥âˆˆXpath(ğ‘“,ğ‘¥)=âˆ… (from property (i) of the defi-
nition of a QBAF for ğ‘“) . Hence, we have the contradiction
andâˆ€ğ‘¥âˆ—âˆˆXâˆ—path({ğ‘“},ğ‘¥)=âˆ….
(ii) Let us show that âˆ€ğ‘¥âˆ—âˆˆXâˆ—âˆ–{ğ‘“}âˆ£path(ğ‘¥âˆ—,{ğ‘“}) âˆ£=
1. We know that âˆ€ğ‘¥âˆˆXâˆ–ğ‘“ âˆ£path(ğ‘¥,ğ‘“) âˆ£= 1(from
property (ii) of the definition of a QBAF for ğ‘“), where
path(ğ‘¥,ğ‘“)=âŸ¨(ğ‘¥,ğ‘¥ 1),...,(ğ‘¥ğ‘˜,ğ‘“)âŸ©. Each relation in this path
is(ğ‘¥,ğ‘¥ 1),(ğ‘¥ğ‘–,ğ‘¥ğ‘–+1),(ğ‘¥ğ‘˜,ğ‘“)âˆˆAâˆªS . Then, by Lemma 4.1,
(ğ‘¥âˆ—,ğ‘¥âˆ—
1),(ğ‘¥âˆ—
ğ‘–,ğ‘¥âˆ—
ğ‘–+1),(ğ‘¥âˆ—
ğ‘˜,{ğ‘“})âˆˆAâˆªS , which creates a unique
path path(ğ‘¥âˆ—,{ğ‘“})=âŸ¨(ğ‘¥âˆ—,ğ‘¥âˆ—
1),...,(ğ‘¥âˆ—
ğ‘˜,{ğ‘“})âŸ© . Therefore,
âˆ€ğ‘¥âˆ—âˆˆXâˆ—âˆ–{ğ‘“}âˆ£path(ğ‘¥âˆ—,{ğ‘“}) âˆ£=1.
(iii) Let us prove by contradiction that âˆ€ğ‘¥âˆ—âˆˆXâˆ—path(ğ‘¥âˆ—,ğ‘¥âˆ—)=
âˆ…. Assume that âˆƒğ‘¥âˆ—âˆˆXâˆ—path(ğ‘¥âˆ—,ğ‘¥âˆ—)â‰ âˆ… . Let this path be
âŸ¨(ğ‘¥âˆ—,ğ‘¥âˆ—
1), ...,
(ğ‘¥âˆ—
ğ‘˜,ğ‘¥âˆ—)âŸ©. By Lemma 4.1, each relation (ğ‘¥âˆ—
ğ‘–,ğ‘¥âˆ—
ğ‘–+1)in this
cycle corresponds to an underlying relation (ğ‘¥ğ‘–,ğ‘¥ğ‘–+1)âˆˆ
AâˆªS , whereğ‘¥ğ‘–âˆˆğ‘¥âˆ—
ğ‘–andğ‘¥ğ‘–+1âˆˆğ‘¥âˆ—
ğ‘–+1, giving a path
âŸ¨(ğ‘¥,ğ‘¥ 1),...,(ğ‘¥ğ‘˜,ğ‘¥)âŸ©, whereğ‘¥,ğ‘¥ 1,ğ‘¥ğ‘˜âˆˆXğ‘–. However, Qğ‘–can-
not have cycles (from property (iii) of a QBAF for ğ‘“). This
contradicts our assumption. Therefore, no cycles can exist in
Qâˆ—.
All three properties hold, therefore Qâˆ—is a QBAF for {ğ‘“}.
â–¡
Proposition 3.Let Q1,...,Qğ‘›be QBAFs for the same argu-
mentğ‘“, forğ‘›>1, where, for ğ‘–âˆˆ{1,...,ğ‘›} ,Qğ‘–=âŸ¨Xğ‘–,Ağ‘–,Sğ‘–,ğœğ‘–âŸ©.
Then, the combined QBAF Qâˆ—=âŸ¨Xâˆ—,Aâˆ—,Sâˆ—,ğœâˆ—âŸ©from Defi-
nition 3 preserves pro/con arguments in the original QBAFs,
i.e., for Pro(ğ‘„ğ‘–)(Con(ğ‘„ğ‘–)) the set of pro-arguments (con-
arguments, respectively) forQâˆ—:
âˆ€ğ‘¥âˆ—âˆˆXâˆ—(ğ‘¥âˆ—âˆˆPro(Qâˆ—)â‡”(âˆƒğ‘¥âˆˆğ‘¥âˆ—,ğ‘–âˆˆ{1,...,ğ‘›}ğ‘¥âˆˆPro(Q ğ‘–))),
and
âˆ€ğ‘¥âˆ—âˆˆXâˆ—(ğ‘¥âˆ—âˆˆCon(Qâˆ—)â‡”(âˆƒğ‘¥âˆˆğ‘¥âˆ—,ğ‘–âˆˆ{1,...,ğ‘›}ğ‘¥âˆˆCon(Q ğ‘–))).
Proof.Let us first prove the case for pro-arguments.
We know from Proposition 2 thatQâˆ—is a QBAF for{ğ‘“}.
(â‡’) We know that ğ‘¥âˆ—âˆˆPro(Qâˆ—). By definition of
pro-arguments, the unique path ğ‘âˆ—=path(ğ‘¥âˆ—,{ğ‘“})=
âŸ¨(ğ‘¥âˆ—,ğ‘¦âˆ—),...,(ğ‘§âˆ—,{ğ‘“}) has an even number of attacks, i.e.
âˆ£ğ‘âˆ—âˆ©Aâˆ—âˆ£is even. Each relation in this path is
(ğ‘¥âˆ—,ğ‘¥âˆ—
1),(ğ‘¥âˆ—
ğ‘—,ğ‘¥âˆ—
ğ‘—+1),(ğ‘¥âˆ—
ğ‘˜,{ğ‘“})âˆˆAâˆ—âˆªSâˆ—. By Lemma 4.1,
each relation (ğ‘¥âˆ—,ğ‘¥âˆ—
1),(ğ‘¥âˆ—
ğ‘—,ğ‘¥âˆ—
ğ‘—+1),(ğ‘¥âˆ—
ğ‘˜,{ğ‘“}) in this path corre-
sponds to an underlying relation (ğ‘¥,ğ‘¥ 1),(ğ‘¥ğ‘—,ğ‘¥ğ‘—+1),(ğ‘¥ğ‘˜,ğ‘“)âˆˆ
AâˆªS , which creates a path ğ‘=path(ğ‘¥,ğ‘“)=
12

âŸ¨(ğ‘¥,ğ‘¥ 1),...,(ğ‘¥ğ‘˜,ğ‘“)âŸ©. Thus, âˆ£ğ‘âˆ—âˆ©Aâˆ—âˆ£=âˆ£ğ‘âˆ©A ğ‘–âˆ£. Since
âˆ£ğ‘âˆ—âˆ©Aâˆ—âˆ£is even, âˆ£ğ‘âˆ©Ağ‘–âˆ£must also be even. By definition
of pro-arguments, this meansğ‘¥âˆˆPro(Q ğ‘–).
(â‡) We know that âˆƒğ‘¥âˆˆğ‘¥âˆ—ğ‘¥âˆˆPro(Q ğ‘–), for some Qğ‘–. By
the definition of pro-arguments, this means the path ğ‘=
path(ğ‘¥,ğ‘“)=âŸ¨(ğ‘¥,ğ‘¥ 1),...,(ğ‘¥ğ‘˜,ğ‘“)âŸ© inQğ‘–has an even number
of attacks, i.e. âˆ£ğ‘âˆ©Ağ‘–âˆ£is even. Each relation in this path
is(ğ‘¥,ğ‘¥ 1),(ğ‘¥ğ‘—,ğ‘¥ğ‘—+1),(ğ‘¥ğ‘˜,ğ‘“)âˆˆAâˆªS . By Lemma 4.1, each
relation (ğ‘¥,ğ‘¥ 1),(ğ‘¥ğ‘—,ğ‘¥ğ‘—+1),(ğ‘¥ğ‘˜,ğ‘“)in this path corresponds to
a relation (ğ‘¥âˆ—,ğ‘¥âˆ—
1),(ğ‘¥âˆ—
ğ‘—,ğ‘¥âˆ—
ğ‘—+1),(ğ‘¥âˆ—
ğ‘˜,{ğ‘“})âˆˆAâˆ—âˆªSâˆ—, which
creates a path ğ‘âˆ—=path(ğ‘¥âˆ—,{ğ‘“})=âŸ¨(ğ‘¥âˆ—,ğ‘¦âˆ—),...,(ğ‘§âˆ—,{ğ‘“}) .
Thus,âˆ£ğ‘âˆ—âˆ©Aâˆ—âˆ£=âˆ£ğ‘âˆ©Ağ‘–âˆ£. Sinceâˆ£ğ‘âˆ©Ağ‘–âˆ£is even, âˆ£ğ‘âˆ—âˆ©Aâˆ—âˆ£
must also be even. By definition, this meansğ‘¥âˆˆPro(Qâˆ—).
The same logic applies to con arguments, where the num-
ber of attacks is odd. Thus the combined QBAF preserves the
set of pro/con arguments of the original argument within the
clustered arguments.â–¡
Proposition 4.Algorithm 1 terminates and returns a com-
bined QBAF in polynomial time.
Proof. To prove that Algorithm 1 terminates we need to show
that all the loops are finite. Main loop (Line 3) iterates up to
the finite maximum depth of the input QBAFs. First inner
loop (Line 5) iterates through a finite number of arguments
in the previous depth. Second inner loop (Line 6) iterates
through all pairs of finite arguments in the current depth.
Third inner loop (Line 15) iterates through a finite number of
arguments in the previous depth and the merged clusters. All
inner loops iterate over finite sets. Therefore, the algorithm
is guaranteed to terminate.
The proof is by double induction. The outer induction is
on the number of QBAFs, ğ‘›. The inner induction is on the
depth of QBAFs,ğ‘‘.
(Outer Induction) Base case:ğ‘›=2
We show that the algorithm correctly produces a combined
QBAF given two QBAFs Q1andQ2. This is proven using an
inner induction on depthğ‘‘.
(Inner Induction) Base case: ğ‘‘= 0Lines 1 initialises
the combined QBAF where Xâˆ—is initialised with singleton
clusters for all arguments in ğ‘¥âˆˆX , and only setting the
base score of ğ‘toğœâˆ—(ğ‘âˆ—)=ğœ”(ğœ 1(ğ‘),ğœ 2(ğ‘)). This correctly
implements the base score definition for the root. Thus, the
proposition holds forğ‘‘=0.
(Inner Induction) Inductive HypothesisAssume that
for all depths ğ‘‘â€²<ğ‘˜(whereğ‘˜â‰¥1), the algorithm has correctly
constructed the combined QBAF, and all properties from
Definition 3 hold for arguments and relations up to depth
ğ‘˜âˆ’1.
(Inner Induction) Inductive Step: ğ‘‘=ğ‘˜ We show that
iterationğ‘˜of the main loop (Line 5) correctly constructs the
combined QBAF for depthğ‘˜.
1.Correct construction of Xâˆ—: Line 6 identifies all argu-
ments at depth ğ‘˜, and Lines 7-12 partitions them into
clusters.â€¢The algorithm initialises {ğ‘¥}âˆˆXâˆ—with singleton
clusters for all arguments in ğ‘¥âˆˆX . The merging
process on Line 8 combines existing clusters. Since
an argument ğ‘¥starts in a unique singleton cluster
{ğ‘¥}and clusters are only ever merged, ğ‘¥will al-
ways belong to exactly one cluster, thus satisfying
property (1) of Definition 3.
â€¢(â‡’) Assumeğ‘¥,ğ‘¦are added to the same cluster ğ‘¥âˆ—
(Line 8), then we know there exists ğ‘§,ğ‘§â€²âˆˆğ‘§âˆ—âˆˆXâˆ—
with(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆA or(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆS (Line 6)
andÎ¨(ğ‘¥,ğ‘¦)â‰¥ğ›¿ (Line 7). ( â‡) Now assume we
haveğ‘§,ğ‘§â€²âˆˆğ‘§âˆ—âˆˆXâˆ—with(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆA or
(ğ‘¥,ğ‘§),(ğ‘¦,ğ‘§â€²)âˆˆS , and Î¨(ğ‘¥,ğ‘¦)â‰¥ğ›¿ . These condi-
tions lead to the execution of adding ğ‘¥,ğ‘¦to the
same clusterğ‘¥âˆ—(Line 8).
2.(â‡’) Assume the algorithm (Line 19) adds (ğ‘¥âˆ—,ğ‘§âˆ—)toAâˆ—,
which is executed if and only if the condition (Line 18),
âˆƒğ‘¥âˆˆğ‘¥âˆ—,âˆƒğ‘§âˆˆğ‘§âˆ—such that (ğ‘¥,ğ‘§)âˆˆA , is true. This di-
rectly matches one direction of the definition. ( â‡) Now
assume there exists an attack (ğ‘¥,ğ‘§) whereğ‘¥âˆˆğ‘¥âˆ—and
ğ‘§âˆˆğ‘§âˆ—, withğ‘¥âˆ—being a new cluster at depth ğ‘˜andğ‘§âˆ—
a cluster at depth ğ‘˜âˆ’1. Since the algorithm iterates
through all such new clusters ğ‘¥âˆ—and all previous argu-
mentsğ‘§(Line 15), the condition (Line 18) is evaluated
for the specific pair (ğ‘¥,ğ‘§) and found to be true. Conse-
quently, the relation (ğ‘¥âˆ—,ğ‘§âˆ—)will be added to Aâˆ—. Thus,
the algorithm constructsSâˆ—exactly as defined.
3.Similar considerations apply to the support relations,
Sâˆ—, w.r.t. Lines 15 and 21-23.
4.Assume given an arbitrary cluster ğ‘¥âˆ—âˆˆXâˆ—created at
iterationğ‘˜. The algorithm (Line 17) assigns the base
score to the cluster ğ‘¥âˆ—asğœâˆ—(ğ‘¥âˆ—)=ğœ”(ğœ(ğ‘¥) âˆ£ğ‘¥âˆˆğ‘¥âˆ—).
This exactly matches the property in Definition 3.
By the principle of induction on ğ‘‘, the algorithm is correct
for all depths whenğ‘›=2.
(Outer Induction) Inductive Hypothesis
Assume Algorithm 1 has correctly constructed the combined
QBAF forğ‘›=ğ‘š QBAFs, where ğ‘šâ‰¥2, and all properties from
Definition 3 are satisfied.
(Outer Induction) Inductive Step:ğ‘›=ğ‘š+1
We show the algorithm is correct for ğ‘›=ğ‘š+ 1QBAFs. The
proof follows the same inner induction on depth ğ‘‘. The algo-
rithmâ€™s output is independent of the value of ğ‘›; it operates
on the union of all arguments. Since, set union is order inde-
pendent (satisfies associativity) the reasoning for each step of
the inner induction holds identically for ğ‘›=ğ‘š+ 1QBAFs as
it does forğ‘›=2. Thus, by the principle of double induction,
the proposition is proven for allğ‘›>1.
To show that the algorithm executes in polynomial time,
letğ‘›be the number of QBAFs, ğ‘=âˆ£Xâˆ£ be the total number
of arguments across all frameworks, and ğ·be the maximum
depth of any input QBAF. The main loop (Lines 3-26) runs
ğ·times. Inside the main loop, the second loop (Lines 5-14)
iterates over ğ‘§in â€˜previous layerâ€™, where â€˜previous layerâ€™ is
at mostğ‘. Inside the second loop, the third loop (Lines 6-13)
13

iterates over all pairs (ğ‘¥,ğ‘¦) that are related to ğ‘§. In the worst
case, a single node could be the parent of all arguments, which
gives time complexity ğ‘‚(ğ‘2). So, the total complexity for
the second loop is ğ‘‚(ğ‘3). The last loop (Lines 15-24) iterates
overğ‘§in â€˜previous layerâ€™ and ğ‘¥âˆ—in â€˜mergedâ€™, which could be
at mostğ‘if all clusters are singletons. The second loop and
the last loop, each iteration of the main loop over ğ·takes
at mostğ‘‚(ğ‘3)=ğ‘‚(ğ‘3)+ğ‘‚(ğ‘2)time. Since the main loop
iteratesğ·times, the total complexity is ğ‘‚(ğ·Ã—ğ‘3). Thus the
algorithm executes in polynomial time.â–¡
Query Generation for the Guardian API
Here, we explain the query generation step to be passed to
the Guardian API to retrieve the relevant articles for the
forecasting claims.
In order to generate queries we use the following prompt:
You are a **Query Generator Agent**. Your task
is to convert a claim into **5 high-quality search
queries**, using Boolean AND/OR, synonyms, and
phrase quotes. **Do not use numeric range opera-
tors like 550000..800000 or natural language com-
parisons (greater than, less than).**
Example: Input: Claim: â€™UK inflation will go up by
the end of 2025â€™ Output: 1. ("UK inflation" OR "UK
consumer price index") AND ("end of 2025" OR "late
2025") AND (forecast OR outlook) 2. ("Bank of Eng-
land" AND interest rate AND inflation AND ("Q4
2025" OR "end -2025")) 3. ("UK CPI" AND ("price
growth" OR inflation) AND ("Dec 2025" OR "2025
forecast"))
â€”
Input: Claim: {claim}
Each forecasting claim is passed into the prompt to get up
to five queries.
9 Multi-Agent Claim Verification
9.1 ArgLLM Agent Pairs
Table 3 reports results for depth 1 and depth 2 for the GJOpen
and Metaculus datasets.
9.2 RAG-ArgLLM Agent Pairs
Table 4 and Table 5 report results for the multi-agent frame-
work using RAG-ArgLLM agents with NYTimes and Guardian
(respectively) for the GJOpen and Metaculus datasets.
9.3 Two-Agent Combination
Tables 6 and 7 show the results of combining two RAG-
ArgLLM agents, where one uses NYTimes and the other uses
Guardian as external sources. Tables 8 and 9 present results
where ArgLLM agents are paired with RAG-ArgLLM agents
using NYTimes. Tables 10 and 11 shows similar pairings but
with Guardian as the external source.9.4 Three-Agent Combination
The results, presented in Tables 12-23, demonstrate the three
agent combinations.
14

Mistral Gemma Gemma-2 Llama-3 GPT-4o Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 65/71 73/57 79/77 78/75 74/69 Single 56/67 70/56 79/77 63/75 69/68
Mixtral 67/70 67 /74 72/7470/7471/57 70/74 72/74 68/75 77/75 68/6876/69 56/69 49/64 49/64 59/7254/68 59/72 54/68 43/74 49/75 46/65 56/67
Mistral 65/71 - - 69/56 71/56 70/74 71/74 69/75 75/75 67/6875/68 56/67 - - 54/6854/6854/68 54/68 49/75 49/75 56/67 56/67
Gemma 73/57 - - - - 70/74 71/74 73/7678 /7872/70 76/70 70/56 - - - - 54/68 54/68 50/70 50/70 69/68 69/68
Gemma-2 79/77 - - - - - - 78/7878/7876/7874/77 79/77 - - - - - - 50/70 50/70 43/75 43/75
Llama-3 78/75 - - - - - - - - 74/69 74/68 63/75 - - - - - - - - 56/67 56/67
MetaculusSingle 61/70 76/73 68/66 81/65 81/74 Single 61/68 76/73 68/66 81/65 82/76
Mixtral 66/74 63/7562/7572/73 74/74 65/66 66/66 66/74 66/74 73/7677/73 61/73 57/7955/7863/72 68/7459/60 61/62 66/7666/7656/72 71/73
Mistral 61/70 - - 61/60 71/72 61/60 60/59 61/70 61/70 72/74 69/73 62/67 - - 65/7455/55 55/55 55/55 61/7461/7463/75 46/70
Gemma 76/73 - - - - 61/60 71/69 68/66 76/73 73/72 70/69 71/73 - - - - 55/55 61/61 76/73 68/66 62/74 56/56
Gemma-2 68/66 - - - - - - 68/66 68/66 73/72 70/69 67/66 - - - - - - 68/66 68/66 62/63 56/56
Llama-3 81/65 - - - - - - - - 81 /74 81/74 78/65 - - - - - - - - 82 /7682/76
Table 3: Accuracy results of our multi-agent combination framework applied to pairs of ArgLLM agents for Depth 1 (left) and Depth 2
(right). We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates
improvement over both Single agents; underline indicates improvement over one and parity with the other.
Mistral Gemma Gemma-2 Llama-3 GPT-4o Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 59/68 71/66 76/75 78/44 72/66 Single 52/68 64/63 75/75 75/50 71/66
Mixtral 61/7162/74 67/7363/65 63/70 61/70 63/70 61/7161/71 64/66 72 /67 49/67 40/63 50/67 48/59 43/54 48/59 43/54 37/49 48/51 49/59 49/59
Mistral 59/68 - - 66/7268/66 66/72 68/72 65/7365/7366/67 72 /66 52/68 - - 48/56 46/59 49/62 46/59 41/49 48/50 52/62 52/62
Gemma 71/66 - - - - 66/72 63/70 76/7576/7571/7371/68 64/63 - - - - 75 /7546/59 53/54 37/57 64/6764/67
Gemma-2 76/75 - - - - - - 76/75 37/57 71/73 75 /75 75/75 - - - - - - 66/71 76/75 75/75 37/56
Llama-3 78/44 - - - - - - - - 72/66 72/66 75/50 - - - - - - - - 75 /6875 /68
MetaculusSingle 79/80 81/73 81/78 79/68 78/73 Single 61/78 72/74 76/74 78/66 79/73
Mixtral 71/78 76/8176/8171/76 71/76 71/72 71/72 71/78 71/78 74/76 75/77 52/72 48/70 56/72 49/69 53/68 52/55 47/51 41/63 52/66 52/66 52/66
Mistral 79/80 - - 79/77 79/76 79/77 79/77 79 /80 79/80 78/77 77/78 61/78 - - 62/72 61/64 61/63 61/64 53/67 56/65 61/69 61/69
Gemma 81/73 - - - - 79/77 81 /7881/78 81 /7378/7778/77 72/74 - - - - 61/63 69/68 64/70 44/47 72/74 76/74
Gemma-2 81/78 - - - - - - 81 /78 81 /78 78/77 78/77 76/74 - - - - - - 71/70 44/47 76/74 76/74
Llama-3 79/68 - - - - - - - - 78/73 78/73 78/66 - - - - - - - - 78/72 78/72
Accuracy results of our multi-agent combination framework applied to pairs of ArgLLM agents for Depth 1 (left) and Depth 2 (right). We show accuracy results using 0.5/estimated
base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥ (Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity
with the other.
Table 4: Accuracy results of our multi-agent combination framework applied to pairs of RAG-ArgLLM agents with NYTimes for Depth 1
(left) and Depth 2 (right). We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations.
Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the other.
Mistral Gemma Gemma-2 Llama-3 GPT-4o Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 66/74 72/64 78/76 78/76 71/67 Single 51/68 64/63 77/76 74/52 72/67
Mixtral 61/72 63/74 67/74 63/63 64/70 63/70 64/70 61/72 61/72 64/67 71 /67 48/68 38/62 47/67 48/60 41/55 48/60 41/55 36/50 51/52 49/60 49/60
Mistral 66/74 - - 68/72 70/64 68/72 69/72 66/74 66/74 66/67 71 /67 51/68 - - 48/57 46/57 51/62 46/57 39/51 48/51 51/61 56/66
Gemma 72/64 - - - - 68/72 64/70 78 /76 78/7671/7472 /69 64/63 - - - - 77 /7646/57 52/56 38/59 64/67 77/76
Gemma-2 78/76 - - - - - - 78 /76 78/7671/74 72/74 77/76 - - - - - - 71/73 38/59 77 /76 77/76
Llama-3 78/76 - - - - - - - - 71/67 71/67 74/52 - - - - - - - - 74 /6874 /68
MetaculusSingle 79/80 80/76 81/78 79/70 79/76 Single 66/77 68/73 80/78 73/68 80/76
Mixtral 69/73 72/79 73/79 71/74 70/73 68/68 69/68 69/73 69/73 71/75 73/76 55/73 53/74 60/74 54/68 53/68 54/56 44/48 45/64 55/66 55/69 55/69
Mistral 79/80 - - 79/77 79/76 79/77 79/77 79 /80 79/8079/7780/77 66/77 - - 63/71 63/63 66/66 63/63 56/66 61/66 66/71 66/71
Gemma 80/76 - - - - 79/77 80/78 81/7880 /7679/7879/78 68/73 - - - - 66/66 64/63 62/69 45/48 68/72 80 /78
Gemma-2 81/78 - - - - - - 81 /78 81/7879/78 79/78 80/78 - - - - - - 76/75 45/48 80 /78 80/78
Llama-3 79/70 - - - - - - - - 79 /76 79/76 73/68 - - - - - - - - 73/76 73/76
Table 5: Accuracy results of our multi-agent combination framework applied to pairs of RAG-ArgLLM agents with Guardian for Depth 1
(left) and Depth 2 (right). We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations.
Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the other.
15

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 61/72 61/72 66/74 66/74 72/64 72/64 78/76 78/76 78/76 78/76 71/67 71/67
Mixtral 61/71 61 /72 61/72 63/74 68/74 64/63 63/69 62/69 63/69 62/69 63/69 63/67 71 /67
Mistral 59/6862/74 67/7366 /74 66/74 66/7169/64 66/71 67/72 66/71 67/72 66/68 72/67
Gemma 71/66 63/7463/7367/74 68/74 78/76 78/7678 /76 78/76 72/74 72/74 71 /68 72/68
Gemma-2 76/75 61/73 63/73 67/74 68/7478/76 78/7678 /76 78/76 76/75 76/75 71/68 71/68
Llama-3 78/44 61/7576/7566/7676/7776/7576/7576/75 76/75 78 /76 78/76 72/67 72/67
GPT-4o 72/66 64/7471/7466/7572 /7670/62 72 /62 72/73 73/74 72/73 73/74 71/67 71/67
MetaculusSingle 69/73 69/73 79/80 79/80 80/76 80/76 81/78 81/78 79/70 79/70 79/76 79/76
Mixtral 71/78 69/73 69/73 74/8176/80 72/77 72/77 71/72 71/72 74/71 74/70 74/76 74/77
Mistral 79/80 71/77 73/77 79 /80 79/80 79/78 79/78 79/78 79/77 78/74 78/74 79 /77 79 /79
Gemma 81/73 68/73 69/73 79/80 79/80 80/76 81/7881 /78 81/78 79/70 79/70 79/76 79/76
Gemma-2 81/78 69/73 69/73 79/80 79/80 81/78 80/76 81 /78 81/78 79/70 79/70 79/76 79/76
Llama-3 79/68 70/7570/7578/8179 /8179/76 78/75 79/78 79/78 79/70 79/70 77/76 77/76
GPT-4o 78/73 70/7471/7477/78 77/78 78/7778/7778/77 78/77 78/72 77/72 79 /76 79/76
Table 6: Accuracy results of our multi-agent combination framework applied to RAG-ArgLLM agents with Guardian (columns) and RAG-
ArgLLM agents with NYTimes (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max)
base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the
other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 49/67 34/57 42/60 40/62 48/66 49/59 42/54 49/59 42/54 38/50 49/52 36/52 48/57
Mistral 52/68 37/63 48/66 40/65 50/68 49/59 46/59 52/63 46/59 41/50 49/51 39/60 50/63
Gemma 64/63 49/6946/7046/6950/69 73/74 69/7073/74 69/70 53/54 37/50 65/6936/60
Gemma-2 75/75 49/69 41/65 51/68 46/63 73/74 69/70 73/74 69/70 67/55 37/50 65/69 36/60
Llama-3 75/50 32/7036/7437/7039/7371/7336/56 71/73 36/56 34/50 28/49 35/64 37/64
GPT-4o-mini 71/66 30/62 38/68 33/66 39/7067/7040/57 67/70 37/56 30/50 32/49 34/64 34/63
MetaculusSingle 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 52/72 36/56 44/57 51/70 56/70 49/71 54/69 53/55 45/47 44/64 53/66 41/61 54/67
Mistral 61/78 47/71 54/69 57/73 62/74 63/70 59/62 61/62 59/62 56/67 57/65 55/69 61/71
Gemma 72/74 57/72 47/69 61/77 65/74 71/72 67/68 75/74 67/68 72/70 50/65 65/7751/72
Gemma-2 76/74 57/72 47/69 66/76 65/74 71/72 73/71 76/74 73/71 72/70 48/66 73/7751/72
Llama-3 78/66 38/73 42/7656/7854/7961/73 44/71 77/75 38/42 45/67 41/65 47/73 53/71
GPT-4o-mini 79/73 32/63 47/70 54/77 57/7978/7648/70 78/76 46/47 42/65 45/64 48/72 51/71
Table 7: Accuracy results of our multi-agent combination framework applied to RAG-ArgLLM agents with Guardian (columns) and RAG-
ArgLLM agents with NYTimes (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max)
base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the
other.
16

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 67/70 67/70 65/71 65/71 73/57 73/57 79/77 79/77 78/75 78/75 74/69 74/69
Mixtral 61/71 67 /70 67 /70 63/72 67/7265/56 69/7569/75 69/75 67/75 77/7665/68 74 /68
Mistral 59/68 66/73 72/7365 /71 65/71 70/7669/57 70/76 70/75 69/75 76/75 68/69 74/69
Gemma 71/66 67/7368/7166/71 67/72 79/77 79/7779 /77 79/77 72/7672/7673/69 74/70
Gemma-2 76/75 67/72 68/71 66/71 67/7279/77 79/7779 /77 79/77 75/7675/7673/69 73/69
Llama-3 78/44 66/7577/7565/7574/7678 /7878 /7778/7878/77 78/75 78/75 76/69 74/68
GPT-4o 72/66 67/74 73/7466/74 73/7571/54 73 /55 75/76 73/76 73/75 72/75 74/69 74/69
MetaculusSingle 66/74 66/74 61/70 61/70 76/73 76/73 68/66 68/66 81/65 81/65 81/74 81/74
Mixtral 71/78 66/74 66/74 61/76 60/72 72/74 76 /73 67/67 67/67 71/67 80/66 78/74 80/75
Mistral 79/80 71/75 71/75 61/70 61/70 69/68 77/74 69/68 69/69 75/68 80/70 80/76 80/76
Gemma 81/73 67/74 66/74 61/70 61/70 76/73 67/66 68/66 67/66 81 /65 81 /65 81 /74 81/75
Gemma-2 81/78 66/74 66/74 61/70 61/70 68/66 76/73 68/66 68/66 81 /65 81 /65 81 /74 81 /74
Llama-3 79/68 69/7670/7664/7165/7276/7476/73 70/68 69/68 81/65 81 /65 81 /7681 /75
GPT-4o 78/73 70/7671/7668/7466/7569/69 68/67 69/69 68/67 77/68 77/68 81 /74 81/74
Table 8: Accuracy results of our multi-agent combination framework applied to ArgLLM agents (columns) and RAG-ArgLLM agents
with NYTimes (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score
aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 56/69 56/69 56/67 56/67 70/56 70/56 79/77 79/77 63/75 63/75 69/68 69/68
Mixtral 61/71 41/66 54/67 44/64 56/6955/6952/67 55/69 52/67 37/70 46/74 38/62 63/68
Mistral 59/68 42/68 55/7045/65 55/6955/52 53/67 56/71 53/67 42/73 47/75 42/65 59/67
Gemma 71/66 56/7049/7152/7053/70 75/7670 /7575/76 70/75 52/74 42/73 68/7033/63
Gemma-2 76/75 56/70 45/67 56/69 50/64 75 /7670/75 75/76 70/75 65/7642/73 68/70 33/63
Llama-3 78/44 41/7245/7446/7148/7372/7748/7572/77 48/75 31/75 31/75 37/66 46/66
GPT-4o 72/66 37/7044/7242/6847/7067/7646/48 67/76 47/73 28/73 33/74 36/65 42/65
MetaculusSingle 61/73 61/73 62/67 62/67 71/73 71/73 67/66 67/66 78/65 78/65 82/76 82/76
Mixtral 71/78 45/69 61 /70 46/66 44/64 62/71 69/7447/48 50/52 35/62 49/66 37/60 56/67
Mistral 79/80 51/7062/71 55/72 55/70 69/73 57/60 56/57 57/60 53/66 51/65 53/68 60/71
Gemma 81/73 57/71 55/70 61/72 60/6776/73 57/57 61/61 57/57 72/68 38/65 65/75 45/71
Gemma-2 81/78 57/71 55/70 62/71 60/67 76 /73 59/60 65/66 59/60 72/68 33/64 74/76 45/71
Llama-3 79/68 54/7560/7759/7738/7663/73 62/72 55/56 45/48 36/65 33/65 46/71 65/72
GPT-4o 78/73 46/72 56/73 61/7745/7856/57 57/72 56/57 49/51 30/65 42/65 48/70 59/71
Table 9: Accuracy results of our multi-agent combination framework applied to ArgLLM agents (columns) and RAG-ArgLLM agents
with NYTimes (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score
aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the other.
17

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 67/70 67/70 65/71 65/71 73/57 73/57 79/77 79/77 78/75 78/75 74/69 74/69
Mixtral 61/72 67 /70 67 /70 62/72 67/72 65/56 69/7567/76 69/75 67/75 77/75 66/6875/69
Mistral 66/74 66/74 71/73 65/71 65/71 71/7669/57 71/76 71/76 70/7677/75 69/68 74 /68
Gemma 72/64 68/7469/7167/71 67/71 79/77 79/7779 /77 79/77 72/7672/7674 /7074 /70
Gemma-2 78/76 68/71 69/71 67/71 67/7179/77 79/7779 /77 79/77 77/76 77/76 74/70 74/70
Llama-3 78/76 68/71 69/71 67/71 67/71 78 /7778 /7778/77 78/77 78/75 78 /75 74/70 74/70
GPT-4o 71/67 68/75 74/7566/74 72/7570/54 73 /56 74/77 73/77 72/75 71/75 74/69 74/69
MetaculusSingle 66/74 66/74 61/70 61/70 76/73 76/73 68/66 68/66 81/65 81/65 81/74 81/74
Mixtral 69/73 66/74 66/74 59/7460/71 69/7474/7465/66 68/68 66/66 79/66 76/74 80/73
Mistral 79/80 70/77 72/77 61/70 61/70 68/68 77/74 68/68 69/69 76/66 80/72 80/75 80/76
Gemma 80/76 71/7767/74 61/70 61/70 76/73 68/67 68/66 68/67 81 /65 81 /65 81 /74 81 /77
Gemma-2 81/78 67/74 67/74 61/70 61/70 68/66 76/73 68/66 68/66 81 /65 81 /65 81 /74 81 /74
Llama-3 79/70 69/7772/7767/7470/7576/7476/73 71/70 70/68 81 /65 81 /65 79/7679/76
GPT-4o 79/76 70/76 74/76 68/76 69/76 70/71 71/71 70/71 71/71 79/71 79/71 81 /74 81 /74
Table 10: Accuracy results of our multi-agent combination framework applied to ArgLLM agents (columns) and RAG-ArgLLM agents
with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score
aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpenSingle 56/69 56/69 56/67 56/67 70/56 70/56 79/77 79/77 63/75 63/75 69/68 69/68
Mixtral 61/72 39/65 54/67 42/65 55/6954/7152/67 54/71 52/67 35/72 46/75 37/63 65/68
Mistral 66/74 42/68 54/7043/65 55/68 54/52 53/66 54/70 53/66 39/74 46/75 40/64 60/67
Gemma 72/64 57/7149/7152/6952/69 77/77 74/7677/77 74/76 51/75 42/7373/7135/64
Gemma-2 78/76 57/71 46/67 57/69 49/63 77 /7774/76 77/77 74/76 68/76 42/73 73/71 35/64
Llama-3 78/76 43/7349/7547/7150/7373/7749/7473/77 49/74 32/75 33/75 38/66 50/66
GPT-4o 71/67 37/7046/7242/6847/7168/7747/49 68/77 47/74 28/74 31/74 36/65 41/65
MetaculusSingle 61/73 61/73 62/67 62/67 71/73 71/73 67/66 67/66 78/65 78/65 82/76 82/76
Mixtral 69/73 50/6965/70 47/65 44/65 63/71 69/7446/49 48/52 37/63 53/66 41/60 65/70
Mistral 79/80 51/73 66 /72 56/67 56/68 66/72 63/62 59/60 63/62 56/65 53/65 56/69 65/73
Gemma 80/76 61/73 51/68 59/7661/6877/7456/56 61/61 56/56 76/66 35/65 63/74 40/71
Gemma-2 81/78 61/73 51/68 63/70 61/68 77/74 57/57 66/66 57/57 76/66 26/65 79/77 40/71
Llama-3 79/70 56/7460/7659/7642/7667/73 63/72 57/59 46/49 41/66 35/65 51/73 62/72
GPT-4o 79/76 52/72 59/72 63/7944/7857/59 60/73 57/59 46/47 35/66 41/65 50/72 56/71
Table 11: Accuracy results of our multi-agent combination framework applied to ArgLLM agents (columns) and RAG-ArgLLM agents
with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score
aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over one and parity with the other.
18

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 67/70Single 61/71 61/71 59/68 59/68 71/66 71/66 76/75 76/75 78/44 78/44 72/66 72/66
Mixtral 61/7268/7068/7068/7068/70 68/70 68/70 68/70 68/70 68/70 68/70 68/70 68/70
Mistral 66/7471/7371/73 71/7371/73 71 /73 71/7371/73 71/73 71/73 71/73 71/73 71 /73
Gemma 72/64 69/71 69/71 69/7169/71 69/7469/7469/74 69/74 69/7469/74 69/7169/71
Gemma-2 78/76 69/71 69/71 69/71 69/71 69/71 69/71 69/71 69/71 69/71 69/71 69/71 69/71
Llama-3 78/76 69/71 69/71 69/71 69/71 69/71 69/7169/71 69/71 69/71 69/71 69/71 69/71
GPT-4o 71/6774/75 74/75 74/75 74/75 74/75 74/7574/75 74/75 74/7574/7574/75 74/75
Metaculus - 66/74Single 71/78 71/78 79/80 79/80 81/73 81/73 81/78 81/78 79/68 79/68 78/73 78/73
Mixtral 69/73 68/74 68/74 68/74 68/74 68/74 68/74 68/74 68/74 68/74 68/74 68/74 68/74
Mistral 79/80 72/77 72/77 72/77 72/77 72/77 72/77 72/77 72/77 72/77 72/77 72/77 72/77
Gemma 80/76 67/74 67/74 67/74 67/74 71/7771/7767/74 67/74 67/74 67/74 71/7771/77
Gemma-2 81/78 67/74 67/74 67/74 67/74 67/74 67/74 67/74 67/74 67/74 67/74 67/74 67/74
Llama-3 79/70 72/77 72/7772/77 72/77 72/7772/7772/77 72/77 72/7772/7772/7772/77
GPT-4o 79/76 74/76 74/7674/76 74/76 74/76 74/76 74/76 74/76 74/76 74/7674/76 74/76
Table 12: Accuracy results of our multi-agent combination framework applied to ArgLLM with Mixtral, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 65/71Single 61/71 61/71 59/68 59/68 71/66 71/66 76/75 76/75 78/44 78/44 72/66 72/66
Mixtral 61/7267/72 67/72 67/72 67/72 67/72 67/7267/72 67/72 67/72 67/72 67/72 67/72
Mistral 66/7470/7370/73 70/7370/73 70/73 70/7370/73 70/73 70/73 70/73 70/73 70/73
Gemma 72/64 69/7469/7467/71 67/71 67/71 67/71 67/71 67/71 69/7469/74 69/7469/74
Gemma-2 78/76 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71
Llama-3 78/76 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71 67/71
GPT-4o 71/6772/7572 /75 72/7572 /75 72/7572 /7572/75 72/75 72/7572/75 72 /7572 /75
Metaculus - 61/70Single 71/78 71/78 79/80 79/80 81/73 81/73 81/78 81/78 79/68 79/68 78/73 78/73
Mixtral 69/73 60/71 60/71 60/71 60/71 60/71 60/71 60/71 60/71 60/71 60/71 60/71 60/71
Mistral 79/80 65/76 65/76 65/76 65/76 65/76 65/76 65/76 65/76 65/76 65/76 65/76 65/76
Gemma 80/76 65/71 65/71 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70
Gemma-2 81/78 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70 61/70
Llama-3 79/70 70/75 70/7570/75 70/75 70/7570/75 70/75 70/75 70/7570/7570/7570/75
GPT-4o 79/76 69/76 69/7669/76 69/76 69/76 69/76 69/76 69/76 69/76 69/7669/76 69/76
Table 13: Accuracy results of our multi-agent combination framework applied to ArgLLM with Mistral, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
19

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 73/57Single 61/71 61/71 59/68 59/68 71/66 71/66 76/75 76/75 78/44 78/44 72/66 72/66
Mixtral 61/72 69/7569/7566/56 66/56 69/7569/7566/56 66/56 69/7569/75 66/56 66/56
Mistral 66/74 69/57 69/57 71/7671/7671/7671/7669/57 69/57 69/57 69/57 69/57 69/57
Gemma 72/64 73 /56 73 /56 73 /57 73 /5778/77 78/7773/56 73/56 74/7774/7773 /57 73 /57
Gemma-2 78/76 73/57 73/57 73/57 73/57 78 /77 78/7773/57 73/57 73/57 73/57 73/57 73/57
Llama-3 78/76 73/57 73/57 78 /7778 /7778 /7778 /7773/57 73/57 78 /7778 /7773/57 73/57
GPT-4o 71/67 73 /56 73 /56 73 /7773 /7773 /56 73 /56 73/56 73/56 73/56 73/56 73 /7773 /77
Metaculus - 76/73Single 71/78 71/78 79/80 79/80 81/73 81/73 81/78 81/78 79/68 79/68 78/73 78/73
Mixtral 69/73 68/68 68/68 68/68 68/68 74/7474/74 74/74 74/74 74/7474/74 68/68 68/68
Mistral 79/80 77/74 77/74 77/74 77/74 77/74 77/74 77/74 77/74 77/74 77/74 77/74 77/74
Gemma 80/76 68/67 68/67 68/66 68/66 68/66 68/66 68/66 68/66 76/73 76/73 76/73 76/73
Gemma-2 81/78 76/73 76/73 68/66 68/66 68/66 68/66 68/66 68/66 76/73 76/73 68/66 68/66
Llama-3 79/70 70/68 70/68 76/73 76/73 76/73 76/73 70/68 70/68 70/68 70/68 76/73 76/73
GPT-4o 79/76 78/73 78 /73 78/73 78/73 71/71 71/71 78/73 78/73 78/73 78/73 71/71 71/71
Table 14: Accuracy results of our multi-agent combination framework applied to ArgLLM with Gemma, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 79/77Single 61/71 61/71 59/68 59/68 71/66 71/66 76/75 76/75 78/44 78/44 72/66 72/66
Mixtral 61/72 69/75 69/75 69/75 69/75 69/75 69/75 69/75 69/75 69/75 69/75 69/75 69/75
Mistral 66/74 71/76 71/76 71/76 71/76 71/76 71/76 71/76 71/76 71/76 71/76 71/76 71/76
Gemma 72/64 74/77 74/77 78/77 78/77 78/77 78/77 74/77 74/77 74/77 74/77 78/77 78/77
Gemma-2 78/76 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77
Llama-3 78/76 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77 78/77
GPT-4o 71/67 73/77 73/77 73/77 73/77 73/77 73/77 73/77 73/77 73/77 73/77 73/77 73/77
Metaculus - 68/66Single 71/78 71/78 79/80 79/80 81/73 81/73 81/78 81/78 79/68 79/68 78/73 78/73
Mixtral 69/73 68/68 68/68 68/68 68/68 68/68 68/68 68/68 68/68 68/68 68/68 68/68 68/68
Mistral 79/80 69/69 69/69 69/69 69/69 69/69 69/69 69/69 69/69 69/69 69/69 69/69 69/69
Gemma 80/76 68/67 68/67 68/66 68/66 68/66 68/66 68/66 68/66 68/67 68/67 68/67 68/67
Gemma-2 81/78 68/66 68/66 68/66 68/66 68/66 68/66 68/66 68/66 68/66 68/66 68/66 68/66
Llama-3 79/70 70/68 70/68 70/68 70/68 70/68 70/68 70/68 70/68 70/68 70/68 70/68 70/68
GPT-4o 79/76 71/71 71/71 71/71 71/71 71/71 71/71 71/71 71/71 71/71 71/71 71/71 71/71
Table 15: Accuracy results of our multi-agent combination framework applied to ArgLLM with Gemma-2, RAG-ArgLLM agents with
NYTimes (columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base
scores andğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates
improvement over one and parity with the other.
20

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 78/75Single 61/71 61/71 59/68 59/68 71/66 71/66 76/75 76/75 78/44 78/44 72/66 72/66
Mixtral 61/72 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75
Mistral 66/74 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75 77/75
Gemma 72/64 72/7672/7672/7672/7672/7672/7672/7672/76 72/7672/76 77/7677/76
Gemma-2 78/76 77/76 77/7677/76 77/7677/76 77/7677/76 77/76 77/76 77/76 77/76 77/76
Llama-3 78/76 77/76 77/7677/76 77/7677/76 77/7677/76 77/76 77/76 77/76 77/76 77/76
GPT-4o 71/67 71/75 71/75 71/75 71/75 71/75 71/75 71/75 71/75 71/75 71/75 71/75 71/75
Metaculus - 81/65Single 71/78 71/78 79/80 79/80 81/73 81/73 81/78 81/78 79/68 79/68 78/73 78/73
Mixtral 69/73 79/66 79/66 79/66 79/66 79/66 79/66 79/66 79/66 79/66 79/66 79/66 79/66
Mistral 79/80 80/72 80/72 80/72 80/72 80/72 80/72 80/72 80/72 80/72 80/72 80/72 80/72
Gemma 80/76 80/69 80/69 80/69 80/69 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65
Gemma-2 81/78 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65 81 /65
Llama-3 79/70 80/67 80/67 80/67 80/67 80/67 80/67 80/67 80/67 80/67 80/67 80/67 80/67
GPT-4o 79/76 79/71 79/71 79/71 79/71 79/71 79/71 79/71 79/71 79/71 79/71 79/71 79/71
Table 16: Accuracy results of our multi-agent combination framework applied to ArgLLM with Llama-3, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 74/69Single 61/71 61/71 59/68 59/68 71/66 71/66 76/75 76/75 78/44 78/44 72/66 72/66
Mixtral 61/7275/6975/6975/6975/6975/6975/69 75/69 75/69 75/69 75/6975/6975/69
Mistral 66/74 74 /68 74 /68 74 /68 74 /68 74 /68 74 /68 74/68 74/68 74/68 74/68 74 /68 74 /68
Gemma 72/64 74 /70 74 /70 74 /7074 /70 74 /7074 /7074/70 74/70 74/7074/70 74 /7074 /70
Gemma-2 78/76 74/70 74/70 74/70 74/70 74/70 74/70 74/70 74/70 74/70 74/70 74/70 74/70
Llama-3 78/76 74/70 74/70 74/70 74/70 74/70 74/7074/70 74/70 74/70 74/70 74/70 74/70
GPT-4o 71/6775/6875/6875/6875/6875/6875/68 75/68 75/68 75/68 75/6875/6875/68
Metaculus - 81/74Single 71/78 71/78 79/80 79/80 81/73 81/73 81/78 81/78 79/68 79/68 78/73 78/73
Mixtral 69/73 80/73 80/73 80/73 80/73 80/73 80/73 80/73 80/73 80/73 80/73 80/73 80/73
Mistral 79/80 80/76 80/76 80/76 80/76 80/76 80/76 80/76 80/76 80/76 80/76 80/76 80/76
Gemma 80/76 81 /74 81 /74 81/74 81 /74 81 /7781 /7781 /77 81 /77 81 /7781 /7781 /7781 /77
Gemma-2 81/78 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74 81 /74
Llama-3 79/70 79/76 79/7679/76 79/76 79/7679/76 79/76 79/76 79/7679/7679/7679/76
GPT-4o 79/76 80/74 80/74 80/74 80/74 80/74 80/74 80/74 80/74 80/74 80/74 80/74 80/74
Table 17: Accuracy results of our multi-agent combination framework applied to ArgLLM with GPT-4o, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 1. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
21

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 56/69Single 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 61/72 28/60 42/67 28/66 43/7043/7048/7053/71 48/70 26/68 33/7465/7369/74
Mistral 66/74 30/65 44/7031/68 43/7153/7248/7153/72 48/71 28/7136/7469/7370/74
Gemma 72/64 56/7247/7246/7356/7255/69 42/7055/69 42/70 49/7561/7471/7570/74
Gemma-2 78/76 56/72 54/69 62/74 56/72 55/69 45/69 55/69 42/65 67/7761/74 71/75 62/73
Llama-3 78/76 27/68 34/7430/7037/7446/7441/7356/74 41/73 27/7328/7464/7464/74
GPT-4o 71/67 68/74 72/74 72/74 73/7467/7463/7467/74 49/74 67/7466/7428/7128/72
Metaculus - 61/73Single 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 69/73 31/65 51/68 37/70 57/72 59/72 54/71 59/72 56/70 30/7445/7673/76 79/76
Mistral 79/80 45/71 57/73 44/72 60/72 52/72 53/72 59/72 56/72 45/76 54/76 77/77 79/77
Gemma 80/76 53/7663/71 51/74 55/74 52/71 46/69 57/71 46/69 61/7767/74 77/7973/77
Gemma-2 81/78 64/7563/71 64/74 63/73 61/72 53/70 57/71 50/70 73/7767/74 77/7973/77
Llama-3 79/70 36/73 47/7644/74 55/76 63/7548/7663/75 51/75 35/7640/7572/7774/77
GPT-4o 79/76 72/7576/7576/76 77/75 67/7667/7667/76 57/76 75/7576/7636/72 39/73
Table 18: Accuracy results of our multi-agent combination framework applied to ArgLLM with Mixtral, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 56/67Single 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 61/72 32/59 46/67 33/62 48/6953/6947/7153/69 50/68 33/66 39/7364/7468/75
Mistral 66/74 34/60 47/6934/63 46/6944/6946/7152/69 49/68 34/67 40/7367/7469/75
Gemma 72/64 45/6953/68 60/7249/7156/7049/6856/70 45/62 51/7346/7470/7565/74
Gemma-2 78/76 56/70 53/68 60/72 56/71 61/71 49/68 56/67 45/62 68/7659/75 71/7659/73
Llama-3 78/76 34/65 41/7335/68 42/7347/7242/7356/73 44/71 35/7134/7369/7567/76
GPT-4o 71/67 66/7469/75 72/75 74/7670/7553/7367/74 53/73 72/7670/7636/6930/71
Metaculus - 62/67Single 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 69/73 45/67 45/64 49/74 53/72 52/7448/69 56/73 48/69 48/7540/7752/76 51/77
Mistral 79/80 50/70 54/70 54/73 60/72 62/74 57/75 62/74 60/72 54/77 47/78 63/7960/79
Gemma 80/76 54/74 44/67 59/77 60/77 65/70 55/74 65/70 55/74 63/8039/7870/7745/78
Gemma-2 81/78 54/74 44/67 59/75 56/70 65/70 59/69 65/70 59/69 68/7936/7577/7945/78
Llama-3 79/70 52/7445/7855/75 55/7866/7846/7866/78 45/75 56/7932/7864/7847/78
GPT-4o 79/76 51/7550/7662/7861/7969/8053/8067/78 47/7965/7846/7960/7840/78
Table 19: Accuracy results of our multi-agent combination framework applied to ArgLLM with Mistral, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
22

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 70/56Single 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 61/72 45/68 47/67 47/7150/7154/52 50/7463/75 49/52 50/50 41/7756/50 49/72
Mistral 66/74 45/6947/47 45/48 46/47 62/54 47/49 62/54 54/70 53/7640/7657/51 53/48
Gemma 72/64 51/51 49/65 57/7247/72 73/7754/53 73/7768/74 74 /7844/7272 /56 45/48
Gemma-2 78/76 60/55 49/65 57/72 49/6576/7654/53 76/76 68/74 74/7844/72 72/56 45/48
Llama-3 78/76 49/50 43/7754/7643/7770/59 44/48 70/59 48/75 66/7731/48 73/7745/48
GPT-4o 71/67 55/7249/7260/7655/4873/57 51/49 73/57 51/49 67/52 46/48 63/7632/76
Metaculus - 71/73Single 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 69/73 55/66 56/72 57/70 66/74 57/56 52/54 61/61 61/73 46/47 43/46 54/54 56/56
Mistral 79/80 57/71 57/56 55/55 61/61 65/65 59/60 65/65 59/60 61/72 50/52 73/73 70/74
Gemma 80/76 56/56 55/72 59/60 65/72 69/73 52/53 69/73 53/5578/7549/73 74/73 55/56
Gemma-2 81/78 56/56 47/48 72/75 65/72 69/73 52/53 69/73 60/6978/7545/48 80 /7853/54
Llama-3 79/70 48/50 46/49 62/73 61/74 64/63 57/73 74/74 57/73 56/56 35/41 75/74 65/74
GPT-4o 79/76 54/55 66/72 66/66 71/73 71/70 55/56 76/73 62/72 74/7453/55 61/72 38/41
Table 20: Accuracy results of our multi-agent combination framework applied to ArgLLM with Gemma, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 79/77Single 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 61/72 45/68 47/67 47/71 50/71 63/75 50/74 63/75 53/71 53/76 41/77 55/73 49/72
Mistral 66/74 45/69 49/71 47/72 49/73 57/75 54/70 63/74 54/70 53/76 40/76 56/75 49/75
Gemma 72/64 54/73 49/65 57/72 47/72 73/77 68/74 73/77 68/74 74/7844/72 72/77 46/73
Gemma-2 78/76 56/71 49/65 57/72 49/65 76/76 68/74 76/76 68/74 74/7844/72 72/77 46/73
Llama-3 78/76 52/75 43/77 54/76 43/77 68/77 48/75 73/77 48/75 66/77 32/77 73/77 45/76
GPT-4o 71/67 55/72 49/72 60/76 51/75 70/76 50/76 76/7850/76 74/77 44/76 63/76 32/76
Metaculus - 67/66Single 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 69/73 43/45 47/50 51/52 56/56 57/56 52/54 61/61 52/53 46/47 43/46 54/54 56/56
Mistral 79/80 52/51 57/56 55/55 61/61 65/65 59/60 65/65 59/60 56/56 50/52 70/69 66/65
Gemma 80/76 56/56 47/48 59/60 59/61 66/66 52/53 66/66 53/55 63/63 45/48 74/73 55/56
Gemma-2 81/78 56/56 47/48 66/68 56/60 64/65 52/53 64/65 56/56 72/71 45/48 80 /7853/54
Llama-3 79/70 48/50 46/49 56/56 56/57 64/63 48/52 66/66 48/50 56/56 35/41 68/67 54/55
GPT-4o 79/76 54/55 55/56 66/66 63/63 71/70 55/56 71/70 51/51 68/68 53/55 56/56 38/41
Table 21: Accuracy results of our multi-agent combination framework applied to ArgLLM with Gemma-2, RAG-ArgLLM agents with
NYTimes (columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base
scores andğœ”ğ‘ğ‘£ğ‘”(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates
improvement over one and parity with the other.
23

Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 63/75Single 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 61/72 26/65 36/74 28/70 39/75 44/74 43/75 52/74 42/75 26/74 28/75 53/74 62/75
Mistral 66/74 30/69 39/75 31/73 39/75 44/74 42/75 52/75 41/74 28/75 32/75 61/75 64/75
Gemma 72/64 60/75 54/7165/7655/75 56/7647/72 56/76 39/74 70/7865/75 67/7662/75
Gemma-2 78/76 60/75 54/71 65/7655/75 56/7647/72 56/76 40/71 70/7865/75 72/7753/75
Llama-3 78/76 27/73 30/75 30/75 34/75 47/75 33/75 57/75 28/74 26/75 25/75 65/75 66/75
GPT-4o 71/67 56/75 64/75 64/75 67/75 71/7656/75 71/76 44/75 66/75 65/75 28/74 25/74
Metaculus - 78/65Single 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 69/73 25/54 34/65 35/61 47/65 53/65 37/65 61/68 34/65 28/64 30/65 65/65 74/65
Mistral 79/80 43/64 50/65 40/64 50/64 50/67 40/65 56/68 37/65 45/65 46/65 72/67 75/65
Gemma 80/76 53/69 48/62 51/67 49/63 41/65 23/64 41/65 23/64 76/71 61/64 78/74 73/64
Gemma-2 81/78 62/71 51/60 64/70 49/63 41/65 23/64 41/65 23/64 76/71 61/64 78/74 76/65
Llama-3 79/70 33/65 34/65 42/65 43/65 60/66 28/65 71/65 24/65 35/66 28/65 74/66 73/65
GPT-4o 79/76 61/66 67/64 70/66 69/65 72/66 55/65 72/66 42/65 75/66 71/65 33/66 32/65
Table 22: Accuracy results of our multi-agent combination framework applied to ArgLLM with Llama-3, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
Mixtral Mistral Gemma Gemma-2 Llama-3 GPT-4o
Avg Max Avg Max Avg Max Avg Max Avg Max Avg Max
GJOpen - 69/68Single 49/68 49/68 51/68 51/68 64/63 64/63 77/76 77/76 74/52 74/52 72/67 72/67
Mixtral 61/72 26/55 43/66 28/57 43/66 61/68 42/66 61/68 44/66 26/62 32/65 71/68 72/68
Mistral 66/74 28/57 42/65 31/61 41/66 48/66 42/65 61/68 42/65 28/63 33/65 72 /68 72/68
Gemma 72/64 61/6947/64 66/7154/66 62/68 33/65 62/68 30/62 50/68 61/6775/7471/68
Gemma-2 78/76 61/69 53/62 66/71 54/66 59/69 39/63 59/69 30/62 70/72 61/67 75 /74 65/68
Llama-3 78/76 27/61 33/65 28/63 35/66 66/68 38/66 66/68 40/65 27/65 26/65 72/6970/69
GPT-4o 71/6772/68 73/68 75/69 75/69 74/6949/66 74/69 49/66 74 /6972/6928/65 26/65
Metaculus - 82/76Single 55/73 55/73 66/77 66/77 68/73 68/73 80/78 80/78 73/68 73/68 80/76 80/76
Mixtral 69/73 36/53 44/54 39/61 49/71 66/72 51/71 66/72 57/71 31/63 32/69 27/57 28/62
Mistral 79/80 51/62 56/66 46/64 56/70 68/73 47/70 68/73 54/71 46/69 51/71 43/67 47/70
Gemma 80/76 66/76 54/68 69/75 61/71 66/72 32/69 66/72 32/70 77/8056/71 59/73 55/70
Gemma-2 81/78 66/76 63/67 69/75 61/71 64/75 32/70 64/75 32/70 77/8072/73 76/8071/73
Llama-3 79/70 44/66 53/71 45/69 48/70 64/72 49/71 73/76 53/71 36/72 34/71 34/72 32/70
GPT-4o 79/76 33/62 36/63 42/66 43/66 72/75 45/70 72/75 53/71 38/73 37/70 35/72 32/71
Table 23: Accuracy results of our multi-agent combination framework applied to ArgLLM with GPT-4o, RAG-ArgLLM agents with NYTimes
(columns), and RAG-ArgLLM agents with Guardian (rows) for Depth 2. We show accuracy results using 0.5/estimated base scores and ğœ”ğ‘ğ‘£ğ‘”
(Avg) andğœ”ğ‘šğ‘ğ‘¥(Max) base score aggregations. Bold indicates improvement over both Single agents; underline indicates improvement over
one and parity with the other.
24