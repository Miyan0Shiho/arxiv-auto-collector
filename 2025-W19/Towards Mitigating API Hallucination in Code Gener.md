# Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware

**Authors**: Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, Yuchi Ma

**Published**: 2025-05-08 08:48:17

**PDF URL**: [http://arxiv.org/pdf/2505.05057v1](http://arxiv.org/pdf/2505.05057v1)

## Abstract
Application Programming Interfaces (APIs) are crucial in modern software
development. Large Language Models (LLMs) assist in automated code generation
but often struggle with API hallucination, including invoking non-existent APIs
and misusing existing ones in practical development scenarios. Existing studies
resort to Retrieval-Augmented Generation (RAG) methods for mitigating the
hallucination issue, but tend to fail since they generally ignore the
structural dependencies in practical projects and do not indeed validate
whether the generated APIs are available or not. To address these limitations,
we propose MARIN, a framework for mitigating API hallucination in code
generated by LLMs with hierarchical dependency aware. MARIN consists of two
phases: Hierarchical Dependency Mining, which analyzes local and global
dependencies of the current function, aiming to supplement comprehensive
project context in LLMs input, and Dependency Constrained Decoding, which
utilizes mined dependencies to adaptively constrain the generation process,
aiming to ensure the generated APIs align with the projects specifications. To
facilitate the evaluation of the degree of API hallucination, we introduce a
new benchmark APIHulBench and two new metrics including Micro Hallucination
Number (MiHN) and Macro Hallucination Rate (MaHR). Experiments on six
state-of-the-art LLMs demonstrate that MARIN effectively reduces API
hallucinations, achieving an average decrease of 67.52% in MiHN and 73.56% in
MaHR compared to the RAG approach. Applied to Huaweis internal projects and two
proprietary LLMs, MARIN achieves average decreases of 57.33% in MiHN and 59.41%
in MaHR.

## Full Text


<!-- PDF content starts -->

Towards Mitigating API Hallucination in Code Generated by
LLMs with Hierarchical Dependency Aware
Yujia Chen
yujiachen@stu.hit.edu.cn
Harbin Institute of Technology
Shenzhen, ChinaMingyu Chen
220110123@stu.hit.edu.cn
Harbin Institute of Technology
Shenzhen, ChinaCuiyun Gao
gaocuiyun@hit.edu.cn
Harbin Institute of Technology
Shenzhen, China
Zhihan Jiang
jiangzhihan2@huawei.com
Huawei Cloud Computing
Technologies Co., Ltd.
Shenzhen, ChinaZhongqi Li
lizhongqi7@huawei.com
Huawei Cloud Computing
Technologies Co., Ltd.
Shenzhen, ChinaYuchi Ma
mayuchi1@huawei.com
Huawei Cloud Computing
Technologies Co., Ltd.
Shenzhen, China
Abstract
Application Programming Interfaces (APIs) are crucial in modern
software development. Large Language Models (LLMs) assist in
automated code generation but often struggle with API hallucina-
tion, including invoking non-existent APIs and misusing existing
ones in practical development scenarios. Existing studies resort to
Retrieval-Augmented Generation (RAG) methods for mitigating
the hallucination issue, but tend to fail since they generally ignore
the structural dependencies in practical projects and do not indeed
validate whether the generated APIs are available or not. To address
these limitations, we propose MARIN, a framework for mitigating
API hallucination in code generated by LLMs with hierarchical
dependency aware. MARIN consists of two phases: Hierarchical
Dependency Mining , which analyzes local and global dependen-
cies of the current function, aiming to supplement comprehensive
project context in LLMs’ input, and Dependency Constrained De-
coding , which utilizes mined dependencies to adaptively constrain
the generation process, aiming to ensure the generated APIs align
with the project’s specifications. To facilitate the evaluation of the
degree of API hallucination, we introduce a new benchmark APIHul-
Bench and two new metrics including Micro Hallucination Number
(MiHN) and Macro Hallucination Rate (MaHR). Experiments on
six state-of-the-art LLMs demonstrate that MARIN effectively re-
duces API hallucinations, achieving an average decrease of 67.52%
in MiHN and 73.56% in MaHR compared to the RAG approach.
Applied to Huawei’s internal projects and two proprietary LLMs,
MARIN achieves average decreases of 57.33% in MiHN and 59.41%
in MaHR.
CCS Concepts
•Software and its engineering →Software development tech-
niques ;•Computing methodologies →Artificial intelligence .
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
FSE Companion ’25, June 23–28, 2025, Trondheim, Norway
©2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 979-8-4007-1276-0/2025/06
https://doi.org/10.1145/3696630.3728569Keywords
Large language model, code generation, LLM hallucination
ACM Reference Format:
Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi
Ma. 2025. Towards Mitigating API Hallucination in Code Generated by
LLMs with Hierarchical Dependency Aware. In 33rd ACM International
Conference on the Foundations of Software Engineering (FSE Companion ’25),
June 23–28, 2025, Trondheim, Norway. ACM, New York, NY, USA, 12 pages.
https://doi.org/10.1145/3696630.3728569
1 INTRODUCTION
In modern software development, developers frequently leverage
application programming interfaces (APIs) to integrate complex
functionalities into their projects efficiently [ 3,4,26,36,40]. The
advent of large language models (LLMs) has revolutionized this
process, with AI-powered coding assistants greatly enhancing de-
velopers’ productivity by generating code snippets automatically [ 2,
19,25,35,44]. However, despite their impressive capabilities, LLMs
still face notable challenges in industrial development scenarios.
A recent study evaluating six mainstream LLMs on practical code
generation shows that 31.67% of erroneous code directly results
from incorrect API usage, a phenomenon named “API hallucina-
tions” [ 45], including invoking non-existent APIs, misusing existing
APIs, and incorrectly using arguments [ 14]. Such mistakes increase
debugging complexity since they can propagate errors in subse-
quent programming. Moreover, a recent study reports that 29% of
security vulnerabilities in the Linux kernel in 2021 were traced
back to improper API usage [ 17]. Given the critical role of APIs
in developers’ daily workflows and the severe consequences of
their misuse, exploring effective mitigation methods has become a
critical research focus. Existing studies primarily rely on Retrieval-
Augmented Generation (RAG) techniques [ 6,14,45], which first
construct the retrieval corpora including API documentation and
code snippets from the project, and then integrate the retrieved
relevant information into the input prompt. While these studies
have demonstrated success in mitigating API hallucination, they
still face the following limitations.
1) Ignoring structural dependencies in projects . When develop-
ers call APIs, they typically rely on the structural dependencies
of the current code snippet, such as relationships with other func-
tions and modules, to ensure proper API usage within the projectarXiv:2505.05057v1  [cs.SE]  8 May 2025

FSE Companion ’25, June 23–28, 2025, Trondheim, Norway Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi Ma
①Incomplete Function ③Retrieved Code Snippetget②Skeleton of Related Files@Overridepublicbooleanupdate(IChatServiceservice, Worldworld, Agentagent) {LOG.info("[Updater / Reaction] Checking if an agent will react to an observation");Reactionreaction= service.getReaction(agent, observation);if(reaction.[API_Position]}publicclassReaction{privatebooleanreact;// ... omitted for brevity...publicvoidsetReact(booleanreact) {}publicbooleanwillReact() {}}publicclassWorld{privateSet<Agent> agents;publicWorld() {}publicvoidsave(Agentagent) {} publicSet<Agent> getAgents() {}// ... omitted for brevity...}Reactionreaction= newReaction();// ... omitted for brevity...booleanwillReact= json.get("react").asBoolean();if(willReact) { // ... omitted for brevity... }reaction.setReact(willReact);// ... omitted for brevity...
Ground Truth: willReact()
get-0.88is   -0.98will-2.45
act    -0.01action -5.10</s>   -5.55
()) -0.16()-1.93().-5.37
④Failure caused byUnconstrained GenerationgetRe
Re-0.26E-1.87Current  -3.62getReactgetReact())
Figure 1: The motivation example: A Wrong API generated by CodeLLama-7B with RAG.
context. However, existing approaches fail to consider these criti-
cal dependencies, and instead, they offer isolated code snippets as
references for LLMs. As illustrated in Figure 1 1○, the incomplete
function attempts to determine whether an agent will react, and
the correct API to be used is willReact . However, the retrieved
code snippet (Figure 1 3○) fails to provide sufficient context from
related files (Figure 1 2○) where the willReact method is defined.
Besides, maintaining a retrieval corpus with updated indexing in-
troduces additional resource costs, limiting the scalability of such
approaches.
2) Unconstrained API generation. Existing approaches utilize auto-
regressive decoding, where tokens are generated solely based on
model probabilities without explicit constraints on the output space
of API tokens. This unconstrained process often leads to the gen-
eration of invalid API tokens. As demonstrated in Figure 1 4○, the
model generates candidate API tokens get,Re,act,()), which does
not match the intended API willReact defined in the Reaction
class. Such errors occur because the model lacks constraints to align
generated tokens with the actual project specifications, resulting
in incorrect and infeasible API calls. This highlights the need to
enforce output validity during the decoding process.
Our work. To address these limitations, in this paper, we propose
MARIN, a framework designed to Mitigate API hallucination in
code gene Rated by LLMs with h Ierarchical depe Ndency aware.
Specifically, MARIN comprises two phases: 1) Hierarchical Depen-
dency Mining. This phase uses static analysis to analyze local and
global dependencies of the current function, such as method call
relationships and file dependencies, forming a structural repre-
sentation of the project to enrich LLM’s input prompt. 2) Depen-
dency Constrained Decoding. This phase adaptively constrains the
token generation process using valid API patterns derived from the
mined dependencies, ensuring the alignment of generated APIs with
project specifications. Through the two phases, MARIN employs
project structural dependencies both in supplying the input and
guiding the generation, eliminating the need for retrieval corpora
construction, thus enabling effective API hallucination mitigation
in the code generation process of LLMs.
Existing API hallucination evaluation benchmarks suffer from
potential data leakage from older repositories [ 6] or reliance onmodel-synthesized data [ 14,32]. Therefore, we introduce APIHul-
Bench, a novel benchmark, comprising 416 high-quality samples
from 98 recent Java repositories on GitHub. It encompasses two
different coding processes: APIHulBench-F (221 samples) where de-
velopers initiate new functions, and APIHulBench-M (195 samples)
where developers have written most of the code in functions. For
evaluating the degree of API hallucination, we also propose two
new metrics: Micro Hallucination Number (MiHN), which quan-
tifies the number of hallucinated elements within one generated
API, and Macro Hallucination Rate (MaHR), which measures the
proportion of the generated APIs containing hallucinations. We
apply MARIN to six state-of-the-art LLMs with varying architec-
tures and sizes (CodeLlama-7B/13B/34B [ 30] and DeepSeekCoder-
1.3B/6.7B/33B [ 11]) using the APIHulBench benchmark. Experimen-
tal results demonstrate that MARIN can significantly mitigate API
hallucination of LLM-generated code, with an average decrease of
67.52% in MiHN and 73.56% in MaHR as well as an average increase
of 107.3% in exact match (EM) and 44.79% in edit similarity (ES) com-
pared to RAG approach. To further validate MARIN’s effectiveness
in industry settings, we construct an additional benchmark compris-
ing 109 samples from Huawei’s internal projects and apply MARIN
on Huawei’s proprietary LLMs (PanguCoder-11B/34B [ 31]). The
results indicate that MARIN effectively and efficiently mitigates API
hallucination, achieving an average decrease of 59.41% in MaHR
and an average increase of 72.39% in EM, with only an average
0.031s overhead increase compared to the base model. We release
APIHulBench at https://github.com/yujiachen99/APIMitigation.
Contributions. The main contributions of our paper are summa-
rized below:
•To the best of our knowledge, we are the first to systematically
investigate API hallucination in the code generation process
under practical scenarios and propose one benchmark and two
metrics.
•We propose MARIN, a novel framework that supplements hier-
archical dependencies externally and constrains the decoding
process internally, mitigating API hallucination in the code gen-
eration process of LLMs.
•We evaluate MARIN on both open-source and industrial scenar-
ios. Experimental results show that our framework outperforms

Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware FSE Companion ’25, June 23–28, 2025, Trondheim, Norway
packagecom.luv2code.aopdemo;importcom.luv2code.aopdemo.dao.AccountDAO;importorg.springframework.boot.SpringApplication;@SpringBootApplicationpublicclassAopdemoApplication{publicstaticvoidmain(String[] args) {SpringApplication.run(AopdemoApplication.class, args);}// ... omitted for brevity...privatevoiddemoTheBeforeAdvice(AccountDAOtheAccountDAO) {theAccountDAO.addAccount();}}Third-party LibraryProject Library
Third-party APIProject-specific API
(a) An illustration example of two types of APIsCL-7B CL-13B DSC-1.3B DSC-6.7B00.51
0.15 0.11 0.13 0.120.83 0.85 0.87 0.86MaHRThird-party APIs Project-specific APIs
(b) Hallucination across different API types
CL-7B CL-13B DSC-1.3B DSC-6.7B0.60.81 0.83 0.85 0.87 0.86
0.73 0.72 0.72 0.77
0.65 0.69 0.7 0.690.56 0.53 0.58 0.57MaHRBase RAG Project files API reference
(c) Hallucination in different input contexts
Figure 2: Analysis of API hallucinations across different dimensions.
baselines, effectively and efficiently mitigating API hallucination
and improving code generation quality.
2 PRELIMINARY STUDY
To better understand API hallucination in the industrial scenario,
we conduct a preliminary study using a Huawei internal project.
The study explores the prevalence of hallucinations across dif-
ferent API types and input contexts. We collect a dataset of 200
code snippets, including 100 third-party library API calls and 100
project-specific API calls, covering common API usage patterns in
industrial software [ 29], as shown in Figure 2(a). The evaluation
involves four widely-used LLMs, including CodeLlama-7B/13B [ 30]
and DeepSeek-Coder-1.3B/6.7B [ 11], and a metric for measuring
the portion of hallucinated APIs, named MaHR.
2.1 Hallucination in Different API Types
We input the collected code snippets into the four LLMs and analyze
the proportion of hallucinated APIs. As shown in Figure 2(b), the
models generate few hallucinations for third-party library APIs,
with an average rate of only 12.75%. However, for project-specific
APIs, the hallucination rate is much higher, averaging 85.25%. This
indicates that while models handle third-party library APIs well
due to their frequent presence in training data, they struggle with
project-specific APIs due to a lack of contextual awareness. Notably,
larger models show only marginal improvements in reducing hal-
lucinations compared to smaller models, indicating that increasing
model size alone is insufficient to address this issue. These findings
highlight the challenge of API hallucination in industrial scenarios,
especially for project-specific APIs.
2.2 Impact of Different Input Contexts
To further explore ways to mitigate hallucination in project-specific
APIs, we design four input context scenarios: (1) Base, only using
the collected code snippets; (2) RAG [45], using BM-25 to retrieve
similar code snippets from the project; (3) Project files , including
all project files randomly; (4) API reference , explicitly providing
validated APIs as guidance. The results are shown in Figure 2(c),
and we make the following observations:
•Observation 1: Including more project information (Sce-
nario 3) improves performance and even outperforms theRAG-based approach (Scenario 2). This highlights the im-
portance of a broader project context for API hallucination
mitigation. However, due to context window limits, it is not
feasible to include all project files.
•Observation 2: Including API references in the input context
(Scenario 4) helps reduce some hallucinations, but the rates
remain still very high, averaging 44% across four models.
This indicates that API references alone are insufficient to
fully guide the model toward accurate API generation.
In summary, our study highlights the challenges of mitigating
API hallucination, particularly for project-specific APIs. While a
broader project context improves performance, it is limited by input
constraints. Additionally, providing API information alone fails to
reduce the hallucination issue. These results emphasize the need for
more effective approaches to address API hallucination in industrial
development.
3 APPROACH
In this section, we propose MARIN, a framework to mitigate API
hallucination in code generated by LLMs with hierarchical depen-
dency aware. We first present the overview of MARIN and then
describe its details in the following subsections.
3.1 Overview
Given a project and an incomplete function, MARIN generates a
complete API call by a two-phase approach: (1) In the hierarchical
dependency mining phase, it extracts both local dependencies (i.e.,
called functions and reference APIs) and global dependencies (i.e.,
related files and the current file), enriching the input prompt to
provide better context for LLM. (2) In the dependency constrained
decoding phase, the extracted dependencies are used to guide the
generated API calls to align with the project’s specifications by
constructing valid API name prefix trees and identifying parameter
patterns.
3.2 Hierarchical Dependency Mining
As shown in Figure 3 ❶, MARIN analyzes dependencies at two
levels: local (function-level) and global (file-level), constructing a
hierarchical structure of the project. This structure decomposes the
project top-down, from files down to detailed functions. Beyond

FSE Companion ’25, June 23–28, 2025, Trondheim, Norway Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi Ma
ProjectIncompleteFunction
LLM VocabularyProjectFileClassesFunctions
❶HierarchicalDependencyMining StaticAnalysis
❷DependencyConstrainedDecoding 
API Name Prefix TreeParameterPatterns✦setReact✦willReact✦getCurrentActivity✦setCurrentActivity
setget())) (){ (). …(‘ (@ (‘--…
LLMInputOriginalLogits11010
⊕MaskVectorModifiedLogitsOutputII. ConstrainedDecoding I. Dependency Preprocessing
ProjectDescription
IncompleteFunctionInputPromptCachedValidTokensrootwillReactCurrentActivity④ReferenceAPIs②CurrentFile①RelatedFiles③CalledFunctionsStructuralRelationshipReferenceRelationshipGlobal DependenciesLocal Dependencies
Figure 3: The overview of MARIN.
explicit structural relationships, it also incorporates implicit refer-
ence dependencies (See Section 3.2.2). Therefore, it provides a rich
context for code generation that spans both immediate function
details and broader project architecture.
3.2.1 Local Dependency Analysis. It focuses on the immediate con-
text of the incomplete function. Through static analysis, we first
identify valid APIs available at the generation position, providing
clear references for the LLM’s output. We also analyze method
dependencies, including functions called within the same file or
across other files in the project. This process captures both function
calls and data flow, offering detailed relationships surrounding the
incomplete function.
3.2.2 Global Dependency Analysis. While local dependencies pro-
vide immediate context, understanding broader project relation-
ships is crucial for generating code within a large project, which is
the global dependency. For the unfinished function, we first lever-
age static analysis to extract the import statements in its current
file and then identify all imported files. These related files provide
essential context about the available methods for the current func-
tion. To avoid overwhelming LLMs and exceeding input length
limits, we extract a concise “skeleton” of these files. Specifically, for
each file, we preserve its class definitions, field declarations, and
function signatures while excluding detailed implementations. This
approach provides a compact yet informative representation of the
global dependency on projects.
3.2.3 Input Prompt Construction. Based on the dependency analy-
sis, we construct a structured input prompt, as illustrated in Figure 4.
This prompt integrates the following key components:
•Project Description. A brief overview of the project’s purpose,
providing essential background for the LLM.
•Global Dependency. Simplified skeletons of related and current
files, including class definitions, member fields, and function
signatures, to represent the broader project structure.
•Local Dependency. Called functions and reference APIs that
are directly relevant to the incomplete function, serving as its
immediate context.
// Incomplete Function 'update'publicbooleanupdate(IChatServiceservice, Worldworld, Agentagent) {LOG.info("[Updater / Reaction] Checking if an agent will react to an observation");Reactionreaction= service.getReaction(agent, observation);if(reaction.[API_Position]}// Calledfunctions// public Reaction getReaction(Agent agent, String observation) {// ... omitted for brevity... }// Reference APIs// getCurrentActivity(), setCurrentActivity(String currentActivity), setReact(booleanreact), willReact(), …// Skeleton of related files// nickm980/smallville/World.java// public class World{// private Set<Agent> agents;// public void save(Agent agent) // ... omitted for brevity ... } // ... omitted for brevity...// Skeleton of thecurrent file 'UpdateReaction.java'// Imported Files: [io.github.nickm980.smallville.World,…]// Fields Declarations: [private String observation, … ]// Functions Declarations: // public UpdateReaction(String observation) {... omitted for brevity...}// Description of project 'smallville'// This project aims to create generative agents which are ... Figure 4: An example illustrating the MARIN’ prompt tem-
plate based on the incomplete function in Section 1.
•Incomplete Function. The partially implemented target func-
tion, with the [API_Position] marking the location where the
API call should be generated.
3.3 Dependency Constrained Decoding
This phase first analyzes the mined dependencies to preprocess
valid API-related information and then integrates these constraints
into the decoding process, as illustrated in Figure 3 ❷.
3.3.1 Dependency Preprocessing. In this step, dependencies are
used to build an API name prefix tree and identify parameter pat-
terns, forming a constrained set of valid options. These valid tokens
are cached to ensure efficient access during decoding, as shown in
Figure 3 ❷-I.
API name prefix tree. Given a reference API set A={𝑎1,𝑎2,···𝑎𝑛},
we tokenize the name of each API 𝑎𝑖toT(𝑎𝑖)based on the LLM’s
vocabulary. It is important to note that tokenization in LLMs is

Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware FSE Companion ’25, June 23–28, 2025, Trondheim, Norway
Algorithm 1: Prefix Tree Construction for API Tokens
input : Reference APIsA, TokenizerT
output: Prefix tree𝐺
1Initialize the prefix tree 𝐺with a root nodeR, whereR.child←∅ ;
2foreach𝑎𝑖∈A do
// recursively build the prefix tree;
3 foreach𝑡𝑖∈T(𝑎𝑖)do
4 if𝑡𝑖∉R.child then
// add𝑡𝑖into the children of R;
5R.child[𝑡𝑖]←create a new node with 𝑡𝑖;
6 end
7R←R .child[𝑡𝑖];
8 end
9end
10returnR;
context-dependent. For example, in CodeLlama-7B, the tokeniza-
tion sequence for willReact is [674, 1123, 627], but in the context
ofreaction.willReact , it becomes [14043, 1123, 627]. To ensure
consistent tokenization, we tokenize both the full API calls and
their prefixes (i.e., the tokens before the last “.”). We then remove
the shared prefixes, yielding a deterministic representation T(𝑎𝑖)
for each API. In real-world projects, reference APIs often share
common prefixes. For efficient constraint validation during genera-
tion, we construct a prefix tree from these APIs’ token sequences,
as described in Algorithm 1. The algorithm initializes the tree with
an empty root node (line 1) and iterates through each reference
API (line 2). For each token in the tokenized API, it builds the tree
recursively (lines 3-8): if a token is not a child of the current node,
a new node is created (lines 4-5), then the algorithm moves to this
child node (line 7). Upon completion, each root-to-leaf path in the
tree represents a complete API token sequence, enabling efficient
validation of generated API calls.
Parameter Patterns. We use an indicator function 𝐼to dif-
ferentiate between APIs with and without parameters. To handle
parameter-related tokens in the LLM vocabulary, we classify them
into two categories:
•𝐵𝑛𝑜𝑝𝑎𝑟𝑎𝑚 : Tokens representing no-parameter patterns (e.g., “())”,
“())){”) that appear when an API is called without arguments.
•𝐵𝑝𝑎𝑟𝑎𝑚 : Tokens representing parameter patterns (e.g., “([ –”, “(@”)
that indicate the start of parameter lists.
3.3.2 Constrained Decoding. As shown in Figure 3 ❷-II, at each
step𝑡, the LLM outputs logits 𝑙∈R|𝑉|representing token probabili-
ties over its vocabulary 𝑉. To ensure the generated APIs conform to
mined dependencies, we employ an adaptive masking mechanism
that combines both API name and parameter pattern constraints.
Given the current sequence {𝑡1,𝑡2,...,𝑡𝑘}, if𝑡𝑘+1is an API name
token, we locate the current node in the trie structure and collect
valid next tokens from its children as 𝑉𝑣𝑎𝑙𝑖𝑑={𝑣|𝑣∈𝑛.𝑐ℎ𝑖𝑙𝑑𝑟𝑒𝑛}.
if𝑡𝑘+1is a parameter token, we consult the parameter indicator
𝐼to determine valid tokens - allowing only no-parameter tokens
when𝐼=0or parameter tokens when 𝐼=1. These constraints are
integrated into a unified binary mask 𝑀∈{0,1}|𝑉|:𝑀𝑖= 
1if𝑖∈𝑉𝑣𝑎𝑙𝑖𝑑 (API name constraint)
1if𝑖∈𝐵𝑛𝑜𝑝𝑎𝑟𝑎𝑚 and𝐼=0(no-param constraint)
1if𝑖∈𝐵𝑝𝑎𝑟𝑎𝑚 and𝐼=1(param constraint)
0otherwise(1)
The constrained logits are then computed through element-wise
multiplication 𝑙𝑚𝑎𝑠𝑘𝑒𝑑 =𝑙⊙𝑀, and the next token is selected via
greedy search:
𝑡(𝑘+1)=𝑎𝑟𝑔𝑚𝑎𝑥𝑡(𝑠𝑜𝑓𝑡𝑚𝑎𝑥(𝑙𝑚𝑎𝑠𝑘𝑒𝑑)). (2)
This process iterates until a complete API call is generated or a
maximum length is reached.
4 EXPERIMENTAL SETUP
4.1 Research Questions
In this paper, we mainly investigate the following research ques-
tions through experiments.
•RQ1: How effective is MARIN in mitigating API hallucination
on APIHulBench?
•RQ2: What are the impacts of two components in MARIN (i.e.,
hierarchical dependency mining anddependency constrained de-
coding )?
•RQ3: How efficient is MARIN compared to baseline approaches?
•RQ4: How does MARIN perform in mitigating API hallucination
in an industrial scenario?
4.2 Benchmarks
Existing API hallucination evaluation benchmarks face challenges
such as potential data leakage from older projects [ 6] and reliance
on model-synthesized data [ 14,32]. To address these issues, we con-
struct a new benchmark, APIHulBench, which focuses on project-
specific API calls in real development scenarios, providing a more
practical evaluation of LLMs.
4.2.1 Project Collection. We collect Java projects from GitHub
created between mid-2023 and mid-2024, ensuring they postdate
the training cut-off dates of many existing code LLMs [ 7]. To ensure
quality, following prior work [ 5], we excluded projects with fewer
than 10 files or fewer than 200 stars, resulting in a final dataset of
98 high-quality projects.
4.2.2 Dataset Generation. For each project, we use tree-sitter [ 34]
to parse Java files and extract functions with more than five lines
as candidate samples. We identify project-specific API calls within
these functions and split each function into two parts: the prompt
(code before the API) and an inference part (containing the ground
truth API). The line position of each API call is recorded. Following
prior studies [ 5,7], we eliminate duplicate prompts, resulting in a
benchmark with 416 unique samples. To reflect different develop-
ment stages, we divide the benchmark into two variants based on
API call positions: 1) APIHulBench-F, including 221 samples where
API calls appear in the first 50% of the function lines, reflecting
scenarios where developers are initiating their implementation and
seeking early assistance. 2) APIHulBench-M, including 195 samples
where API calls appear beyond the 50% mark, simulating scenarios
where developers have written most of the code and need assistance

FSE Companion ’25, June 23–28, 2025, Trondheim, Norway Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi Ma
during later stages of development. This division enables a more
nuanced evaluation of LLM performance across different stages
of coding, providing insights into their practical performance in
real-world development.
4.3 Studied LLMs
Following prior studies [ 37,42,45], we adopt two widely-used LLMs
for code generation with different model sizes:
•CodeLlama [ 30]released by Meta AI, is further trained on Llama
2 [33] with 0.5 trillion code-specific tokens. Our experiments use
its 7B, 13B, and 34B versions.
•DeepSeekCoder [ 11]released by DeepSeek AI, is a series of
code-specialist LLMs trained on 2 Trillion tokens across over 80
programming languages. It achieves state-of-the-art performance
among open-source code LLMs. Our experiments use its 1.3B,
6.7B, and 33B versions.
4.4 Studied Baselines
To evaluate the effectiveness of MARIN, we compare it with the
following baselines. Note that we do not include DAG [ 14] in the
comparison because this approach requires detailed documentation
for each API, which is unavailable for many projects.
•Base Generation is a default generation strategy using the cur-
rent function as the input prompt.
•RAG [ 45]retrieves code snippets from the project similar to the
incomplete function and includes them in the input prompt.
•De-Hallucinator [ 6]first generates code using the incomplete
function. Then, it retrieves APIs related to this initial output, adds
them to the input prompt, and iteratively refines the generation.
4.5 Metrics
To comprehensively evaluate the performance of LLMs, we focus
on two aspects: generation accuracy and generation hallucination.
4.5.1 Accuracy. Following prior work [ 6], we adopt three metrics
to evaluate generation accuracy:
•Exact Match (EM) measures the percentage of output that ex-
actly matches the ground truth.
•Edit Similarity (ES) calculates the Levenshtein distance between
the output and the ground truth, normalized to a similarity score.
•Identifier Match (IM) measures the percentage of output with
correct API identifiers compared to the ground truth.
4.5.2 Hallucination. We focus on two key elements in APIs, in-
cluding the names and parameter patterns, and introduce two new
metrics for evaluating the degree of API hallucination.
•Micro Hallucination Number (MiHN) counts the average
number of hallucinatory elements within the generated APIs:
MiHN =Í𝑛
𝑖=1Count(ℎ𝑎𝑙𝑙𝑢𝑐𝑖𝑛𝑎𝑡𝑜𝑟𝑦𝑒𝑙𝑒𝑚𝑒𝑛𝑡𝑠𝑖𝑛𝑎 𝑖)
𝑛, (3)
where𝑛is the total number of generated APIs, and 𝑎𝑖is the𝑖-th
generated API.
•Macro Hallucination Rate (MaHR) calculates the proportion
of generated APIs that contain any hallucinatory elements:MaHR =Count(𝐴𝑃𝐼𝑠𝑤𝑖𝑡ℎℎ𝑎𝑙𝑙𝑢𝑐𝑖𝑛𝑎𝑡𝑖𝑜𝑛𝑠 )
𝑛, (4)
where𝑛is the total number of generated APIs.
4.6 Implementation Details
Given the limited input size of 8,000 tokens, we restrict the project
content to 7,000 tokens and the function content to 1,000 tokens (as
the average length of incompetent function in our benchmark is
358). Content exceeding these limits is truncated from left to right,
which ensures adequately and equally sized input windows for dif-
ferent baselines. The prompts of RAG [ 45] and De-Hallucinator [ 6]
are constructed following their original papers. For a fair com-
parison, we run De-Hallucinator one iteration. We download all
LLMs from HuggingFace Hub [ 13], use vllms [ 18] on Ascend as
the inference and serving engine, and set the max_new_tokens
parameter to 15. All experiments are conducted on a server with
192-kunpeng-920 CPU cores, 1.5T memory, hosted by EulerOS 2.1
Linux distribution, and equipped with 4 Ascend 910B-B3 64G NPUs.
5 RESULTS
5.1 Effectiveness of MARIN on APIHulBench
(RQ1)
Experimental Design. To answer this research question, we con-
duct experiments on the two benchmarks APIHulBench-F and
APIHulBench-M using six different LLMs.
Results. Table 1 shows that MARIN consistently outperforms base-
line approaches across all evaluated LLMs. Using the Wilcoxon
signed-rank test [ 38] (p-value < 0.001), we confirm the improve-
ments are statistically significant.
MARIN can be tailored to various programming scenar-
ios.The available content of incomplete function affects the base
models’ performance. For example, the six models achieve an aver-
age ES of 54.81% and MaHR of 66.74% on APIHulBench-M, while
on APIHulBench-F, these metrics are 52.86% and 69.67%, respec-
tively. MARIN demonstrates strong performance in mitigating API
hallucination across both scenarios. On APIHulBench-F, MARIN im-
proves the performance of the CodeLlama family by up to 175.39%
in EM while reducing MaHR by up to 80.15% compared to RAG.
On APIHulBench-M, similar gains are observed, with increasing
up to 83.98% in EM and reducing up to 79.62% in MaHR. These
results show MARIN is well-suited for early-stage development
with sparse context to later-stage tasks with richer dependencies.
MARIN shows generalization capability across various
LLMs. For DeepSeekCoder-1.3B, MARIN boosts IM by 81.56%,
while reducing MiHN by 69.84% compared to De-Hallucinator on
APIHulBench-F. For larger models, DeepSeekCoder-33B, the im-
pact remains substantial, improving IM by 87.06% and reducing
MiHN by 77.19%. Similar trends are observed in the CodeLlama
family. This generalization capability ensures MARIN can be widely
applied across different model architectures and sizes in diverse
development scenarios.
Answer to RQ1: MARIN significantly mitigates API halluci-
nation across diverse development scenarios and model sizes,

Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware FSE Companion ’25, June 23–28, 2025, Trondheim, Norway
Table 1: Evaluation results of baseline approaches and MARIN on two benchmarks, ∗denotes statistically significant improve-
ment (t-test with p-value < 0.001) over the baseline approaches.
Model ApproachAPIHulBench-F APIHulBench-M
EM(%) ES(%) IM(%) MaHR(%) MiHN EM(%) ES(%) IM(%) MaHR(%) MiHN
CodeLlama-7BBase 21.71 46.32 28.95 73.30 0.79 27.69 55.69 35.89 65.12 0.74
RAG 27.60 50.71 34.84 67.87 0.71 36.41 61.10 47.69 53.84 0.61
De-Hallucinator 22.17 46.79 29.41 73.30 0.81 29.89 56.62 40.20 60.30 0.71
MARIN 76.01 ∗87.04 ∗87.33 ∗ 15.83 ∗ 0.17 ∗66.66 ∗83.66 ∗89.23 ∗ 12.30 ∗ 0.13 ∗
CodeLlama-13BBase 33.03 60.05 39.81 61.08 0.71 33.33 61.73 41.02 59.48 0.70
RAG 49.32 69.78 59.27 42.98 0.48 36.41 61.61 48.71 52.82 0.61
De-Hallucinator 41.62 66.35 49.32 52.03 0.60 32.98 62.24 41.75 58.76 0.69
MARIN 66.96 ∗80.20 ∗74.20 ∗ 28.95 ∗ 0.33 ∗66.66 ∗84.09 ∗88.20 ∗ 12.30 ∗ 0.13 ∗
CodeLlama-34BBase 19.45 51.62 27.14 75.56 0.81 24.61 55.02 32.30 68.71 0.74
RAG 31.67 55.21 39.36 63.80 0.66 38.46 62.59 48.20 52.82 0.58
De-Hallucinator 18.09 49.25 25.79 76.47 0.84 26.28 55.50 33.50 67.52 0.76
MARIN 81.90 ∗89.75 ∗90.49 ∗ 12.66 ∗ 0.13 ∗70.76 ∗86.24 ∗90.76 ∗ 10.76 ∗ 0.12 ∗
DeepSeekCoder-1.3BBase 21.71 52.19 29.41 72.85 0.87 23.58 52.71 32.82 68.20 0.82
RAG 38.91 63.04 46.15 56.10 0.67 34.87 61.26 44.61 56.41 0.71
De-Hallucinator 40.27 64.81 46.60 54.29 0.63 30.92 57.06 40.20 60.30 0.71
MARIN 75.11 ∗86.82 ∗84.61 ∗ 17.64 ∗ 0.19 ∗64.61 ∗82.34 ∗85.64 ∗ 15.38 ∗ 0.16 ∗
DeepSeekCoder-6.7BBase 20.81 49.00 25.33 75.56 0.82 23.07 51.78 31.28 68.71 0.76
RAG 37.10 59.57 42.98 57.46 0.64 33.33 58.90 44.10 56.92 0.65
De-Hallucinator 31.22 56.88 39.36 64.25 0.72 24.22 53.39 32.47 67.52 0.77
MARIN 75.56 ∗87.65 ∗86.42 ∗ 16.74 ∗ 0.18 ∗68.20 ∗85.23 ∗89.74 ∗ 11.28 ∗ 0.11 ∗
DeepSeekCoder-33BBase 35.74 57.99 41.62 59.72 0.66 20.00 51.98 30.25 70.25 0.78
RAG 46.15 67.40 54.29 47.05 0.50 36.41 61.90 46.15 54.35 0.60
De-Hallucinator 42.98 64.45 48.86 52.03 0.57 27.83 57.26 36.59 63.40 0.71
MARIN 81.90 ∗90.83 ∗91.40 ∗ 11.76 ∗ 0.13 ∗67.69 ∗85.39 ∗91.28 ∗ 9.74 ∗ 0.10 ∗
achieving an average increase of 107.32% in EM and an average
decrease of 67.31% in MaHR compared to the RAG approach.
5.2 Impacts of Different Components in MARIN
(RQ2)
Experimental Design. For this RQ, we perform ablation studies
by considering different levels of dependencies with and without
constrained decoding (CD), resulting in eight variants.
•ALL w/wo CD: Provides complete hierarchical dependencies,
including both local and global dependencies.
•-LD w/wo CD: Removes local dependencies, providing only re-
lated files and the current file.
•-GD w/wo CD: Removes global dependencies, providing only
called functions and reference APIs.
•-LG w/wo CD: Removes both local and global dependencies,
providing only the incomplete function.
Results. Figures 5 and 6 show the performance of eight variants
on APIHulBench-F and APIHulBench-M, respectively. The results
confirm that both hierarchical dependencies and constrained de-
coding independently improve the performance of MARIN, with
their combination achieving the best results.Global dependency is more beneficial for hallucination
mitigation. Removing global dependencies (-GD) causes a larger
performance drop. For example, on APIHulBench-F, removing global
dependencies causes a 33.39% drop in average EM and a 186% rise in
average MaHR across six LLMs. In contrast, removing local depen-
dencies results in a 15.79% decrease in average EM and an 81.66%
increase in average MaHR. This demonstrates that global depen-
dencies, such as file structures and method signatures, are crucial
for providing the context required for accurate API generation.
Constrained decoding consistently improves hallucina-
tion mitigation across different input contexts. For complete
dependencies (ALL), with constrained decoding, on APIHulBench-
F, the average EM increases by 9.12 points and MaHR decreases
by 11.53 points across six LLMs. On APIHulBench-M, the EM in-
creases by 11.28 points and MaHR decreases by 12.22 points. Even
in limited dependency settings (-LD, -GD, -LG), constrained decod-
ing also achieves the improvements. For example, in “-LG” variant,
constrained decoding improves the EM by an average of 8.52 points
and reduces MaHR by an average of 16.13 points on APIHulBench-F
across six LLMs. These results highlight the effectiveness of con-
strained decoding could employ the available dependencies to pre-
vent invalid API tokens in the generation process.

FSE Companion ’25, June 23–28, 2025, Trondheim, Norway Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi Ma
Without Constrained Decoding With Constrained Decoding
ALL -GD -LD -LG20406080100
↑
↑
↑
↑9.05
6.79
4.98
6.34EM
(a) CodeLlama-7B-LG -GD -LD ALL020406080↑↑↑
↑6.337.69
4.07
7.69
(b) CodeLlama-13B-LG -GD -LD ALL020406080↑
↑
↑
↑12.67
4.53
4.53
6.34
(c) CodeLlama-34B-LG -GD -LD ALL020406080↑
↑
↑
↑9.5
7.69
6.79
19.0
(d) DeepSeekCoder-1.3B-LG -GD -LD ALL020406080↑↑
↑
↑6.799.05
4.53
6.79
(e) DeepSeekCoder-6.7B-LG -GD -LD ALL020406080↑
↑
↑
↑10.41
9.96
1.81
4.98
(f) DeepSeekCoder-33B
-LG -GD -LD ALL020406080
↓↓↓↓
11.317.248.1513.58MaHR
(g) CodeLlama-7B-LG -GD -LD ALL020406080
↓↓↓↓
16.74 8.156.3311.76
(h) CodeLlama-13B-LG -GD -LD ALL020406080
↓↓↓↓
12.224.978.159.95
(i) CodeLlama-34B-LG -GD -LD ALL020406080
↓↓↓↓
9.968.1411.7730.35
(j) DeepSeekCoder-1.3B-LG -GD -LD ALL020406080
↓↓↓↓
7.699.517.6917.19
(k) DeepSeekCoder-6.7B-LG -GD -LD ALL020406080
↓↓↓↓
11.3110.415.4314.02
(l) DeepSeekCoder-33B
Figure 5: Evaluation results of different variants on APIHulBench-F. “-LD” denotes removing local dependency, “-GD” denotes
removing global dependency and “-LG” denotes removing local and global dependencies.
Without Constrained Decoding With Constrained Decoding
-LG -GD -LD ALL020406080
↑
↑
↑↑9.05
8.21
4.0114.36EM
(a) CodeLlama-7B-LG -GD -LD ALL020406080
↑
↑
↑↑10.77
11.79
6.157.18
(b) CodeLlama-13B-LG -GD -LD ALL020406080↑
↑
↑↑11.28
12.3
5.139.74
(c) CodeLlama-34B-LG -GD -LD ALL020406080
↑
↑
↑
↑9.05
12.3
2.05
8.72
(d) DeepSeekCoder-1.3B-LG -GD -LD ALL020406080↑↑
↑
↑11.2814.36
7.18
10.26
(e) DeepSeekCoder-6.7B-LG -GD -LD ALL020406080
↑↑↑
↑11.8013.3316.41
8.2
(f) DeepSeekCoder-33B
-LG -GD -LD ALL020406080
↓↓↓↓
9.057.2412.3113.58MaHR
(g) CodeLlama-7B-LG -GD -LD ALL020406080
↓↓↓↓
11.809.5910.7718.97
(h) CodeLlama-13B-LG -GD -LD ALL020406080
↓↓↓↓
11.812.3113.3420.51
(i) CodeLlama-34B-LG -GD -LD ALL020406080
↓↓↓↓
12.3111.7910.2618.97
(j) DeepSeekCoder-1.3B-LG -GD -LD ALL020406080
↓↓↓↓
11.7914.3612.8220.0
(k) DeepSeekCoder-6.7B-LG -GD -LD ALL020406080
↓↓↓↓
14.8713.3421.0219.49
(l) DeepSeekCoder-33B
Figure 6: Evaluation results of different variants on APIHulBench-M. “-LD” denotes removing local dependency, “-GD” denotes
removing global dependency and “-LG” denotes removing local and global dependencies.
Table 2: Computational time comparison across baseline approaches and MARIN. The abbreviation “De-Hal.” denotes “De-
Hallucinator”, the “CL” denotes “CodeLlama” and the “DSC” denotes “DeepSeekCoder”.
ApproachAPIHulBench-F APIHulBench-M
CL-7B CL-13B CL-34B DSC-1.3B DSC-6.7B DSC-33B CL-7B CL-13B CL-34B DSC-1.3B DSC-6.7B DSC-33B
Base 0.203 0.228 0.379 0.214 0.217 0.309 0.204 0.216 0.380 0.209 0.211 0.319
RAG 0.526 0.684 0.874 0.659 0.664 0.888 0.910 0.935 1.054 0.916 0.919 1.045
De-Hal. 0.571 0.729 0.906 0.551 0.773 0.865 0.560 0.744 0.950 0.552 0.768 0.858
MARIN 0.214 0.276 0.418 0.226 0.233 0.329 0.216 0.232 0.453 0.210 0.215 0.333
Answer to RQ2: Both components are essential for the per-
formance of MARIN. Removing hierarchical dependency and
constrained decoding leads to a performance decrease. Amongthese, global dependency is the most important module, having
the greatest impact on overall performance.

Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware FSE Companion ’25, June 23–28, 2025, Trondheim, Norway
5.3 Efficiency of MARIN (RQ3)
Experimental Design. To evaluate the efficiency, we measure
the computational time for all approaches. Due to computational
resource constraints, we use 20 concurrent processes for LLMs with
up to 10B parameters and 10 concurrent processes for LLMs with
over 30B parameters. For each approach, we specifically measure:
•Base: The time required for model inference with only incom-
plete function.
•RAG: The total time for retrieval and model inference.
•De-Hallucination: The total time for initial inference, retrieval,
and a secondary inference.
•MARIN: The total time for static analysis and model inference,
reflecting its dependency analysis and decoding phases.
To ensure reliable results, the reported computational time for each
approach is averaged across all test samples.
Results. As shown in Table 2, MARIN achieves comparable ef-
ficiency to base models while greatly outperforming RAG and
De-Hallucinator in computational time across all model sizes and
benchmarks.
MARIN maintains consistent efficiency across various bench-
marks. Different development scenarios greatly impact the infer-
ence time of the base model, as six LLMs achieve fast inference
with an average time of 0.203s on APIHulBench-F and 0.256s on
APIHulBench-M, respectively. RAG experiences a substantial in-
crease in time, adding 0.457s on APIHulBench-F and 0.706s on
APIHulBench-M due to the retrieval process. De-Hallucinator, which
requires iterative generation, introduces additional delays, with an
overhead of 0.474s on APIHulBench-F and 0.482s on APIHulBench-
M. In contrast, MARIN adds only 0.024s on APIHulBench-F and
0.02s on APIHulBench-M, maintaining minimal computational over-
head. This benefit stems from the MARIN’s lightweight design (i,e.,
not rely on the expensive retrieval or iterative processes.).
MARIN exhibits superior scalability with increasing model
size. For example, in the DeepSeekCoder family, the smallest model
(DSC-1.3B) completes inference in an average of 0.211s across two
benchmarks. MARIN adds only 0.007s overhead, while RAG and
De-Hallucinator add 0.576s and 0.333s, respectively. For the largest
model (DSC-33B), despite the base inference time increasing to
0.314s, MARIN maintains a low additional overhead of 0.017s. In
comparison, RAG adds 0.652s, and De-Hallucinator adds 0.547s.
These results demonstrate that MARIN exhibits superior scalability,
maintaining minimal overhead regardless of model size.
Answer to RQ3: MARIN achieves comparable efficiency to
base models, adding only 0.022s overhead on average. MARIN’s
lightweight design and superior scalability make it an efficient
framework for mitigating API hallucination across diverse de-
velopment scenarios and model sizes.
5.4 Performance of MARIN in Industrial
Scenario (RQ4)
Experimental Design. To evaluate MARIN in an industrial sce-
nario, we construct a benchmark with 109 samples from Huawei’s
internal Java projects, following the process described in Section 4.2.Table 3: Evaluation results of baseline approaches and
MARIN in the industry scenario. The abbreviation of “De-
Hal.” denotes “De-Hallucinator”. ∗denotes statistically sig-
nificant improvement (t-test with p-value < 0.001) over the
baseline approaches.
Approach EM(%) ES(%) MaHR(%) MiHN Time(s)
PanguCoder-11B
Base 13.63 50.53 85.45 1.06 0.205
RAG 35.45 60.97 60.90 0.73 0.411
De-Hal. 13.76 48.72 86.23 1.11 0.479
MARIN 60.90 ∗80.19 ∗ 25.45 ∗ 0.31 ∗ 0.235
PanguCoder-34B
Base 13.63 48.27 84.54 1.05 0.206
RAG 33.63 63.80 60.00 0.70 0.479
De-Hal. 13.76 49.80 85.32 1.04 0.501
MARIN 58.18 ∗78.21 ∗ 23.63 ∗ 0.30 ∗ 0.239
We use Huawei proprietary LLMs, PanguCoder-11B and PanguCoder-
34B, as the base models for the experiments.
Results. The results in Table 3 show that MARIN outperforms base-
line approaches in industrial scenarios, with statistically significant
improvements (p-value < 0.001, Wilcoxon signed-rank test [ 38]),
while maintaining competitive inference efficiency.
Effectiveness Analysis. De-Hallucinator shows no improve-
ment or even slight degradation compared to the base model. RAG
achieves an EM of 35.45%, but its high hallucination rate of 60.90%
on PanguCoder-11B limits its effectiveness. In contrast, MARIN de-
livers significant improvements across all metrics. On PanguCoder-
11B, it boosts EM by 71.79%, ES by 31.52%, and reduces MaHR
by 58.21% and MiHN by 57.53% compared to RAG. These results
demonstrate that merely providing relevant code snippets or itera-
tive grounding is insufficient for industrial scenarios, while MARIN
effectively addresses these challenges by integrating project-specific
dependencies and constrained decoding.
Efficiency Analysis. RAG and De-Hallucinator introduce sub-
stantial latency (e.g., 0.411s and 0.479s per sample on PanguCoder-
11B) due to their reliance on retrieval and iterative processes. MARIN
achieves impressive efficiency, requiring only 0.235s per sample
on PanguCoder-11B and 0.237s on PanguCoder-34B, adding just
0.030s and 0.033s overhead compared to base models. These re-
sults show that MARIN is both effective and practical for industrial
deployment, balancing performance with efficiency.
Answer to RQ4: MARIN demonstrates strong performance
in industrial scenarios, achieving substantial improvements in
both generation accuracy and hallucination mitigation while
maintaining high efficiency.

FSE Companion ’25, June 23–28, 2025, Trondheim, Norway Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi Ma
// Incomplete function 'update'publicbooleanupdate(IChatServiceservice, Worldworld, Agentagent) {LOG.info("[Updater / Reaction] Checking if an agent will react to an observation");Reactionreaction= service.getReaction(agent, observation);if(reaction.[API_Position]}RAG//Reference APIs// String getFullTimeFormat()// String getTimeFormat()// String getApiPath()
BasewillReact())getReact())getReaction()
MARINRAGDe-HallucinatorisReacting())Base// Here are some similar code snippets in other filesReaction reaction = new Reaction();// ... omitted for brevity...// booleanwillReact= json.get("react").asBoolean();// if (willReact) { // ... omitted for brevity... }// reaction.setReact(willReact);// ... omitted for brevity...De-Hallucinator
Base:isisReisReactisReactingis  -1.16get -1.19has -2.88act    -0.79action -1.46ative-1.57Re     -2.39Valid  -2.45Active -2.61ing-0.69()) -1.62s   -2.72isReacting())
()) -0.17()  -2.37To  -3.75
De-Hal:getgetRegetReactiongetReaction()
RAG:getgetRegetReactgetReact())
MARIN:willget -1.06is  -1.38has -3.02Re     -1.87Action -2.25Type   -2.52action -0.34act    -1.57ason-3.95()   -1.23Type -1.34()). -1.99get  -0.88is   -0.98will -2.45Re       -0.26E        -1.87Current  -3.62act    -0.01action -5.10</s>   -5.55()) -0.16()  -1.93(). -5.37will -0.01get  -4.53set  -10.13
Re -4.8E-07
act -3.6E-07
()) -0.02()  -3.36(). -10.26willRewillReactwillReact())// Description of project 'smallville'// This project aims to create generative agents ...// Skeleton of related files// nickm980/smallville/World.java// public class World{// private Set<Agent> agents;// public void save(Agent agent) // ... omitted for brevity ... } // ... omitted for brevity...// Skeleton of thecurrentfile 'UpdateReaction.java'// Imported Files: [io.github.nickm980.smallville.World,…]// Fields Declarations: [private String observation, … ]// Functions Declarations// public UpdateReaction(String observation) {...}// Calledfunctions // public Reaction getReaction(Agent agent) {...}// Reference APIs// getCurrentActivity(), willReact(), …MARIN
(a) Different project contexts provided in the input prompt
// Incomplete function 'update'publicbooleanupdate(IChatServiceservice, Worldworld, Agentagent) {LOG.info("[Updater / Reaction] Checking if an agent will react to an observation");Reactionreaction= service.getReaction(agent, observation);if(reaction.[API_Position]}RAG//Reference APIs// String getFullTimeFormat()// String getTimeFormat()// String getApiPath()
Base// Description of project 'smallville'// This project aims to create generative agents ...// Skeleton of related files// nickm980/smallville/World.java// public class World{// private Set<Agent> agents;// public void save(Agent agent) // ... omitted for brevity ... } // ... omitted for brevity...// Skeleton of present file 'UpdateReaction.java'// Imported Files: [io.github.nickm980.smallville.World,…]// Defined Fields: [private String observation, … ]// Defined Functions// public UpdateReaction(String observation) {...}// Dependent method of current function 'update'// public Reaction getReaction(Agent agent) {...}// Reference APIs// getCurrentActivity(), willReact(), …
willReact())getReact())getReaction()
MARIN
MARINRAGDe-HallucinatorisReacting()Base// Here are some similar code snippets in other filesReaction reaction = new Reaction();// ... omitted for brevity...// booleanwillReact= json.get("react").asBoolean();// if (willReact) { // ... omitted for brevity... }// reaction.setReact(willReact);// ... omitted for brevity...De-Hallucinator
Base:isisReisReactisReactingis  -1.16get -1.19has -2.88act    -0.79action -1.46ative-1.57Re     -2.39Valid  -2.45Active -2.61ing-0.69()) -1.62s   -2.72isReacting())
()) -0.17()  -2.37To  -3.75
De-Hal:getgetRegetReactiongetReaction()
RAG:getgetRegetReactgetReact())
MARIN:willget -1.06is  -1.38has -3.02Re     -1.87Action -2.25Type   -2.52action -0.34act    -1.57ason-3.95()   -1.23Type -1.34()). -1.99get-0.88is   -0.98will-2.45Re-0.26E-1.87Current  -3.62act    -0.01action -5.10</s>   -5.55()) -0.16()-1.93().-5.37will -0.01get  -4.53set  -10.13
Re -4.8E-07
act -3.6E-07
()) -0.02()  -3.36(). -10.26willRewillReactwillReact()) (b) Generation process with Top-3 token logits
Figure 7: Case study on API hallucination mitigation across Base, De-Hallucinator, RAG, and MARIN using CodeLlama-7B.
6 DISCUSSION
6.1 Why does MARIN work?
The effectiveness of MARIN lies in enriching the input context with
structural project information and adaptively guiding the decod-
ing process to adhere to valid APIs. As demonstrated in Figure 7,
we revisit the example from the Introduction, where the update
function requires an API to determine an agent’s reaction to an
observation.
6.1.1 Hierarchical dependency mining for enriching the input con-
text with structural project information. As shown in Figure 7(a),
baseline approaches fail to provide sufficient context. The Base
model relies solely on the incomplete function and generates the
hallucinated API isReacting()) . De-Hallucinator retrieves rele-
vant APIs but does not establish their connection to the function,
producing the incorrect getReaction() . Similarly, RAG retrieves
similar code snippets but overlooks project-specific dependencies,
leading to the invalid getReact()) . In contrast, MARIN mines both
local and global dependencies from the project such as the skeleton
ofClass World and the implementation of getReaction to cre-
ate a structured and enriched input prompt. By providing a more
comprehensive view of the project, MARIN enables the model to
accurately generate the API willReact()) while avoiding invalid
alternatives.
6.1.2 Dependency constrained decoding for adaptively guiding the
generation process to valid API tokens. Figure 7(b) shows the token
logits for each approach, revealing differences in generation confi-
dence. The Base model shows high uncertainty, with weak logits
for its first token is(-1.16). De-Hallucinator improves slightly, with
stronger logits for get(-1.06), and RAG retrieves broader context,
resulting in logits of -0.88 for getand -0.01 for act. In contrast,
MARIN demonstrates near-certain logits for the correct token se-
quence, assigning -0.01 for will , followed by deterministic logits
forRe(-4.8E-07) and act(-3.6E-07). This precision is guided bythe API prefix tree, ensuring that the generated tokens align with
the project’s valid APIs. Additionally, the final ())token is accu-
rately predicted through parameter validation, further enhancing
the reliability of the generated code. By adaptively guiding the gen-
eration process, MARIN ensures the generation complies with API
specifications in the project, thus mitigating the API hallucination.
6.2 Threats to Validity
We identify four main threats to the validity of our study:
Model Selection. Although we have evaluated MARIN on multi-
ple models, including CodeLlama, DeepSeekCoder, and PanguCoder,
many other LLMs remain unexplored, such as CodeQwen [ 41],
CodeGen [ 27]. However, the consistent improvements across cur-
rent models suggest that our framework is highly generalizable.
In the future, we will extend our evaluation to a wider range of
models to further validate its scalability.
Evaluation Tasks. Our current implementation and evaluation
are centered on Java projects. However, the design of MARIN is
language-agnostic, and we believe the framework can be extended
to other programming languages with minimal adaptation, leverag-
ing their respective dependency analysis.
Prompt Design. The effectiveness of MARIN partially depends
on our prompt template design. While we have conducted exten-
sive experiments to validate our template, there might be room
for further optimization. To mitigate this threat, we have open-
sourced our prompt templates to facilitate community feedback
and improvements.
Benchmark Curation. Our benchmarks are created automat-
ically. While automation enables scalability to handle extensive
benchmarking tasks, it introduces potential concerns regarding
dataset correctness and quality. In the future, we will enhance
benchmark reliability by incorporating more extensive human vali-
dation or adopting hybrid dataset creation strategies.

Towards Mitigating API Hallucination in Code Generated by LLMs with Hierarchical Dependency Aware FSE Companion ’25, June 23–28, 2025, Trondheim, Norway
7 RELATED WORK
7.1 LLMs for Code Generation
The impressive capabilities of LLMs in natural language processing
have inspired researchers and companies to develop specialized
models for code generation [ 8,21,24,27,28,30,42]. OpenAI pro-
poses Codex [ 28], the earlier representative work of code LLMs. Sub-
sequently, various models have emerged, such as Meta’s InCoder [ 8]
and CodeLlama [ 30], Salesforce’s CodeGen [ 27], BigCode project’s
StarCoder series [ 20,23], and Deepseek AI’s DeepseekCoder [ 11].
These code LLMs typically follow two development approaches:
continuously training existing general models (e.g. CodeLlama), or
training from scratch with code-specific data (e.g. DeepseekCoder).
These advances have enabled commercial programming assistants
like GitHub Copilot [ 10] and Amazon CodeWhisperer [ 1] demon-
strate promising results in software development. Our proposed
framework MARIN can be applied seamlessly to current intelli-
gent programming assistants to mitigate hallucinations in code
generation, enhancing their accuracy and reliability.
7.2 Hallucinations in LLMs
While LLMs have shown remarkable performance in text gener-
ation, they frequently produce outputs that sound plausible but
are incorrect, known as “Hallucination”, severely impacting reli-
ability and practical applications [ 9,12,15,16,39,43]. In the do-
main of code generation, hallucination poses similar challenges,
particularly in scenarios involving API usage, where models may
generate invalid API calls or misuse existing APIs. Liu et al. [22]
conduct pioneering work in categorizing different types of code
hallucinations. Zhang et al. [45] further explore the prevalence of
code hallucinations in industrial settings, highlighting the unique
challenges faced in real-world applications. Agarwal et al. [32]
propose a benchmark for detecting hallucinated code snippets on
Python. To mitigate hallucination issues, Zhang et al. [45] retrieve
project-specific code snippets to enhance generation. Eghbali et
al.[6] propose De-Hallucinator, which adds API references related
to the model’s predictions into the prompt. Jain et al. [14] introduce
Documentation Augmented Generation (DAG), using API docu-
mentation from services like AWS and Azure to guide generation.
Different from these approaches, our MARIN combines project-
specific structural context and dependency constrained decoding
to ensure valid API generation, effectively mitigating hallucination
in practical code generation scenarios.
8 CONCLUSION
In this paper, we propose MARIN, a framework designed to miti-
gate API hallucination based on hierarchical dependency analysis.
By identifying local and global dependencies in the incomplete
function and applying dependency constrained decoding, MARIN
ensures the generated APIs align with project requirements. Ex-
periments show that MARIN significantly improves API accuracy,
reduces hallucination rates, and maintains efficiency with minimal
overhead. In addition, MARIN’s strong performance in industrial
scenarios demonstrates its effectiveness in generating accurate and
reliable APIs. As a solution to mitigate API hallucination in LLM-
driven code generation, MARIN contributes to the developmentof accurate and reliable code generation systems. In future work,
we plan to extend MARIN to a wider range of LLMs, additional
programming languages, and optimize our prompt template.
Acknowledgments
We thank all the anonymous reviewers. This research is supported
by National Natural Science Foundation of China under project
(No. 62472126), Natural Science Foundation of Guangdong Province
(Project No. 2023A1515011959), Shenzhen-Hong Kong Jointly Funded
Project (Category A, No. SGDX20230116091246007), Shenzhen Ba-
sic Research (General Project No. JCYJ20220531095214031), Shen-
zhen International Science and Technology Cooperation Project
(No. GJHZ20220913143008015), and CCF-Huawei Populus Grove
Fund.
References
[1] Amazon. 2024. https://aws.amazon.com/codewhisperer
[2]Shraddha Barke, Michael B James, and Nadia Polikarpova. 2023. Grounded
copilot: How programmers interact with code-generating models. Proceedings of
the ACM on Programming Languages 7, OOPSLA1 (2023), 85–111.
[3]Yujia Chen, Cuiyun Gao, Xiaoxue Ren, Yun Peng, Xin Xia, and Michael R. Lyu.
2023. API Usage Recommendation Via Multi-View Heterogeneous Graph Repre-
sentation Learning. IEEE Trans. Software Eng. 49, 5 (2023), 3289–3304.
[4]Yujia Chen, Cuiyun Gao, Muyijie Zhu, Qing Liao, Yong Wang, and Guoai Xu. 2024.
APIGen: Generative API Method Recommendation. In IEEE International Confer-
ence on Software Analysis, Evolution and Reengineering, SANER 2024, Rovaniemi,
Finland, March 12-15, 2024 . IEEE, 171–182.
[5]Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad, Hantian Ding, Ming Tan, Nihal
Jain, Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan Roth,
and Bing Xiang. 2023. CrossCodeEval: A Diverse and Multilingual Benchmark
for Cross-File Code Completion. In Advances in Neural Information Processing
Systems 36: Annual Conference on Neural Information Processing Systems 2023,
NeurIPS 2023, New Orleans, LA, USA, December 10 - 16, 2023 , Alice Oh, Tristan
Naumann, Amir Globerson, Kate Saenko, Moritz Hardt, and Sergey Levine (Eds.).
[6]Aryaz Eghbali and Michael Pradel. 2024. De-hallucinator: Iterative grounding
for llm-based code completion. arXiv preprint arXiv:2401.01701 (2024).
[7]Jia Feng, Jiachen Liu, Cuiyun Gao, Chun Yong Chong, Chaozheng Wang, Shan
Gao, and Xin Xia. 2024. ComplexCodeEval: A Benchmark for Evaluating Large
Code Models on More Complex Code. In Proceedings of the 39th IEEE/ACM Inter-
national Conference on Automated Software Engineering, ASE 2024, Sacramento,
CA, USA, October 27 - November 1, 2024 , Vladimir Filkov, Baishakhi Ray, and
Minghui Zhou (Eds.). ACM, 1895–1906.
[8]Daniel Fried, Armen Aghajanyan, Jessy Lin, Sida Wang, Eric Wallace, Freda Shi,
Ruiqi Zhong, Scott Yih, Luke Zettlemoyer, and Mike Lewis. 2023. InCoder: A
Generative Model for Code Infilling and Synthesis. In The Eleventh International
Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 .
OpenReview.net.
[9]Vahid Ghafouri, Vibhor Agarwal, Yong Zhang, Nishanth Sastry, Jose M. Such, and
Guillermo Suarez-Tangil. 2023. AI in the Gray: Exploring Moderation Policies in
Dialogic Large Language Models vs. Human Answers in Controversial Topics.
InProceedings of the 32nd ACM International Conference on Information and
Knowledge Management, CIKM 2023, Birmingham, United Kingdom, October 21-25,
2023, Ingo Frommholz, Frank Hopfgartner, Mark Lee, Michael Oakes, Mounia
Lalmas, Min Zhang, and Rodrygo L. T. Santos (Eds.). ACM, 556–565.
[10] Github. 2024. copilot.github.com
[11] Daya Guo, Qihao Zhu, Dejian Yang, Zhenda Xie, Kai Dong, Wentao Zhang, Guant-
ing Chen, Xiao Bi, Y. Wu, Y. K. Li, Fuli Luo, Yingfei Xiong, and Wenfeng Liang.
2024. DeepSeek-Coder: When the Large Language Model Meets Programming -
The Rise of Code Intelligence. CoRR abs/2401.14196 (2024).
[12] Dong Huang, Qingwen Bu, Jie Zhang, Xiaofei Xie, Junjie Chen, and Heming Cui.
2023. Bias Assessment and Mitigation in LLM-based Code Generation. CoRR
abs/2309.14345 (2023).
[13] Huggingface Hub. 2024. https://huggingface.co/
[14] Nihal Jain, Robert Kwiatkowski, Baishakhi Ray, Murali Krishna Ramanathan,
and Varun Kumar. 2024. On Mitigating Code LLM Hallucinations with API
Documentation. arXiv preprint arXiv:2407.09726 (2024).
[15] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
Yejin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of Hallucination in
Natural Language Generation. ACM Comput. Surv. 55, 12 (2023), 248:1–248:38.
[16] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii,
Ye Jin Bang, Andrea Madotto, and Pascale Fung. 2023. Survey of hallucination in

FSE Companion ’25, June 23–28, 2025, Trondheim, Norway Yujia Chen, Mingyu Chen, Cuiyun Gao, Zhihan Jiang, Zhongqi Li, and Yuchi Ma
natural language generation. Comput. Surveys 55, 12 (2023), 1–38.
[17] Jiasheng Jiang, Jingzheng Wu, Xiang Ling, Tianyue Luo, Sheng Qu, and Yanjun
Wu. 2024. APP-Miner: Detecting API Misuses via Automatically Mining API
Path Patterns. In IEEE Symposium on Security and Privacy, SP 2024, San Francisco,
CA, USA, May 19-23, 2024 . IEEE, 4034–4052.
[18] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng,
Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient
Memory Management for Large Language Model Serving with PagedAttention.
InProceedings of the 29th Symposium on Operating Systems Principles, SOSP 2023,
Koblenz, Germany, October 23-26, 2023 , Jason Flinn, Margo I. Seltzer, Peter Dr-
uschel, Antoine Kaufmann, and Jonathan Mace (Eds.). ACM, 611–626.
[19] Jingxuan Li, Rui Huang, Wei Li, Kai Yao, and Weiguo Tan. 2021. Toward Less
Hidden Cost of Code Completion with Acceptance and Ranking Models. In IEEE
International Conference on Software Maintenance and Evolution, ICSME 2021,
Luxembourg, September 27 - October 1, 2021 . IEEE, 195–205.
[20] Raymond Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov,
Chenghao Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu,
Evgenii Zheltonozhskii, Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig
Davaadorj, Joel Lamy-Poirier, João Monteiro, Oleh Shliazhko, Nicolas Gontier,
Nicholas Meade, Armel Zebaze, Ming-Ho Yee, Logesh Kumar Umapathi, Jian
Zhu, Benjamin Lipkin, Muhtasham Oblokulov, Zhiruo Wang, Rudra Murthy
V, Jason T. Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov, Marco Zocca,
Manan Dey, Zhihan Zhang, Nour Fahmy, Urvashi Bhattacharyya, Wenhao Yu,
Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor Zhdanov,
Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger, Hailey
Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson,
Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy,
Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean
Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. 2023.
StarCoder: may the source be with you! Trans. Mach. Learn. Res. 2023 (2023).
[21] Bingchang Liu, Chaoyu Chen, Cong Liao, Zi Gong, Huan Wang, Zhichao Lei,
Ming Liang, Dajun Chen, Min Shen, Hailian Zhou, Hang Yu, and Jianguo Li. 2024.
MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning. In Proceedings of
the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD
2024, Barcelona, Spain, August 25 – 29, 2024 . ACM.
[22] Fang Liu, Yang Liu, Lin Shi, Houkun Huang, Ruifeng Wang, Zhen Yang, Li Zhang,
Zhongqi Li, and Yuchi Ma. 2024. Exploring and evaluating hallucinations in
llm-powered code generation. arXiv preprint arXiv:2404.00971 (2024).
[23] Anton Lozhkov, Raymond Li, Loubna Ben Allal, Federico Cassano, Joel Lamy-
Poirier, Nouamane Tazi, Ao Tang, Dmytro Pykhtar, Jiawei Liu, Yuxiang Wei,
Tianyang Liu, Max Tian, Denis Kocetkov, Arthur Zucker, Younes Belkada, Zi-
jian Wang, Qian Liu, Dmitry Abulkhanov, Indraneil Paul, Zhuang Li, Wen-Ding
Li, Megan Risdal, Jia Li, Jian Zhu, Terry Yue Zhuo, Evgenii Zheltonozhskii, Nii
Osae Osae Dade, Wenhao Yu, Lucas Krauß, Naman Jain, Yixuan Su, Xuanli He,
Manan Dey, Edoardo Abati, Yekun Chai, Niklas Muennighoff, Xiangru Tang, Muh-
tasham Oblokulov, Christopher Akiki, Marc Marone, Chenghao Mou, Mayank
Mishra, Alex Gu, Binyuan Hui, Tri Dao, Armel Zebaze, Olivier Dehaene, Nicolas
Patry, Canwen Xu, Julian J. McAuley, Han Hu, Torsten Scholak, Sébastien Paquet,
Jennifer Robinson, Carolyn Jane Anderson, Nicolas Chapados, and et al. 2024.
StarCoder 2 and The Stack v2: The Next Generation. CoRR abs/2402.19173 (2024).
[24] Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu,
Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023. WizardCoder:
Empowering Code Large Language Models with Evol-Instruct. In The Twelfth
International Conference on Learning Representations .
[25] Yao Wan nd Zhangqian Bi, Yang He, Jianguo Zhang, Hongyu Zhang, Yulei Sui,
Guandong Xu, Hai Jin, and Philip S. Yu. 2024. Deep Learning for Code Intelligence:
Survey, Benchmark and Toolkit. ACM Comput. Surv. 56, 12 (2024), 309:1–309:41.
[26] Phuong Thanh Nguyen, Juri Di Rocco, Davide Di Ruscio, Lina Ochoa, Thomas
Degueule, and Massimiliano Di Penta. 2019. FOCUS: a recommender system
for mining API function calls and usage patterns. In Proceedings of the 41st
International Conference on Software Engineering, ICSE 2019, Montreal, QC, Canada,
May 25-31, 2019 , Joanne M. Atlee, Tevfik Bultan, and Jon Whittle (Eds.). IEEE /
ACM, 1050–1060.
[27] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo Zhou,
Silvio Savarese, and Caiming Xiong. 2023. CodeGen: An Open Large Language
Model for Code with Multi-Turn Program Synthesis. In The Eleventh International
Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023 .OpenReview.net.
[28] OpenAI. 2022. Codex. https://openai.com/blog/openai-codex/
[29] Yun Peng, Shuqing Li, Wenwei Gu, Yichen Li, Wenxuan Wang, Cuiyun Gao, and
Michael R. Lyu. 2023. Revisiting, Benchmarking and Exploring API Recommen-
dation: How Far Are We? IEEE Trans. Software Eng. 49, 4 (2023), 1876–1897.
[30] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xi-
aoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy Rapin, Artyom
Kozhevnikov, Ivan Evtimov, Joanna Bitton, Manish Bhatt, Cristian Canton-Ferrer,
Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar,
Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel Syn-
naeve. 2023. Code Llama: Open Foundation Models for Code. CoRR abs/2308.12950
(2023).
[31] Bo Shen, Jiaxin Zhang, Taihong Chen, Daoguang Zan, Bing Geng, An Fu, Muhan
Zeng, Ailun Yu, Jichuan Ji, Jingyang Zhao, Yuenan Guo, and Qianxiang Wang.
2023. PanGu-Coder2: Boosting Large Language Models for Code with Ranking
Feedback. CoRR abs/2307.14936 (2023).
[32] Yuchen Tian, Weixiang Yan, Qian Yang, Qian Chen, Wen Wang, Ziyang Luo, and
Lei Ma. 2024. CodeHalu: Code Hallucinations in LLMs Driven by Execution-based
Verification. arXiv preprint arXiv:2405.00253 (2024).
[33] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi,
Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, and
Shruti Bhosale et al. 2023. Llama 2: Open Foundation and Fine-Tuned Chat
Models. arXiv preprint (2023).
[34] Tree-sitter. 2024. https://github.com/tree-sitter/tree-sitter
[35] Chaozheng Wang, Junhao Hu, Cuiyun Gao, Yu Jin, Tao Xie, Hailiang Huang,
Zhenyu Lei, and Yuetang Deng. 2023. Practitioners’ Expectations on Code
Completion. CoRR abs/2301.03846 (2023).
[36] Moshi Wei, Nima Shiri Harzevili, Yuchao Huang, Junjie Wang, and Song Wang.
2022. CLEAR: Contrastive Learning for API Recommendation. In 44th IEEE/ACM
44th International Conference on Software Engineering, ICSE 2022, Pittsburgh, PA,
USA, May 25-27, 2022 . ACM, 376–387.
[37] Yuxiang Wei, Zhe Wang, Jiawei Liu, Yifeng Ding, and Lingming Zhang. 2024.
Magicoder: Empowering Code Generation with OSS-Instruct. In Forty-first Inter-
national Conference on Machine Learning .
[38] Frank Wilcoxon. 1992. Individual comparisons by ranking methods. In Break-
throughs in statistics: Methodology and distribution . Springer, 196–202.
[39] Fangzhou Wu, Ning Zhang, Somesh Jha, Patrick D. McDaniel, and Chaowei Xiao.
2024. A New Era in LLM Security: Exploring Security Concerns in Real-World
LLM-based Systems. CoRR abs/2402.18649 (2024).
[40] Xin Xia, Lingfeng Bao, David Lo, Pavneet Singh Kochhar, Ahmed E. Hassan, and
Zhenchang Xing. 2017. What do developers search for on the web? Empir. Softw.
Eng. 22, 6 (2017), 3149–3185.
[41] An Yang, Baosong Yang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Zhou, Cheng-
peng Li, Chengyuan Li, Dayiheng Liu, Fei Huang, Guanting Dong, Haoran Wei,
Huan Lin, Jialong Tang, Jialin Wang, Jian Yang, Jianhong Tu, Jianwei Zhang,
Jianxin Ma, Jianxin Yang, Jin Xu, Jingren Zhou, Jinze Bai, Jinzheng He, Junyang
Lin, Kai Dang, Keming Lu, Keqin Chen, Kexin Yang, Mei Li, Mingfeng Xue,
Na Ni, Pei Zhang, Peng Wang, Ru Peng, Rui Men, Ruize Gao, Runji Lin, Shijie
Wang, Shuai Bai, Sinan Tan, Tianhang Zhu, Tianhao Li, Tianyu Liu, Wenbin Ge,
Xiaodong Deng, Xiaohuan Zhou, Xingzhang Ren, Xinyu Zhang, Xipin Wei, Xu-
ancheng Ren, Xuejing Liu, Yang Fan, Yang Yao, Yichang Zhang, Yu Wan, Yunfei
Chu, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, Zhifang Guo, and Zhihao Fan. 2024.
Qwen2 Technical Report. CoRR abs/2407.10671 (2024).
[42] Zhaojian Yu, Xin Zhang, Ning Shang, Yangyu Huang, Can Xu, Yishujie Zhao,
Wenxiang Hu, and Qiufeng Yin. 2024. WaveCoder: Widespread And Versatile
Enhanced Instruction Tuning with Refined Data Generation. In Proceedings of the
62nd Annual Meeting of the Association for Computational Linguistics . Association
for Computational Linguistics.
[43] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting
Huang, Enbo Zhao, Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei
Bi, Freda Shi, and Shuming Shi. 2023. Siren’s Song in the AI Ocean: A Survey on
Hallucination in Large Language Models. CoRR abs/2309.01219 (2023).
[44] Ziyin Zhang, Chaoyu Chen, Bingchang Liu, Cong Liao, Zi Gong, Hang Yu, Jianguo
Li, and Rui Wang. 2023. Unifying the perspectives of nlp and software engineering:
A survey on language models for code. arXiv preprint arXiv:2311.07989 (2023).
[45] Ziyao Zhang, Yanlin Wang, Chong Wang, Jiachi Chen, and Zibin Zheng. 2024.
Llm hallucinations in practical code generation: Phenomena, mechanism, and
mitigation. arXiv preprint arXiv:2409.20550 (2024).