# TraceRAG: A LLM-Based Framework for Explainable Android Malware Detection and Behavior Analysis

**Authors**: Guangyu Zhang, Xixuan Wang, Shiyu Sun, Peiyan Xiao, Kun Sun, Yanhai Xiong

**Published**: 2025-09-10 06:07:12

**PDF URL**: [http://arxiv.org/pdf/2509.08865v1](http://arxiv.org/pdf/2509.08865v1)

## Abstract
Sophisticated evasion tactics in malicious Android applications, combined
with their intricate behavioral semantics, enable attackers to conceal
malicious logic within legitimate functions, underscoring the critical need for
robust and in-depth analysis frameworks. However, traditional analysis
techniques often fail to recover deeply hidden behaviors or provide
human-readable justifications for their decisions. Inspired by advances in
large language models (LLMs), we introduce TraceRAG, a retrieval-augmented
generation (RAG) framework that bridges natural language queries and Java code
to deliver explainable malware detection and analysis. First, TraceRAG
generates summaries of method-level code snippets, which are indexed in a
vector database. At query time, behavior-focused questions retrieve the most
semantically relevant snippets for deeper inspection. Finally, based on the
multi-turn analysis results, TraceRAG produces human-readable reports that
present the identified malicious behaviors and their corresponding code
implementations. Experimental results demonstrate that our method achieves 96\%
malware detection accuracy and 83.81\% behavior identification accuracy based
on updated VirusTotal (VT) scans and manual verification. Furthermore, expert
evaluation confirms the practical utility of the reports generated by TraceRAG.

## Full Text


<!-- PDF content starts -->

TraceRAG: A LLM-Based Framework for
Explainable Android Malware Detection and
Behavior Analysis
Guangyu Zhang
Independent Researcher
zgy020725@outlook.comXixuan Wang
Australian National University
xixuan.wang@anu.edu.auShiyu Sun
George Mason University
ssun20@gmu.edu
Peiyan Xiao
The College of William and Mary
pxiao@wm.eduKun Sun
George Mason University
ksun3@gmu.eduYanhai Xiong*
The College of William and Mary
yxiong05@wm.edu
Abstract—Sophisticated evasion tactics in malicious Android
applications, combined with their intricate behavioral semantics,
enable attackers to conceal malicious logic within legitimate
functions, underscoring the critical need for robust and in-depth
analysis frameworks. However, traditional analysis techniques
often fail to recover deeply hidden behaviors or provide human-
readable justifications for their decisions. Inspired by advances
in large language models (LLMs), we introduce TraceRAG, a
retrieval-augmented generation (RAG) framework that bridges
natural language queries and Java code to deliver explainable
malware detection and analysis. First, TraceRAG generates
summaries of method-level code snippets, which are indexed in
a vector database. At query time, behavior-focused questions
retrieve the most semantically relevant snippets for deeper
inspection. Finally, based on the multi-turn analysis results,
TraceRAG produces human-readable reports that present the
identified malicious behaviors and their corresponding code
implementations. Experimental results demonstrate that our
method achieves 96% malware detection accuracy and 83.81%
behavior identification accuracy based on updated VirusTotal
(VT) scans and manual verification. Furthermore, expert evalu-
ation confirms the practical utility of the reports generated by
TraceRAG.
Index Terms—Android Malware Detection, Malicious Behavior
Analysis, Large Language Model, Retrieval-Augmented Genera-
tion
I. INTRODUCTION
The rapid growth of mobile services and internet penetration
has enabled individuals to engage in various activities through
mobile applications, such as shopping, banking, and social
networking. According to Statista’s report [1], the number of
mobile app downloads worldwide has steadily increased from
2016 to 2023, when it reached 257 billion, and this upward
trend is expected to continue. However, this surge in app usage
has also made smartphones prime targets for cybercriminals,
with Android devices being particularly vulnerable. The open-
source nature of Android allows users to install apps from
untrusted third-party markets, significantly increasing the risk
*Corresponding author.of malicious software. In Q3 2024, the Kaspersky Security
Network reported detecting 222,444 Android malware samples
and potentially unwanted app variants [2]. Mobile malware
spreads rapidly, and new variants of malicious apps emerge
daily, often in millions [3]. Cyber attackers are employing
increasingly sophisticated techniques, such as obfuscation,
sandbox evasion, and encryption, to evade detection. The
proliferation of malware poses serious security threats, not
only to individuals but also to businesses and government
organizations, as it has the potential to compromise sensitive
data, lead to financial losses, disrupt system functionality, and
even enable large-scale cyberattacks. Consequently, develop-
ing effective methods for malware detection remains an urgent
and critical issue.
Researchers and practitioners have proposed three major
categories of techniques to address such threats: static [4]–
[7], dynamic [8]–[10], and hybrid analysis methods [11]–
[15]. Static analysis enables fast, scalable, and pre-installation
malware detection by attempting to conservatively examine
all possible execution paths [16], but struggles with handling
code obfuscation and dynamic runtime mechanisms such
as virtual function calls, reflection, and event-driven exe-
cution—common techniques in modern mobile applications
[17]–[19]. In contrast, dynamic analysis does not rely on disas-
sembly but instead directly observes an executable’s behavior
at runtime, making it more effective against code obfusca-
tion [20], [21]. However, it is time-intensive and resource-
consuming [22]. Hybrid analysis combines both approaches to
surmount their intrinsic limitations: it first performs static anal-
ysis and then observes the program dynamically at runtime,
but faces the challenge of how to utilize the results of static
analysis to assist dynamic analysis testing [23], [24]. Addition-
ally, most existing methods focus on detection or classification
but lack interpretability, producing outputs that are neither
human-readable nor insightful for thorough analysis. This
raises reliability concerns, especially when applied to real-
world or novel datasets, where their ability to detect previouslyarXiv:2509.08865v1  [cs.SE]  10 Sep 2025

unseen malicious Android applications remains questionable.
The rapid advancement of large language models (LLMs),
exemplified by ChatGPT [25] and Llama [26], has transformed
various fields. By leveraging vast datasets and advanced neural
architectures, these models excel in language comprehension
and generation, pushing the boundaries of artificial general
intelligence and enabling effective collaboration with domain
experts [27], [28]. Building on these strengths, some re-
searchers have explored the application of LLMs to enhance
malware detection accuracy, such as analyzing behavioral se-
mantics [29], capturing structural dependencies [30], enhanc-
ing interpretability through LLMs’ non-decisional role [31], or
leveraging retrieval-augmented generation (RAG) to transform
static features into semantically rich functional summaries
[32]. In contrast to these work leveraging various features as
input, our approach directly provide LLM with Android Java
source code, which provides a more comprehensive view of
an app’s functionality and logic to uncover hidden malicious
behaviors. Walton et al. [33] introduce a hierarchical-tiered
approach to code summarization, however, their method strug-
gles with fully utilizing function call relationships, limiting its
analytical precision. Our framework overcomes this limitation
by generating summaries for code segments and producing
credible analysis reports grounded in real code and call chains.
In this study, we present TraceRAG, an LLM-assisted
system designed to analyze how Android malware carries out
its malicious behavior. First, we construct a vector database to
support a RAG pipeline. For each code segment, we employ
a specific LLM to generate a descriptive summary, which is
stored alongside the corresponding code. Second, we retrieve
potentially suspicious code snippets from the database using a
series of carefully crafted behavior-focused queries. Third, we
prompt another specialized LLM with these retrieved snippets
to perform a depth-first analysis of the code, guided by a
structured and security-oriented prompt design. Finally, an
additional LLM module compiles the analysis into a concise,
human-readable report that includes app metadata, a summary
of potential malicious behaviors, a step-by-step explanation
of suspicious code paths and method calls, and an overall
assessment conclusion.
During the implementation of the proposed framework,
a primary challenge lies in ensuring the precision of code
snippets’ retrieval for subsequent analysis. Given that a typical
Android application may contain thousands of source files with
complex structures and intricate interdependencies, identifying
the most relevant code segments is not easy. To address this
challenge, we carefully design prompts that enable the specific
LLM to generate high-quality code summaries, which serve
as semantic indices for RAG. Additionally, we store class and
method names as metadata filters alongside the original code
and corresponding summaries in the vector database, which
further enhances retrieval accuracy.
Another significant challenge is the hallucination issue in-
herent in LLMs [34], which arises particularly when handling
excessively long inputs or overly complex tasks, potentially
resulting in incorrect or fabricated outputs [35]. To mitigatethis issue, we split the Java code into method-level chunks
to reduce input length and remove dead code or unreachable
statements to ensure that all the inputs fed into LLM are
concise. In addition, we structure the analytical pipeline to sup-
port incremental LLM analysis by decomposing the broader
task into smaller, clearly defined sub-tasks. Each sub-task is
handled by a dedicated LLM, which reduces task complexity
and cognitive load, thereby minimizing the likelihood of
hallucinations. The detailed implementation of this stepwise
approach is elaborated in the methodology section.
To assess TraceRAG’s performance, we conduct a com-
prehensive experimental study. First, we assemble an eval-
uation dataset of 70 malicious and 30 benign APKs from
AndroZoo [36]. Using the original AndroZoo’s labels of
datasets, TraceRAG achieves 90% accuracy on binary malware
detection and 83.81% accuracy on behavior identification.
After updating ground truth with recent VirusTotal (VT) scans
and manual verification (involving source code analysis of
suspicious behaviors and expert consultation), its malware
detection accuracy rises to 96%. We then compare Trac-
eRAG’s reports against VT’s sandbox outputs, demonstrating
our framework’s superior coverage, traceability, and behavioral
organization. In addition, ablation experiments confirm the
effectiveness of each retrieval enhancement technique in our
framework. Finally, we deliver some generated analysis reports
on malicious samples to experts from the Google Android
Security Team for assessment to demonstrate the practicality
and usefulness of our system.
In summary, we make the following contributions:
•To the best of our knowledge, our work is an initial explo-
ration of applying RAG and LLM methods for Android
malicious behavior detection, moving beyond traditional
black-box approaches to achieve code-grounded analysis,
and emphasizing the importance of explainability in par-
allel with decision-making.
•We present TraceRAG, a framework that not only deter-
mines whether an application exhibits a specific malicious
behavior but also pinpoints the exact Java code snippets
and call chains responsible for it, offering clear advan-
tages over existing malware analysis platforms.
•Experimental results demonstrate that TraceRAG
achieves high accuracy in both malware detection
and behavior identification. Furthermore, we
validate the quality and practical usefulness of
its analysis reports through expert feedback. Our
code and the generated reports are available at
https://github.com/yanhaixiong/TraceRAG.
II. LITERATURE REVIEW
A. Large Language Models in Code Understanding
LLMs have demonstrated considerable potential in the
domains of natural language understanding and program-
ming code processing tasks [37]. In the context of code
understanding, LLMs can serve as on-demand information
support by generating comprehensive explanations, detailed

API descriptions, clarifications of domain-specific concepts,
and illustrative usage examples [38]. Moreover, LLMs can
directly produce or facilitate the generation of executable
and highly readable source code from decompiled binaries
[39], as well as identify and rectify errors within obfuscated
disassembled code [40], thereby improving reverse engineer-
ing performance. To further enhance development efficiency
and improve code maintainability, recent studies have em-
ployed methods such as few-shot training for project-specific
adaptation and semantic prompt augmentation to enhance
the performance of LLMs in code summarization tasks [41],
[42]. In malware summarization, Lu et al. [43] fine-tune
CodeT5+model using transfer learning, integrating malicious
software functional features and decompiled pseudocode struc-
tural characteristics to generate informative code summaries.
Furthermore, Walton et al. [33] leverage OpenAI’s GPT-
4o-mini model with optimized prompt engineering to auto-
matically classify Android malware and generate functional
summaries at function, class, and package levels, thereby
enabling systematic security analysis and tracing of malicious
behaviors.
B. Large Language Models in Malware Analysis
Conventional malware detection methods often struggle
against sophisticated and polymorphic malware designed to
evade detection [44]. Advancements in LLMs introduce novel
methodologies that overcome these limitations by leveraging
extensive pre-trained knowledge to identify subtle coding pat-
terns in malware [45]. Some researchers have applied LLMs to
perform static analysis on Android apps, facilitating effective
malware classification and generating detailed explanatory
insights [29], [46]. For instance, Qian et al. [30] construct
a practical, context-driven framework that employs static
analysis combined with backward program slicing to extract
sensitive API contexts, followed by a three-tier LLM reason-
ing pipeline enhanced with factual consistency verification,
improving the accuracy of malware detection. Additionally,
Li et al. [31] compare traditional decision-centric Android
malware detection models with ChatGPT, demonstrating the
superiority of LLMs’ non-decisional contributions in provid-
ing detailed analysis. Similarly, Arikkat et al. [32] propose
a RAG framework that transforms structural Android app
features into semantically rich descriptions, achieving superior
classification accuracy when combined with domain-specific
BERT classifiers. Furthermore, employing a hybrid testing
approach, Wang et al. [47] integrate static analysis of API call
chains with LLM-enhanced test case generation and dynamic
code injection to replicate and detect sensitive behaviors.
The application of LLMs for malware detection also extends
beyond Android platforms into diverse environments and data
formats, including websites [48], Windows systems [49]–[52],
Java source files [53], [54] and NPM Packages [55], [56].
While existing approaches have advanced Android malware
detection through various learning-based methods, they funda-
mentally operate at the abstraction level of extracted features.
In contrast, our approach directly analyzes Java source codeat the method level, establishing semantic bridges between
natural language queries and actual code implementations
through RAG. This shift from feature-level to code-level anal-
ysis enables not only detection but also precise localization of
malicious logic within applications, providing security analysts
with traceable evidence paths from suspicious behaviors to
their concrete implementations.
III. PROPOSEDMETHODOLOGY
This section presents an overview of TraceRAG. The system
begins by reverse-engineering an Android application to ex-
tract all associated Java files. These files are then segmented
and cleaned by a dedicated LLM, named LLM-Cleanser, to
improve the quality of subsequent analysis. For each processed
code segment, a textual description is generated by LLM-
Describer and used as the index, while both the description
and the corresponding code are stored together in the vector
database for retrieval. Subsequently, relevant code segments
are retrieved from the database based on carefully designed
queries and analyzed by LLM-Analyzer to detect potential
malicious behaviors within the app. Based on the LLM-
Analyzer’s iterative analysis, the system generates a report
summarizing any suspicious activities detected and provides
a clear, comprehensive explanation. The overall system archi-
tecture of TraceRAG is shown in Fig. 1. For the call chain,
the output of one step serves as the input to the next, and
we implement this agent-like sequence using a LangGraph
workflow.
A. RAG Framework
In this study, we employ a RAG framework combined with
LLMs to facilitate malicious software detection in Android
applications.
In a typical RAG application, there are two primary com-
ponents: (1) an indexing pipeline for ingesting data from a
source and constructing an index, and (2) a retrieval-and-
generation mechanism that processes a user query in real
time, retrieves relevant data from the index, and passes it to
the model [57]. However, our framework differs in a crucial
respect: rather than retrieving text-based content, our goal is
to retrieve Java code. Traditional RAG systems assess the
semantic similarity between text queries and text documents,
but Java code—lacking natural language semantics—cannot
be directly retrieved in this manner.
To overcome this challenge, we leverage LLM-Describer to
generate descriptive summaries for each Java code, articulating
its functionality and potential usage in human-readable text.
These generated descriptions serve as “indexes” that enable
retrieval based on semantic similarity with the user’s natural-
language query. In practical terms, we store each Java code
snippet alongside its corresponding description and metadata
in a vector database. Consequently, when the system receives
a query in human language, it compares the query with
the code’s textual descriptions and accurately retrieves the
pertinent code segments, thus fulfilling the primary goal of
our RAG-based framework. Additionally, we create a separate

Fig. 1. System Architecture of TraceRAG
vector database for each app, to ensure that no Java code from
other apps is mixed in and to avoid collisions.
We adopt the RAG paradigm for three primary reasons.
First, an Android application inherently serves as a database,
thus establishing a well-defined scope for building a vector
database. In addition, the Java code within the app naturally
consists of distinct code segments, effectively mitigating the
challenges associated with chunking. Moreover, despite Java
code, as a machine-oriented language, lacks inherent human-
language semantics, recent advancements in LLMs enable ac-
curate code understanding and summarization. Consequently,
these capabilities enable precise retrieval of Java code blocks
that semantically align with human-language queries, ensuring
that only relevant code is selected for analysis.
All LLM modules in our framework (LLM-Cleanser, LLM-
Describer, LLM-Analyzer, LLM-Organizer and several Re-
viewers) utilize the OpenAI o3-mini model [58], a compact
model optimized for reasoning and code analysis. Its low com-
putational cost and strong performance make it particularly
well-suited for our task within the TraceRAG pipeline.
B. Description Generation
In this section, we present our method for generating
high-quality descriptions of Java code. This process includes
APK decompilation, code splitting and cleaning, as well as
description generation, which collectively support accurate and
efficient semantic retrieval in downstream analysis.
1) APK Decompilation:We begin by decompiling the An-
droid APK using the reverse engineering tool JADX1to obtain
all associated Java source files. To enhance the clarity and
traceability of the final report, we also extract key metadata
from the decompiled content, including package name and
SHA-256.
1https://github.com/skylot/jadx2) Code Splitting and Cleaning:A major challenge at this
stage is that some Java files contain millions of tokens, far
exceeding the input limits of LLMs and degrading the quality
of generated descriptions. Given that Java code follows a well-
defined structure—where classes encapsulate methods—we
apply method-level code splitting using the JavaLang library
in Python. Each method is extracted individually, while pre-
serving essential information such as imported packages and
class-level variable declarations. In the end, we create each of
the split methods a file, converting a long class level file into
many smaller method level files.
Another factor affecting description quality is code obfus-
cation, which is common in real-world Android applications.
Obfuscated code often contains dead code and unreachable
branches that do not contribute to actual execution. To mit-
igate this, we use LLM-Cleanser to remove such irrelevant
code, preserving only the core logic. This results in clearly
organized code snippets of manageable length, making them
well-suited for the next step of description generation. Fig. 2
presents the exact prompt used by LLM-Cleanser together with
a representative cleaning case on the classic Android mal-
warecom.bp.statis.bloodsugar. The cleaned snip-
pet clearly eliminates unreachable and opaque code while
preserving the essential semantics, resulting in a structure
closely resembling the textbook implementation. This simi-
larity demonstrates the effectiveness of our cleaning step.
3) Code Description:We leverage LLM-Describer to gen-
erate descriptions of code snippets through carefully de-
signed prompt engineering. The structure of our prompt
template consists of two key components: First, the LLM-
Describer is instructed to focus on the core functionality
of the code—explaining in detail what the code does, in-
cluding its inputs and outputs. Second, the prompt guides
the LLM-Describer to identify and describe any potentially
malicious intent. The output includes all observed suspicious

Fig. 2. Prompt and Cleaning Case for LLM-Cleanser
behaviors, enabling more accurate semantic retrieval when
using queries related to specific threats. Fig. 3 presents
the exact prompt used by LLM-Describer together with
a representative case on thep(String)method from
com.bp.statis.bloodsugar. The output successfully
identifies the string permutation obfuscation and highlights
suspicious behaviors, which aligns with our expected objec-
tives for the description step.C. Vector Database Construction
To improve the accuracy of code retrieval, we not only index
the LLM-generated code descriptions but also incorporate
metadata as auxiliary labels to help categorize and filter code
snippets. Specifically, we include the following elements for
each record, enabling precise filtering when a query requires
a specific method definition:
•Processed Code Snippets: The method-level code snippets
extracted from the application after splitting and cleaning.

Fig. 3. Prompt and Description Case for LLM-Describer
•Code Description: A summary generated by the LLM
describing the method’s functionality and potential mali-
cious behavior.
•Method Name: The name of the method.
•Class Name: The name of the class to which the methods
belong.
We employ OpenAI’s text-embedding-ada-002 model to
generate embeddings for each record [59], encompassing both
the description index and associated metadata.
D. LLM Conversation
With all preparatory steps completed, we proceed to analyze
the suspicious behaviors of the target application through
interactions with LLM-Analyzer.
1) Query Design:To conduct a comprehensive analysis, we
design 11 retrieval queries covering three common categories
of malicious behavior observed in Android malware, as shown
in Table I. These queries are formulated based on empiri-
cal experiments and expert input from professional malware
analysts. Additionally, they are intentionally kept simple for
ease of interpretation and to align better with LLM reasoning,
which reduces ambiguity in multi-turn analysis. Additionally,
the query set can be easily updated to reflect emerging
malware patterns, supporting incremental indexing of recent
apps and behaviors. For each APK under inspection, all 11
queries are executed sequentially, with each query invoking the
complete iterative retrieval pipeline before proceeding to the
next, thereby ensuring full coverage of all targeted behaviors.TABLE I
QUERYDESIGN FORTRACERAG
Type Query
Information Theft
and AbuseQ1: Does the application access or collect sensitive
user data (e.g., SMS, contacts, location, or device
identifiers)?
Q2: Does the application capture user activity
through screen recording or screenshots?
Q3: Does the application connect to suspicious
external URLs or perform background downloads
without user interaction?
Q4: Is obfuscation or encryption used to conceal
communication endpoints or downloaded content?
Monetary Fraud and
Financial AbuseQ5: Does the application send messages or make
calls that may incur charges without user consent?
Q6: Does the UI mislead users into clicking ads or
subscribing to services?
Q7: Is there evidence of tampering with in-app
purchases or payment processes?
Privilege Abuse and
System ExploitationQ8: Does the application request elevated privileges
(e.g., Accessibility or Device Administrator) or at-
tempt to maintain persistence?
Q9: Does the application support remote command
execution or include dynamic code loading and anti-
analysis techniques?
Q10: Is there evidence of root-level activity, such
as executing system commands or interacting with
system partitions?
Q11: Does the application use native libraries or
known exploits to escalate privileges or bypass
system security policies?

2) Retrieval and Result Processing:A critical aspect of
retrieval is setting an appropriate threshold. A overly high
threshold may result in few or no matches, potentially ex-
cluding truly malicious code. Conversely, a low threshold
may yield many irrelevant results, increasing analysis time
and degrading the quality of the final report. To strike a
balance between stability and relevance, we employ a two-
stage retrieval strategy. First, we apply a top-k threshold of five
to ensure a consistent number of code snippets retrieved. Then,
our Relevance-Reviewer LLM filters out irrelevant snippets
and retains only those indicative of suspicious behavior. If
none of the top-5 retrieved snippets are relevant to the query
or demonstrate any indicators of malicious behavior, this LLM
outputs a message that indicates no related code is found, and
the query result is excluded from further analysis. This ap-
proach reduces noise while maintaining retrieval consistency,
thereby improving the accuracy and efficiency of downstream
processing.
3) LLM Analysis:Following retrieval and initial filtering
by Relevance-Reviewer, the remaining code snippets—those
most likely to contain malicious behavior—are analyzed indi-
vidually by LLM-Analyzer to determine whether they exhibit
malicious intent. The analysis proceeds in several steps. First,
LLM-Analyzer identifies the core behavior of the given code,
determines its intent, and reports the fully qualified code
path. If the code does not exhibit malicious behavior, or if a
conclusion can already be drawn based on the current snippet,
LLM-Analyzer will generate a detailed result summarizing the
identified behavior and include the corresponding code path
for reference.
If LLM-Analyzer determines that the current code snippet
invokes another function to achieve a specific intention, and
additional context is required to understand its behavior and
reach a conclusion, it will generate a follow-up query. This
query includes the target method’s name, the corresponding
class name, and its input parameters to support further analy-
sis. For example:
“Could you provide the implementation of the method
j defined in class b, which takes one String as an input
parameter?”
This newly generated query is then used to retrieve from
the vector database mentioned before. During retrieval, the
stored metadata is applied to narrow the search scope. In
this example, the system filters for code snippets labeled with
”method name j”and”class name b”. Typically, this yields a
single match; however, to address potential naming collisions,
all retrieved snippets are passed to Collision-Reviewer. This
LLM-based reviewer selects the most appropriate result, which
is then forwarded to LLM-Analyzer for continued analysis. We
also implement Query-Reviewer that inspects LLM-Analyzer’s
output and, if it detects a follow-up query, invokes the retrieval
module; otherwise, it generates the final results.
It is worth noting that although both LLM-Describer and
the LLM-Analyzer are involved in interpreting code behavior,
they serve distinct purposes. LLM-Describer only focuses
on summarizing the general intent of a given code snippet.Its primary task is to clearly describe the code’s function-
ality, including its inputs, outputs, and overall purpose. In
contrast, LLM-Analyzer is designed to conduct a deeper
investigation into the code’s usage context, with the goal of
identifying malicious behavior by digging out all components
contributing to the malicious functionality. Fig. 4 illustrates the
prompt and a segment of the LLM-Analyzer’s workflow on
com.bp.statis.bloodsugar. The results indicate that
the LLM-Analyzer not only pinpoints suspicious behaviors
but also formulates appropriate follow-up queries, thereby
validating the practicality of our analysis step.
4) Report Generation:The reporting process for results
generated by LLM-Analyzer is organized into three hierar-
chical layers: code reports, query reports, and a final report.
Each layer is produced by a dedicated LLM-Organizer. First,
each code snippet may require multiple rounds of analysis and
supporting code retrieval. An LLM-Organizer compiles these
results into a code report. Then, all code reports under the same
query are aggregated into a query report. Finally, all eleven
query reports are combined into a final report. This final report
is structured into four main parts: App Info, Overall Summary,
Detailed Analyses, and Conclusion. In the Detailed Analyses
section, each query’s subsection either provides a detailed
summary of the identified malicious behavior, complete with
implementation details and supporting code references, or
explicitly states that no related malicious activity is detected.
IV. EVALUATION
In this section, we evaluate the performance of TraceRAG
by answering the following research questions (RQs):
•RQ1: How effective is TraceRAG in detecting Android
malware and malicious behavior?
•RQ2: Do the preprocessing steps of the RAG module
enhance its effectiveness and robustness?
•RQ3: Are the reports generated by TraceRAG instructive
and valid?
A. Datasets
To rigorously assess TraceRAG’s performance, we use a
dataset sourced from AndroZoo [36], a continuously growing
collection of Android applications gathered from multiple
official App stores like Google Play. To ensure that our
samples cover the vast majority of real-world APKs, we
randomly download 1,000 apps from AndroZoo spanning 2010
to 2025, each of which has been scanned on VT by more than
ten security scanners2. After APK decompilation and code
splitting described above, we find that most samples contain
fewer than 3,000 code snippets. We therefore randomly select
100 apps within this range—30 benign and 70 malicious,
based on AndroZoo’s labels—as our evaluation dataset. This
ratio is used to expose TraceRAG to more malicious behav-
iors, since the goal is behavior analysis rather than binary
classification. Table II shows details about the used dataset.
Statistics show that generating the 100 corresponding analysis
2https://www.virustotal.com/gui/home/upload

Fig. 4. Prompt and Analysis Process of LLM-Analyzer
reports consumes over 100 million total tokens and incurs
approximately $600 in API charges.
TABLE II
OVERVIEW OF THEEVALUATIONDATASET
Attribute Interval Range Sample Count
Snippet Count Before Splitting<100 54
100–200 26
200-400 20
Snippet Count After Splitting<1000 48
1000–2000 16
2000-4000 36
Size (MB)<5 65
5–20 26
20–50 9B. RQ1: Performance of TraceRAG
To answer RQ1, we assess TraceRAG across three related
evaluations:
•Evaluation 1: A binary malware detection evaluation
using AndroZoo labels as ground truth.
•Evaluation 2: A refined binary malware detection evalua-
tion using VT updated results supplemented with manual
verification as ground truth to account for discrepancies
between AndroZoo labels and VT results.
•Evaluation 3: A multiclass behavior detection evaluation
in which each malicious app is assigned to one or more
of the three predefined behavior categories (Table I),
with predictions compared against VT’s behavior analysis
results.
The evaluation metrics employed in our experiments are
accuracy, precision, recall, and F1-score. For the multiclass
evaluations, since each malicious APK may exhibit multiple

TABLE III
OVERALLPERFORMANCE(%)OFTRACERAGONMALWARE AND
BEHAVIORDETECTION
Setting Accuracy Precision Recall F1
Evaluation 1 90.00 87.50 100.00 93.33
Evaluation 2 96.00 95.89 98.59 97.22
Evaluation 3 83.81 84.89 86.35 85.46
behavior types, we treat each of the three behavior categories
as a separate binary classification and compute micro-averaged
precision, recall, and F1-score.
When evaluating TraceRAG on benign samples, we note
that it occasionally reports potential vulnerabilities or risks
rather than true malicious behaviors. This effect stems from
our prompt’s instruction to flag any suspicious code, leading
TraceRAG to treat security risks as indicators of malware. To
prevent conflating non-malicious vulnerabilities with malware
detection, we establish a criterion: a sample is counted as
malicious only when the report explicitly identifies a malicious
behavior and provides a corresponding explanation of its
implementation. Generic warnings, such as “this code may
pose risks when used”—are therefore not considered evidence
of malware. By applying this rule, we ensure that TraceRAG’s
performance metrics reflect genuine malware detection rather
than general security concerns.
Table III summarizes the results for the three evaluation set-
tings described above, demonstrating that TraceRAG achieves
strong overall performance. Specifically, in the first malware
detection evaluation based on AndroZoo labels, TraceRAG ob-
tains an accuracy of 90%, correctly identifying all 70 malicious
APKs (achieving a recall of 100%), while misclassifying 10
benign samples as malware. For behavior detection, TraceRAG
achieves an overall accuracy of 83.81%, with precision, recall,
and F1-scores similarly high across the dataset. These results
also demonstrate the effectiveness of each LLM-driven module
in our pipeline.
1) Malware Detection Performance:To obtain more ac-
curate performance estimates, we re-examine the 30 samples
originally labeled benign by AndroZoo, using updated VT
scans and manual verification. Among the 10 false positives
reported by TraceRAG, seven are found to be valid detections
upon closer inspection. In addition, we identify one actual
malicious sample that TraceRAG failed to detect—a false
negative. Correcting these discrepancies raises our effective
malware detection accuracy from 90% to 96%.
Among the ten false positive cases in Evaluation 1
that use AndroZoo labels as ground truth, one com-
mon scenario involves samples that are still labeled
as benign by AndroZoo but have been reclassified as
malicious in more recent VT scans. For example, in
the case ofcom.smartsm5.smart_5_293 (sha256:
2A88D86B5F36EFD0E9A668B84C893171C0A9326DD154FAEF1A35F80884F5BED7)3, TraceRAG’s report in-
cludes the following excerpt:
Within the run() method, the app accesses an exter-
nal URL (via main.this.downloadImgUrl) and down-
loads an image silently.
- The downloaded image is stored in the device’s
external storage under the DCIM/Camera folder
without any user notification.
- The call chain is clear: execution enters run()→
retrieves the URL from main.this.downloadImgUrl
→performs a silent download and writes to external
storage, reflecting covert behavior.
Although this sample is labeled as benign by AndroZoo
(based on a VT scan dated 2014-06-26), more recent VT
results have reclassified it as malicious (dated 2021-02-05),
citing external URL-related suspicious behavior. Three other
cases exhibit similar discrepancies between historical and
updated VT results, further validating TraceRAG’s capability
to detect malware behavior that may have been previously
overlooked.
Apart from such outdated-labeling cases, we also ob-
serve examples where VT fails to detect actual malicious
behavior. One such case iscom.dijlah.sh_khotaba
(sha256:55152EE88521E599145568F8CF949BAA4D
9884B6670002C8FC760844CD540947)4, which is also
labeled benign in AndroZoo. However, TraceRAG’s result
shows that it allow the application to perform unauthorized
financial operations by sending SMS and initiating phone
calls without user confirmation. We manually confirm that
this app’s code indeed contains silent SMS-sending functions,
with permissions to modify both the message content and the
recipient. Two additional samples fall into this category, where
TraceRAG successfully identifies malicious functionality that
is not flagged by VT.
The remaining three cases appear to be genuine false
positives. In these instances, TraceRAG infers that the apps are
attempting to connect to an external URL and silently conduct
a download behavior without the user’s consent. However,
our inspection reveals that the apps are merely conducting
regular connection functions without evidence of malicious
intent. This suggests a limitation of LLM-based reasoning:
lacking access to the actual content of the external URL, the
model tends to conservatively classify ambiguous URL-related
behavior as malicious.
2) Behavior Detection Performance:To evaluate Trac-
eRAG’s ability to detect each behavior type, Table IV presents
the per-category precision, recall and F1-score across all 70
malicious samples. In total, TraceRAG correctly identifies 176
of the 210 labeled behaviors. However, the results indicate
that behaviors associated withMonetary Fraud and Financial
Abusepresent greater challenges for accurate detection, with
3https://www.virustotal.com/gui/file/2a88d86b5f36efd0e9a668b84c893171c0
a9326dd154faef1a35f80884f5bed7
4https://www.virustotal.com/gui/file/55152ee88521e599145568f8cf949baa4d
9884b6670002c8fc760844cd540947

TABLE IV
DETAILEDPERFORMANCE(%)OFTRACERAGONBEHAVIORDETECTION
Type Accuracy Precision Recall F1
Information Theft
and Abuse88.57 98.41 89.86 93.94
Monetary Fraud and
Financial Abuse75.71 68.75 75.86 72.13
Privilege Abuse and
System Exploitation87.14 87.50 93.33 90.32
noticeably lower classification performance compared to the
other categories. By analyzing TraceRAG’s reasoning process
for this type, we identify three primary misclassification
causes, each corresponding to one of the three queries under
this category. First, sending SMS may be part of an app’s
legitimate functionality (e.g., for verification via one-time
passwords). However, if TraceRAG cannot reliably determine
whether the appropriate permissions have been requested or
whether user consent has been properly obtained, it may
incorrectly classify such behavior as malicious. Second, as-
sessing whether the user interface is misleading involves
interpreting elements related to front-end design, button labels,
and behavioral cues. Such interaction-related information is
typically absent from the Java source code, which may lead
to misinference by TraceRAG. Third, in-app purchases and
payment processes often span multiple modules. Developers
may also employ techniques such as reflection, dynamic
loading, and code obfuscation to conceal critical operations.
Even with some capacity for behavioral tracing, TraceRAG
may fail to capture the full execution chain or detect subtle
manipulations. As the invocation chain becomes longer and
more complex, TraceRAG is more prone to misclassification.
3) Comparison with VirusTotal Reports:Currently, VT
offers several sandbox analyses—Tencent HABO, Zenbox
android, VirusTotal Droidy, and VirusTotal R2DBox, but each
delivers either behavioral logs or source-code snippets in
isolation and lacks explicit linkage between observed behav-
iors and their implementing code. Moreover, their coverage
remains low: on 100 randomly selected APKs, none exceed
40% coverage (as shown in Table V). In contrast, TraceRAG
can generate a comprehensive report for every APK: it not
only identifies suspicious behaviors but also retrieves the exact
Java snippets responsible and reconstructs the full call chains
that realize those behaviors, achieving 100% coverage in
our evaluation. In addition, by clearly categorizing malicious
behavior types and pinpointing their root causes, TraceRAG
can help experts narrow their focus, significantly reducing
investigation scope and saving valuable time.
C. RQ2: Ablation Study on TraceRAG
Since TraceRAG’s analysis depends critically on the quality
of retrieval and the additional information provided during
analysis, any change in these components can significantly
affect the final report. To evaluate the necessity of each
retrieval enhancement technique in our framework, we conductablation experiments from three perspectives: the role of code
descriptions, the impact of preprocessing, and the influence of
multi-turn interaction. To maintain consistency, we continue
to usecom.bp.statis.bloodsugaras our example,
which contains 9,107 code snippets before splitting and 86,035
snippets after splitting.
1) Role of Code Description:As described before, Trac-
eRAG relies on code descriptions generated by LLM-
Describer to index and retrieve the most relevant code snippets
for each malicious behavior query, which are then passed to
LLM-Analyzer for further analysis. To validate the importance
of the description step, we perform an ablation experiment in
which we skip description generation and instead index only
the raw source code. Incom.bp.statis.bloodsugar
case study, indexing with code descriptions achieves successful
retrievals for most queries. In contrast, indexing on raw code
alone returns no valid matches among the top five results,
making any downstream analysis impossible.
These results further support one of this paper’s contribu-
tions: by leveraging LLMs and RAG, we establish a bridge
between natural language queries and Android Java code,
enabling simple user queries to retrieve the most relevant
snippets. This approach is not limited to Java, it can be
extended to other languages such as Python or C++ and
explored in a variety of related research domains.
2) Effect of Preprocessing:Before the description gen-
eration process of TraceRAG, we first apply a series of
preprocessing steps, including code splitting and cleaning.
This is motivated by the observation that many Java files are
excessively long and contain heavily obfuscated code, which
can hinder code understanding and retrieval effectiveness. To
evaluate the necessity of these preprocessing steps, we conduct
an ablation in which we skip splitting and cleaning, and
instead pass the entire original Java file to LLM-Describer
for description generation. To account for this change, we also
adjust the prompt for the LLM-Describer to handle entire Java
file, which typically contain a single public class with multiple
methods. We instruct the model to provide an overview of this
class along with the explaination of each method’s intent and
functionality.
As shown in Table VI, omitting preprocessing causes a steep
drop in TraceRAG’s performance: only 2 out of 7 queries
correctly return the relevant malicious behaviors (Q1: access
or collection of sensitive user data; Q4: use of obfuscation or
encryption). Moreover, even for those two correctly retrieved
cases, the subsequent analysis reports are relatively superficial,
and call chains are rarely reconstructed successfully.
A meticulous post-hoc review reveals that these results
are mainly caused by two reasons. First, without splitting
and cleaning, the top-5 snippets retrieved for most queries
bear no relation to the corresponding behavior and are sub-
sequently discarded by the Relevance-Reviewer. As a result,
LLM-Analyzer fails to receive any relevant code, causing
the malicious behavior to be overlooked. Second, even when
relevant snippets are retrieved, the input remains overly large
and contains extraneous code, which degrades analysis quality.

TABLE V
COMPARISON OFTRACERAGANDVT REPORTS
Behavior Source code Link between them Coverage Ratio Malicious Benign
Tencent HABO ✓ × × 36% 28 8
Zenbox android ✓ × × 1% 1 0
VirusTotal Droidy × ✓ × 37% 26 11
VirusTotal R2DBox × ✓ × 3% 3 0
TraceRAG ✓ ✓ ✓ 100% 70 30
TABLE VI
COMPARISON OFDETECTIONRESULTS AND NUMBER OF CODES
ANALYZED
TraceRAG - No Split and Cleaning TraceRAG VT
Detection Codes Detection Codes Detection
Analyzed Analyzed
Q1 1 2 1 3 1
Q2 0 3 0 3 0
Q3 0 1 1 4 1
Q4 1 2 1 3 1
Q5 0 1 0 1 0
Q6 0 3 0 3 0
Q7 0 1 0 1 0
Q8 0 3 1 3 1
Q9 0 1 1 4 1
Q10 0 4 1 4 1
Q11 0 1 1 1 1
Total 2 22 7 30 7
Moreover, follow-up queries frequently target incorrect snip-
pets, causing the analysis process to terminate prematurely.
These findings demonstrate that code splitting and cleaning
process not only improve retrieval accuracy but also enhance
analysis quality. Shorter and cleaner inputs allow TraceRAG
to focus on simpler tasks, which also reduces hallucination
issues.
3) Influence of Multi-turn Conversation:Android applica-
tions routinely invoke functionality across multiple classes,
and malware authors often employ dynamic loading or ob-
fuscation to conceal their intent. As a result, key behaviors
may only become apparent when the analyzer can follow these
multi-step invocation paths. To support this, TraceRAG allows
the LLM-analyzer to generate follow-up queries for additional
code snippets, iteratively piecing together the full execution
chain and draw accurate conclusions. To evaluate the necessity
of this multi-turn analyze, we remove the follow-up query
part from LLM-Analyzer’s prompt, only allow it to reason
in a single pass. The results mirror those of the preprocessing
ablation, TraceRAG produces only superficial summaries, and
cannot reconstruct call chains. It can only describe possible
intent or usage of the code, but cannot explain how those
intents are achieved or what outcomes they produce. These
findings underscore the importance of multi-turn interaction, as
successive queries enable TraceRAG to derive deeper insights
into complex malicious behaviors.D. RQ3: Specialist Feedback and Usability Study
Since TraceRAG focuses on behavior-level detection and
interpretability, rather than merely performing binary malware-
versus-benign classification, it fundamentally differs in objec-
tive and output format from existing Android malware detec-
tion methods. As a result, direct quantitative comparisons with
conventional detection systems are not entirely meaningful. To
address this, we conduct a structured developer study aimed
at evaluating the practical utility of our system. The goal is
to evaluate how well the system helps developers understand
Android applications, detect malicious behavior, and reduce
analysis time.
1) Participants and Survey Design:We invite specialists
from the Google Android Security Team to review a set of
analysis reports generated for Android applications that are
flagged as malware on AndroZoo. A total of 42 reports are
shared, and the specialists provide 31 pieces of feedback
covering 24 APKs, selected at random. For APK reports
evaluated by multiple specialists, we use the average of their
scores.
The survey includes three main sections. The first section
evaluates theusefulness of each componentof the LLM-
generated report, including the App Info, Overall Summary,
Detailed Analyses, and Conclusion. The second section fo-
cuses on the system’sability to identify malicious behaviors,
asking participants to assess its performance across predefined
behavior categories such as information theft, monetary abuse,
and privilege escalation. The third section coversoverall
accuracy and findings, including whether the report correctly
identifies malicious functions, whether participants discover
new insights, and how confident they feel in the report’s
conclusions.
The survey uses a mix of 5-point Likert scale questions,
multiple-choice questions, and a few open-ended items (in the
general survey only). We release the survey along with the
source code.
2) Feedback Results:We analyze the collected report from
the following three perspectives.
Usefulness of Report Components.Participants rate the
usefulness of four key components of the LLM-generated
report: App Info, Overall Summary, Detailed Analyses, and
Final Conclusion. The App Info section receives the highest
average usefulness score of 4.83, reflecting consistent clarity
and relevance. The Detailed Analyses and Overall Summary

05101520
123456789101112131415161718192021222324Conclusion Overall Summary Detailed Analysis App InfoFig. 5. Usefulness of Report Components
also received positive ratings, with average scores of 3.69
and 3.53, respectively. Several participants mention that these
sections highlight suspicious behaviors and reduce the amount
of manual inspection needed. The Summary section shows
more variation in ratings, with an average score of 3.23,
suggesting that further refinement may improve focus and
clarity. Figure 5 shows the distribution of scores for each
section.
Malicious Behavior Identification.To assess how effectively
the system identifies malicious behaviors, participants report
whether the flagged behaviors in each report align with their
own analysis. Out of 29 responses, 65.52% indicate alignment,
20.69% disagree, and 13.79% remain unsure. These responses
suggest the system generally captures relevant behavior pat-
terns, though precision can still improve.
Participants submitted six reports of incorrect behavior
categories across 31 reports. Three relate toInformation Theft
and Abuse, two toPrivilege Abuse and System Exploitation,
and one toMonetary Fraud and Financial Abuse. This shows
that misclassifications occur across all behavior types, with
slightly more in the information theft category.
When asked whether any major behavior types are missed,
73.33% of 30 responses say ”no,” 6.67% say ”yes,” and 20%
remain unsure. The two participants who believe behaviors
are missed point to indicators related toPrivilege Abuse and
System Exploitation. This indicates that, while the system
broadly covers key behaviors, privilege-related cases may need
better detection.
Accuracy and Findings.Participants evaluate the overall
accuracy of the system’s conclusions. Out of 30 responses,
53.33% state the final app classification (malware or not) is
accurate, 16.67% say it is inaccurate, and 30% are unsure.
This suggests a general sense of reliability.
Among 25 responses related to confirmed malware samples,
56% say the system correctly identifies malicious methods
or functions. This supports the system’s ability to highlight
critical behaviors. However, 16% report missing key meth-
ods, and 28% are unsure, indicating a chance to improve
detection—especially for behaviors that are subtle, hidden, or
depend on context.When asked whether flagged methods and classes are
helpful for malware detection, 34.48% say all are useful,
another 34.48% say most are useful but some are misleading,
6.9% say only a few are useful, and 6.9% say most are not
useful. Free-text responses mention concerns such as too much
detail, irrelevant SDK-related content, and missing context like
Android version differences or dynamically loaded code.
Moreover, most participants express confidence in their
ability to evaluate the system. Out of 31 responses, 15 rate
their confidence at 4 out of 5, and 9 give a full 5. Only 7 rate
below 4. These findings highlight that the system is capable of
identifying malicious behavior across a range of samples. They
also point to an opportunity to further align flagged content
with user expectations by refining how suspicious or malicious
activity is prioritized and presented.
V. DISCUSSION
In this section, we discuss the current limitations in Trac-
eRAG and outline possible directions for improvement.
1) Information Loss during Code Cleaning:TraceRAG’s
preprocessing pipeline removes dead or highly obfuscated
code to reduce noise, but this step can inadvertently eliminate
legitimately executed logic. As a result, the LLM-Describer
may generate descriptions that omit critical behavior, which
in turn impacts downstream analysis. Our ablation study also
reveals the inverse problem: skipping the cleaning step leads
to generated descriptions containing useless information from
dead code, which degrades the quality of further analysis. This
issue only arises occasionally when input code is extremely
obfuscated, so we have to trade off the conciseness and
completeness of the code. Despite extensive prompt tuning
to mitigate information loss, some essential logic may still
occasionally be removed. In future work, we plan to evaluate
more advanced LLMs and develop adaptive cleaning strategies
that balance noise reduction with preservation of critical code
paths.
2) Limitations of Java-only Analysis:While static analysis
of Java code uncovers many malicious behaviors, TraceRAG
currently misses functionality implemented outside of the
indexed app code. Some malware hides core logic in native
libraries—exposed only as native method stubs and hidden in
binaries that standard decompilers cannot inspect. At the same
time, follow-up queries generated by LLM-Analyzer some-
times refer to Android SDK methods whose implementations
lie outside our indexed corpus, preventing TraceRAG from
retrieving or examining their code. Although LLMs possess
strong general reasoning capabilities, they may struggle with
highly specialized, domain-specific tasks. In future work, we
plan to incorporate such considerations into our framework to
further improve TraceRAG’s robustness.
3) Compute Resources Constraints:All LLMs used in our
experiments are based on the state-of-the-art OpenAI o3-
mini model, which provides TraceRAG with strong reasoning
capabilities under an acceptable cost constraint. However,
due to limitations in computational resources and budget,
we are unable to conduct experiments on a larger scale.

While local deployment of LLMs would allow for greater
flexibility, it requires significantly more hardware support.
After extensive testing, we opted to use OpenAI’s API for
all experiments. Nevertheless, the API imposes restrictions
on traffic load, preventing us from utilizing more threads to
accelerate processing. As a result, we have to make trade-offs
between experimental time cost and dataset scale.
VI. CONCLUSION
In this work, we present TraceRAG, a novel framework that
integrates LLMs with RAG to enable explainable Android
malware detection and analysis. We first process each app
into cleaned, method-level code snippets and generate concise
semantic summaries for efficient indexing; when a specific
behavior query is issued, TraceRAG retrieves the most relevant
snippets, performs iterative analysis to identify malicious
behaviors and corresponding code paths, and then compiles the
findings into a structured, human-readable report. Grounded
by comprehensive evaluations, TraceRAG demonstrates strong
performance in both malware detection and behavior identi-
fication. Compared to existing malware detection platforms
that provide only simple behavioral logs or isolated code
fragments, TraceRAG-generated reports are more traceable,
clearly organized, and instructive. A promising direction for
future work would be to extend the LLM-driven analysis
framework to support the examination of native libraries and
dynamically loaded components, thereby achieving end-to-end
coverage of all execution paths.
ACKNOWLEDGEMENTS
This research is supported by the Commonwealth Cyber
Initiative (CCI)’s Coastal Virginia Node and Northern Virginia
Node (Grant ID: 765711). The authors also thank the Google
Android Security Team for providing valuable feedback on
this work.

REFERENCES
[1] Statista, “Annual number of mobile app downloads worldwide
from 2016 to 2023,” Tech. Rep., Jan 2025. [Online]. Available:
https://www.statista.com/statistics/271644/worldwide-free-and-paid-m
obile-app-store-downloads/
[2] A. Kivva, “It threat evolution in q3 2024. mobile statistics,” Securelist
by Kaspersky, Tech. Rep., Nov 2024. [Online]. Available: https:
//securelist.com/malware-report-q3-2024-mobile-statistics/114692/
[3] Zimperium, “2024 global mobile threat report,” Tech. Rep., 2025.
[Online]. Available: https://www.zimperium.com/resources/2024-globa
l-mobile-threat-report/
[4] H. Zhang, S. Luo, Y . Zhang, and L. Pan, “An efficient android malware
detection system based on method-level behavioral semantic analysis,”
IEEE Access, vol. 7, pp. 69 246–69 256, 2019.
[5] T. Lei, Z. Qin, Z. Wang, Q. Li, and D. Ye, “Evedroid: Event-aware
android malware detection against model degrading for iot devices,”
IEEE Internet of Things Journal, vol. 6, no. 4, pp. 6668–6680, 2019.
[6] M. Alazab, M. Alazab, A. Shalaginov, A. Mesleh, and A. Awajan,
“Intelligent mobile malware detection using permission requests and
api calls,”Future Generation Computer Systems, vol. 107, pp. 509–521,
2020.
[7] S. Chen, B. Lang, H. Liu, Y . Chen, and Y . Song, “Android malware
detection method based on graph attention networks and deep fusion
of multimodal features,”Expert Systems with Applications, vol. 237, p.
121617, 2024.
[8] P. Feng, J. Ma, C. Sun, X. Xu, and Y . Ma, “A novel dynamic android
malware detection system with ensemble learning,”IEEE Access, vol. 6,
pp. 30 996–31 011, 2018.
[9] J. G. de la Puerta, I. Pastor-L ´opez, I. Porto, B. Sanz, and P. G. Bringas,
“Detecting malicious android applications based on the network packets
generated,”Neurocomputing, vol. 456, pp. 629–636, 2021.
[10] R. Surendran, T. Thomas, and S. Emmanuel, “Gsdroid: Graph signal
based compact feature representation for android malware detection,”
Expert Systems with Applications, vol. 159, p. 113581, 2020.
[11] W. Han, J. Xue, Y . Wang, L. Huang, Z. Kong, and L. Mao, “Maldae:
Detecting and explaining malware based on correlation and fusion of
static and dynamic characteristics,”computers & security, vol. 83, pp.
208–233, 2019.
[12] H. Wang, W. Zhang, and H. He, “You are what the permissions told
me! android malware detection based on hybrid tactics,”Journal of
Information Security and Applications, vol. 66, p. 103159, 2022.
[13] F. Taher, O. AlFandi, M. Al-kfairy, H. Al Hamadi, and S. Alrabaee,
“Droiddetectmw: a hybrid intelligent model for android malware detec-
tion,”Applied Sciences, vol. 13, no. 13, p. 7720, 2023.
[14] Y . Wu, J. Shi, P. Wang, D. Zeng, and C. Sun, “Deepcatra: Learning
flow-and graph-based behaviours for android malware detection,”IET
Information Security, vol. 17, no. 1, pp. 118–130, 2023.
[15] J. Feng, L. Shen, Z. Chen, Y . Lei, and H. Li, “Hgdetector: A hybrid
android malware detection method using network traffic and function
call graph,”Alexandria Engineering Journal, vol. 114, pp. 30–45, 2025.
[16] J. Samhi, R. Just, T. F. Bissyand ´e, M. D. Ernst, and J. Klein, “Call graph
soundness in android static analysis,” inProceedings of the 33rd ACM
SIGSOFT International Symposium on Software Testing and Analysis,
2024, pp. 945–957.
[17] A. M. Memon and A. Anwar, “Colluding apps: Tomorrow’s mobile
malware threat,”IEEE Security & Privacy, vol. 13, no. 6, pp. 77–81,
2015.
[18] Y . Pan, X. Ge, C. Fang, and Y . Fan, “A systematic literature review of
android malware detection using static analysis,”Ieee Access, vol. 8, pp.
116 363–116 379, 2020.
[19] M. Amin, T. A. Tanveer, M. Tehseen, M. Khan, F. A. Khan, and
S. Anwar, “Static malware detection and attribution in android byte-
code through an end-to-end deep system,”Future generation computer
systems, vol. 102, pp. 112–126, 2020.
[20] O. Or-Meir, N. Nissim, Y . Elovici, and L. Rokach, “Dynamic malware
analysis in the modern era—a state of the art survey,”ACM Computing
Surveys (CSUR), vol. 52, no. 5, pp. 1–48, 2019.
[21] C. Li, Q. Lv, N. Li, Y . Wang, D. Sun, and Y . Qiao, “A novel deep
framework for dynamic malware detection based on api sequence
intrinsic features,”Computers & Security, vol. 116, p. 102686, 2022.
[22] Y . Ye, T. Li, D. Adjeroh, and S. S. Iyengar, “A survey on malware
detection using data mining techniques,”ACM Computing Surveys
(CSUR), vol. 50, no. 3, pp. 1–40, 2017.[23] H. Darabian, S. Homayounoot, A. Dehghantanha, S. Hashemi, H. Karim-
ipour, R. M. Parizi, and K.-K. R. Choo, “Detecting cryptomining
malware: a deep learning approach for static and dynamic analysis,”
Journal of Grid Computing, vol. 18, pp. 293–303, 2020.
[24] S. Baek, J. Jeon, B. Jeong, and Y .-S. Jeong, “Two-stage hybrid malware
detection using deep learning,”Human-centric Computing and Informa-
tion Sciences, vol. 11, no. 27, pp. 10–22 967, 2021.
[25] OpenAI, “Introducing chatgpt,” Tech. Rep., 2022. [Online]. Available:
https://openai.com/index/chatgpt/
[26] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,
T. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azharet al.,
“Llama: Open and efficient foundation language models,”arXiv preprint
arXiv:2302.13971, 2023.
[27] J. Wei, Y . Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud,
D. Yogatama, M. Bosma, D. Zhou, D. Metzleret al., “Emergent abilities
of large language models,”arXiv preprint arXiv:2206.07682, 2022.
[28] P. Kaur, G. S. Kashyap, A. Kumar, M. T. Nafis, S. Kumar, and
V . Shokeen, “From text to transformation: A comprehensive review of
large language models’ versatility,”arXiv preprint arXiv:2402.16142,
2024.
[29] W. Zhao, J. Wu, and Z. Meng, “Apppoet: Large language model based
android malware detection via multi-view prompt engineering,”Expert
Systems with Applications, vol. 262, p. 125546, 2025.
[30] X. Qian, X. Zheng, Y . He, S. Yang, and L. Cavallaro, “Lamd: Context-
driven android malware detection and classification with llms,”arXiv
preprint arXiv:2502.13055, 2025.
[31] Y . Li, S. Fang, T. Zhang, and H. Cai, “Enhancing android malware
detection: The influence of chatgpt on decision-centric task,”arXiv
preprint arXiv:2410.04352, 2024.
[32] D. R. Arikkat, S. Nicolazzo, A. Noceraet al., “Enhancing android
malware detection with retrieval-augmented generation,”arXiv preprint
arXiv:2506.22750, 2025.
[33] B. J. Walton, M. E. Khatun, J. M. Ghawaly, and A. Ali-Gombe, “Ex-
ploring large language models for semantic analysis and categorization
of android malware,” in2024 Annual Computer Security Applications
Conference Workshops (ACSAC Workshops). IEEE, 2024, pp. 248–254.
[34] C. Patsakis, F. Casino, and N. Lykousas, “Assessing llms in malicious
code deobfuscation of real-world malware campaigns,”Expert Systems
with Applications, vol. 256, p. 124912, 2024.
[35] Y . Zhang, Y . Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,
Y . Zhang, Y . Chenet al., “Siren’s song in the ai ocean: a survey on hal-
lucination in large language models,”arXiv preprint arXiv:2309.01219,
2023.
[36] K. Allix, T. F. Bissyand ´e, J. Klein, and Y . Le Traon, “Androzoo:
Collecting millions of android apps for the research community,” in
Proceedings of the 13th international conference on mining software
repositories, 2016, pp. 468–471.
[37] C. Fang, N. Miao, S. Srivastav, J. Liu, R. Zhang, R. Fang, R. Tsang,
N. Nazari, H. Wang, H. Homayounet al., “Large language models for
code analysis: Do{llms}really do their job?” in33rd USENIX Security
Symposium (USENIX Security 24), 2024, pp. 829–846.
[38] D. Nam, A. Macvean, V . Hellendoorn, B. Vasilescu, and B. Myers,
“Using an llm to help with code understanding,” inProceedings of
the IEEE/ACM 46th International Conference on Software Engineering,
2024, pp. 1–13.
[39] H. Tan, Q. Luo, J. Li, and Y . Zhang, “Llm4decompile: Decom-
piling binary code with large language models,”arXiv preprint
arXiv:2403.05286, 2024.
[40] H. Rong, Y . Duan, H. Zhang, X. Wang, H. Chen, S. Duan, and
S. Wang, “Disassembling obfuscated executables with llm,”arXiv
preprint arXiv:2407.08924, 2024.
[41] T. Ahmed, K. S. Pai, P. Devanbu, and E. Barr, “Automatic semantic
augmentation of language model prompts (for code summarization),” in
Proceedings of the IEEE/ACM 46th international conference on software
engineering, 2024, pp. 1–13.
[42] T. Ahmed and P. Devanbu, “Few-shot training llms for project-specific
code-summarization,” inProceedings of the 37th IEEE/ACM interna-
tional conference on automated software engineering, 2022, pp. 1–5.
[43] H. Lu, H. Peng, G. Nan, J. Cui, C. Wang, W. Jin, S. Wang, S. Pan,
and X. Tao, “Malsight: Exploring malicious source code and benign
pseudocode for iterative binary malware summarization,”arXiv preprint
arXiv:2406.18379, 2024.

[44] J. Al-Karaki, M. A.-Z. Khan, and M. Omar, “Exploring llms for malware
detection: Review, framework design, and countermeasure approaches,”
arXiv preprint arXiv:2409.07587, 2024.
[45] H. Jelodar, S. Bai, P. Hamedi, H. Mohammadian, R. Razavi-Far,
and A. Ghorbani, “Large language model (llm) for software security:
Code analysis, malware analysis, reverse engineering,”arXiv preprint
arXiv:2504.07137, 2025.
[46] A. Rahali and M. A. Akhloufi, “Malbert: Malware detection using
bidirectional encoder representations from transformers,” in2021 IEEE
international conference on systems, man, and cybernetics (SMC).
IEEE, 2021, pp. 3226–3231.
[47] Y . Wang, M. Fan, X. Zhang, J. Shi, Z. Qiu, H. Wang, and T. Liu,
“Liredroid: Llm-enhanced test case generation for static sensitive be-
havior replication,” inProceedings of the 15th Asia-Pacific Symposium
on Internetware, 2024, pp. 81–84.
[48] T. Koide, H. Nakano, and D. Chiba, “Chatphishdetector: Detecting
phishing sites using large language models,”IEEE Access, 2024.
[49] D. Devadiga, G. Jin, B. Potdar, H. Koo, A. Han, A. Shringi, A. Singh,
K. Chaudhari, and S. Kumar, “Gleam: Gan and llm for evasive adver-
sarial malware,” in2023 14th International Conference on Information
and Communication Technology Convergence (ICTC). IEEE, 2023, pp.
53–58.
[50] X. Li, T. Zhu, and W. Zhang, “Efficient ransomware detection via
portable executable file image analysis by llama-7b,” 2023.
[51] H. Wang, N. Luo, and P. LIu, “Unmasking the shadows: Pinpoint the
implementations of anti-dynamic analysis techniques in malware using
llm,”arXiv preprint arXiv:2411.05982, 2024.
[52] C. Zhou, Y . Liu, W. Meng, S. Tao, W. Tian, F. Yao, X. Li, T. Han,
B. Chen, and H. Yang, “Srdc: Semantics-based ransomware detection
and classification with llm-assisted pre-training,” inProceedings of the
AAAI Conference on Artificial Intelligence, vol. 39, no. 27, 2025, pp.
28 566–28 574.
[53] A. A. Hossain, M. K. PK, J. Zhang, and F. Amsaad, “Malicious code
detection using llm,” inNAECON 2024-IEEE National Aerospace and
Electronics Conference. IEEE, 2024, pp. 414–416.
[54] A. Shestov, R. Levichev, R. Mussabayev, E. Maslov, P. Zadorozhny,
A. Cheshkov, R. Mussabayev, A. Toleu, G. Tolegen, and A. Krasso-
vitskiy, “Finetuning large language models for vulnerability detection,”
IEEE Access, 2025.
[55] Z. Yu, M. Wen, X. Guo, and H. Jin, “Maltracker: A fine-grained npm
malware tracker copiloted by llm-enhanced dataset,” inProceedings of
the 33rd ACM SIGSOFT International Symposium on Software Testing
and Analysis, 2024, pp. 1759–1771.
[56] Y . Huang, R. Wang, W. Zheng, Z. Zhou, S. Wu, S. Ke, B. Chen, S. Gao,
and X. Peng, “Spiderscan: Practical detection of malicious npm packages
based on graph-based behavior modeling and matching,” inProceedings
of the 39th IEEE/ACM International Conference on Automated Software
Engineering, 2024, pp. 1146–1158.
[57] P. Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,
H. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschelet al., “Retrieval-
augmented generation for knowledge-intensive nlp tasks,”Advances in
neural information processing systems, vol. 33, pp. 9459–9474, 2020.
[58] OpenAI, “Openai o3-mini,” Tech. Rep., 2025. [Online]. Available:
https://openai.com/index/openai-o3-mini/
[59] ——, “New and improved embedding model,” Tech. Rep., 2022.
[Online]. Available: https://openai.com/index/new-and-improved-emb
edding-model/