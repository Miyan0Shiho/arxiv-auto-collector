# Unmasking Hiring Bias: Platform Data Analysis and Controlled Experiments on Bias in Online Freelance Marketplaces via RAG-LLM Generated Contents

**Authors**: Wugeng Zheng, Guohou Shan

**Published**: 2025-10-15 02:17:19

**PDF URL**: [http://arxiv.org/pdf/2510.13091v2](http://arxiv.org/pdf/2510.13091v2)

## Abstract
Online freelance marketplaces, a rapidly growing part of the global labor
market, are creating a fair environment where professional skills are the main
factor for hiring. While these platforms can reduce bias from traditional
hiring, the personal information in user profiles raises concerns about ongoing
discrimination. Past studies on this topic have mostly used existing data,
which makes it hard to control for other factors and clearly see the effect of
things like gender or race. To solve these problems, this paper presents a new
method that uses Retrieval-Augmented Generation (RAG) with a Large Language
Model (LLM) to create realistic, artificial freelancer profiles for controlled
experiments. This approach effectively separates individual factors, enabling a
clearer statistical analysis of how different variables influence the
freelancer project process. In addition to analyzing extracted data with
traditional statistical methods for post-project stage analysis, our research
utilizes a dataset with highly controlled variables, generated by an RAG-LLM,
to conduct a simulated hiring experiment for pre-project stage analysis. The
results of our experiments show that, regarding gender, while no significant
preference emerged in initial hiring decisions, female freelancers are
substantially more likely to receive imperfect ratings post-project stage.
Regarding regional bias, a strong and consistent preference favoring US-based
freelancers shows that people are more likely to be selected in the simulated
experiments, perceived as more leader-like, and receive higher ratings on the
live platform.

## Full Text


<!-- PDF content starts -->

Unmasking Hiring Bias: Platform Data Analysis and Controlled
Experiments on Bias in Online Freelance Marketplaces via
RAG-LLM Generated Contents
Wugeng Zheng
zheng.wug@northeastern.edu
Northeastern University
Boston, Massachusetts, USAGuohou Shan
g.shan@northeastern.edu
Northeastern University
Boston, Massachusetts, USA
Abstract
Online freelance marketplaces, a rapidly growing part of the global
labor market, are creating a fair environment where professional
skills are the main factor for hiring. While these platforms can re-
duce bias from traditional hiring, the personal information in user
profiles raises concerns about ongoing discrimination. Past studies
on this topic have mostly used existing data, which makes it hard
to control for other factors and clearly see the effect of things like
gender or race. To solve these problems, this paper presents a new
method that uses Retrieval-Augmented Generation (RAG) with a
Large Language Model (LLM) to create realistic, artificial freelancer
profiles for controlled experiments. This approach effectively sepa-
rates individual factors, enabling a clearer statistical analysis of how
different variables influence the freelancer project process. In addi-
tion to analyzing extracted data with traditional statistical methods
for post-project stage analysis, our research utilizes a dataset with
highly controlled variables, generated by an RAG-LLM, to conduct
a simulated hiring experiment for pre-project stage analysis. The
results of our experiments show that, regarding gender, while no
significant preference emerged in initial hiring decisions, female
freelancers are substantially more likely to receive imperfect ratings
post-project stage. Regarding regional bias, a strong and consistent
preference favoring US-based freelancers shows that people are
more likely to be selected in the simulated experiments, perceived
as more leader-like, and receive higher ratings on the live platform.
Keywords
Large language models, human-AI interaction, retrieval-augmented
generation, generative models, user experiments, controlled experi-
ments, synthetic data generation, demographic bias, human-in-the-
loop evaluation
ACM Reference Format:
Wugeng Zheng and Guohou Shan. 2026. Unmasking Hiring Bias: Platform
Data Analysis and Controlled Experiments on Bias in Online Freelance
Marketplaces via RAG-LLM Generated Contents. InProceedings of March
23â€“26, 2026 (ACM Conference on Intelligent User Interfaces â€™2026).ACM, New
York, NY, USA, 8 pages. https://doi.org/XXXXXXX.XXXXXXX
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
ACM Conference on Intelligent User Interfaces â€™2026,
Â©2025 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-x-xxxx-xxxx-x/YYYY/MM
https://doi.org/XXXXXXX.XXXXXXX
Figure 1: Workflow
1 Introduction
Online freelance marketplaces are increasingly becoming a vital
component of the global labor market after the COVID-19 crisis [ 1].
In Europe and the United States, 20 to 30 percent of the working-age
population engage in some form of independent work [ 2]. These
platforms provide workers with flexibility to choose projects that fit
their skills while giving employers access to a diverse talent [ 3][4].
In theory, this task-oriented model should boost a more equally
competitive environment, where professional capabilities, rather
than personal background, serve as the core criterion for evaluation
[5].
However, while online platforms can mitigate the direct dis-
crimination present in traditional face-to-face recruitment [ 6][7], it
remains unclear whether they have truly achieved the goal of elim-
inating bias. User profiles on these platforms contain personally
identifiable information, leading to both unconscious and conscious
biases during candidate evaluations [ 8]. While prior studies have
confirmed the presence of gender and racial bias on online freelance
platforms using statistical regression [ 9][10], their methodologies
face critical limitations: Analyzing observational data extracted
from sources like freelancer profiles and ratings makes it difficult
to control for confounding factors, thus hindering the precision of
the findings. The conventional solution, collecting massive datasets
to statistically account for these variables poses significant data
acquisition challenges.
To more rigorously examine the bias on freelancer platforms, a
new experimental methodology designed for strict variable control
is proposed. A new method that employing Retrieval-Augmented
Generation (RAG) to prompt a Large Language Model (LLM) to
generate highly relevant experimental data, including freelancer
profiles. By inviting participants to participate in the controlled ex-
periments, we can thoroughly examine the biases on the freelancer
platforms. Figure 1 shows the workflow of our method. The key
methodological contributions of this research are:arXiv:2510.13091v2  [cs.HC]  16 Oct 2025

ACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
Zheng et al.
(1)Controlled Experiments via Synthetic Data:The usage
of RAG-LLM generating synthetic data for controlled exper-
iments allows the precise isolation of variables, overcoming
the challenge of confounding factors present in traditional
observational data.
(2)Multi-Stage Bias Analysis:The multi-stage analysis of bias
by examining both the initial hiring phase through a user
study and the post-project evaluation phase using real-world
data provides a more complete view than studies limited to
post-project data, revealing how different biases manifest at
different stages of the engagement process.
2 Related Work
2.1 Discrimination in Online Marketplaces
With the development of internet technology and the evolution of
work models, the global economy has exhibited the rapid rise of
the "gig economy"[ 11]. This new economic model, characterized by
its flexibility and decentralization, has reshaped the organizational
forms of the traditional workforce. Online freelance marketplaces,
such as Upwork, Fiverr, and Freelancer.com, are central platforms
of the gig economy. By connecting clients and freelancers on a
global scale, these platforms break down geographical barriers and
provide unprecedented opportunities for both parties [ 12][13][14].
This mechanism enhances matching efficiency through information
transparency and market competition [ 15]. In theory, it should allow
skills to be the decisive factor, thereby reducing the potential for
biases that may exist in traditional hiring processes [16].
However, the existing studies have found that discrimination con-
tinues to be a significant challenge. Profiles on these platforms often
contain personally identifiable information, such as names and pho-
tographs, which creates opportunities for both explicit and implicit
bias. Hannak [ 9] found that on platforms like TaskRabbit and Fiverr,
workers perceived as Black received significantly lower ratings than
their peers from other ethnic groups, while female workers received
a comparatively lower number of reviews. Edelman [ 17] argued
that even on sharing economy platforms with relative information
transparency, such as Airbnb, consumer discrimination persists. In
the absence of credible, low-cost information on individual quality,
consumers may tend to group characteristics like race as a proxy,
resulting in statistical discrimination against minorities. A field ex-
periment conducted by Chan [ 18] in an online labor market found
that hiring preferences can sometimes favor female applicants, with
employers in certain contexts showing a greater inclination to hire
women.
2.2 Machine Learning and Large Language
Models
Traditionally, methods for studying online discrimination have pri-
marily relied on data scraping and econometric analysis, like works
of Hannak [ 9] and Chan [ 18]. However, such approaches have an
inherent limitation: The complexity of real-world data makes it
challenging for researchers to control for all potential confound-
ing variables. For instance, a candidateâ€™s individual qualifications,
such as skills and experience, are often intertwined with their de-
mographic identity (e.g., race or gender), complicating efforts to
precisely identify the true source of bias.The complexity of real-world data makes it challenging for re-
searchers to control for all potential correlation variables. For in-
stance, a candidateâ€™s individual qualifications, such as skills and
experience, are often intertwined with their demographic identity
(e.g., race or gender), complicating efforts to precisely identify the
true source of bias. Some studies, like Liu et al. [ 19] used individual
screening preferences modeling by providing a synthetic profile
methodology to process controlled experiments, to identify and
mitigate biases
Recently, generative artificial intelligence, particularly Large Lan-
guage Models (LLMs) has been used to understand the user activity
on digital platforms such as the Stack Overflow (e.g., [ 20][21][22]),
online reviews (e.g., [ 23][24][25]). It has also been used to under-
stand usersâ€™ online search (e.g., [ 26]) and coding behavior ([ 27]). It
offers a novel methodological approach to overcoming traditional
research challenges in this area. LLMs like GPT, Gemini, and Claude
can generate highly realistic and contextually relevant text. This
capability allows for the creation of synthetic virtual survey data
under tightly controlled conditions. By systematically manipulating
specific variables of interest while holding all others constant, we
can conduct comparative experiments that effectively isolate causal
effects from the influence of confounding variables often present
in observational data [28].
However, standard LLMs may suffer from factual errors like
hallucinations or an inability to process professional information.
To overcome these limitations, Retrieval-Augmented Generation
(RAG) technology was developed. The RAG workflow typically
involves three core steps:
(1)Retrieve:Upon receiving a prompt, the system does not
immediately send it to the LLM. Instead, it uses keywords
from the query to search a vast external knowledge base for
the most relevant information segments.
(2)Augment:The system then combines these retrieved infor-
mation segments with the original query to form an aug-
mented prompt, which is richer in content and more contex-
tually specific.
(3)Generate:Finally, this augmented prompt is sent to the
LLM. The LLM leverages this additional, reliable context
to generate an answer that is more accurate and factually
grounded.
Through this mechanism, RAG not only enhances the accuracy
and relevance of the generated content but also allows us to "an-
chor" the modelâ€™s knowledge to specific, credible data sources. In
our research, we can leverage an RAG-LLM framework to create
highly realistic and variably controlled experimental materials. For
example, based on specific professional skill requirements, we can
generate a series of virtual candidate backgrounds that are iden-
tical in skills and experience, differing only in the name or other
variables to reflect different races or genders.
For the user study, a controlled experimental environment is
created using a simulated hiring website, where real recruiters are
invited to evaluate a set of constructed freelancer profiles. In these
strictly controlled environments, we can precisely measure and
isolate the independent impact of specific variables on hiring deci-
sions. This allows for a deeper understanding of the mechanisms
behind bias in online markets. This research paradigm, based on

Unmasking Hiring BiasACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
Figure 2: Overall Workflow
user study, holds the promise of overcoming the limitations of tra-
ditional methods and opening new avenues for the study of online
discrimination.
3 Methodology
3.1 Overall Framework
In this study, a controlled experiment is employed. Data are obtained
through a user study with highly controlled variables.
The overall process is shown in Figure 2. First, user information
is collected from freelancer.com. This information is then processed
to build a knowledge base for a Large Language Model (LLM). Sub-
sequently, customized freelancer profiles are generated by the LLM
using Retrieval-Augmented Generation (RAG). These profiles are de-
signed to be nearly identical, differing only in the specific variables
being investigated. Finally, a webpage is created for the experiment,
and participants are recruited through Amazon Mechanical Turk
(MTurk) to collect the data.
3.2 Data Acquisition and Processing
Scripts are used to collect data from Freelancer.com, a global crowd-
sourcing marketplace where potential employers post jobs for
which freelancers can then bid. This dataset includes project re-
views and ratings. The collected profile attributes include details
such as Username, User ID, Verification Badges, Overall Rating, and
Profile Taglines.
The raw scraped data requires significant preprocessing due to
unstructured and inconsistent formatting. A primary challenge is
the absence of explicit gender labels on Freelancer.com. To address
this, a gender classification model is deployed, which predomi-
nantly features self-portraits. Specifically, this pre-trained facial
recognition model from Huggingface is employed to analyze these
freelancersâ€™ avatars, classifying each as "male" or "female" and gen-
erating a corresponding gender_confidence score. To ensure the reli-
ability of the dataset for subsequent analysis, a confidence threshold
of 0.75 is applied, and only profiles exceeding this score are included
in the final study. For the demographic component, the availability
of country data allows for an interaction analysis between geogra-
phy and gender. This analysis is specifically focused on freelancers
from India and the United States, the two most represented nations
in the dataset.3.3 RAG and LLM
To generate realistic and contextually relevant freelancer profiles,
a Retrieval-Augmented Generation (RAG) pipeline is utilized. The
knowledge base for this pipeline is created by vectorizing the pro-
cessed data with an embedding model from Huggingface. This
process embeds the data into a vector space where profiles with
similar semantic content are located closer to one another, enabling
effective content retrieval.
The core of the content generation model is the Qwen/QwQ-
32B Large Language Model (LLM). This model is selected for its
advanced text generation capabilities and its proven ability to pro-
duce high-quality, consistent output. It is recognized as a powerful
open-source solution for this task.
With processed data and a prepared model, virtual information
for the experiment is synthetically generated through a multi-stage
process to ensure experimental control and anonymity.
The profile generation process begins by processing and vectoriz-
ing the collected data to serve as a knowledge base. This knowledge
base is then used within a Retrieval-Augmented Generation (RAG)
pipeline, which grounds the Large Language Model (LLM) in fac-
tual information. In the first step, the most similar profiles from the
knowledge base are retrieved. These retrieved documents are then
added to the LLMâ€™s context as relevant examples. This augmented
prompt ensures the final generated profile is not only coherent
but also contextually aligned with real-world data. After genera-
tion, each profile is manually reviewed and edited to ensure it is
high-quality and appropriate for the experiment.
To complete the profiles, names are also synthetically generated
using public demographic data. Indian names are sourced from
Forebears [ 29][30], while American names are created using data
from the U.S. Social Security Administration and the Census Bureau
[31][32].
3.4 Website Platform
With Flask module, interactive webpages for participants on the
platform are built and structured into distinct tasks to facilitate
precise behavioral data collection.
(1)Task Selection:Users begin on a main page, which displays
their overall progress and presents two independent exper-
imental tasks: the "Freelancer Comparison Task" and the
"Review Comparison Task".
(2)Comparison and Voting:In the Freelancer Comparison
Task, the platform displays two freelancer profiles side-by-
side and asks the user to vote for the one they would prefer to
hire. In the Review Comparison Task, participants are shown
relevant review information and are required to answer a
series of questions.
(3)Task Completion and Survey:After completing a prede-
termined number of comparison tasks, users are directed to
a completion page. They are then redirected to a final survey
to collect demographic information and subjective feedback
related to their experience. Attention check questions are
added to the survey. If users fail to pass the attention check
by choosing the wrong answer of common sense, we exclude
the previous selection of this user.

ACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
Zheng et al.
3.5 Recruit Participants
Participants are recruited for the study through the MTurk crowd-
sourcing platform and directed to our designed experimental web-
site. As tasks are completed, the selections and interaction data
from each participant are logged. Following the main tasks, a sur-
vey containing several attention check questions is administered.
To ensure data integrity, any submissions from participants who
fail these checks are filtered out and removed.
3.6 Statistical Analysis
The results from the LLM-based user study enable an analysis of the
pre-project freelancer selection process. This approach is a notable
departure from previous studies, which have been largely confined
to analyzing post-project outcomes. With the experiment data, the
same analytical methods can be applied to both pre-project and
post-project scenarios.
For the statistical analysis, several methods are employed. Star
rating data are first binarized into two categories (5-star vs. non-5-
star), and a logistic regression model is applied. Logistic regression
is also used to analyze count-based outcomes, such as the likelihood
of a freelancer being selected. These regression models are specified
to include the effects of country and gender, and are analyzed both
with and without interaction terms between these variables. Finally,
a chi-square test is used to examine the independence between
categorical variables.
4 Results
4.1 Methodological Efficiency and Control
Previous studies are based on traditional observational data and
face a critical limitation: the inherent difficulty of controlling for
confounding variables. In online marketplace platforms, freelancersâ€™
profiles, such as their skills, educational background, and project
experience, are typically intertwined with their demographic at-
tributes (e.g., gender, country of origin, or ethnicity). Manually
writing each profile is not a feasible alternative. This approach
would be time-consuming, with an estimated 10-15 minutes re-
quired for each profile. More importantly, it would be extremely
difficult to ensure that for every pair of profiles being compared, all
attributes are kept highly consistent except for the specific variable
under investigation. By contrast, the RAG-LLM framework could
address this issue by facilitating precise control and isolation of ex-
perimental variables. Rather than analyzing observational data with
massive noise, our methodology involves the proactive generation
of highly controlled synthetic content for experimentation.
Figure 3 shows a screenshot of the web displaying a pair of
freelancer profiles for comparison. This particular pair is gener-
ated to be nearly identical in qualifications, with the same rating,
project completion rate, hourly rate, and tagline. The purpose of
this setup is to test for selection bias based on freelancersâ€™ demo-
graphics, which are signaled through regionally distinct names.
The profile descriptions, while not identical, were generated to be
closely matched in length and substance. This strategy prevents
the experimental setup from appearing unrealistic while ensuring
that the content of the descriptions does not become a confounding
variable in the participantâ€™s decision-making process.
Figure 3: An Example Pair of Freelancersâ€™ Profiles
Figure 4: Data Overview from Freelancer.com
4.2 Insights with User Study
The dataset is collected from the Freelancer website and contains
12,799 freelancer profiles, containing variables such as overall rat-
ing, review count, country, and AI-inferred gender.
Figure 4 provides a visual summary of key distributions within
the data. The datasetâ€™s composition is further illustrated by compar-
ing the counts of freelancers from our primary countries of interest,
the United States and India, and by examining the overall gender
distribution. These patterns, particularly the right-skewed distri-
bution of review counts, are consistent with activity data typically
found on online marketplaces and social platforms about demo-
graphic distribution [ 33][34][35]. This analysis sets the stage for
the more rigorous statistical modeling used to investigate biases in
selection and ratings.
4.2.1 Hiring Decisions.A total of 1,980 freelancer profile pairs
are generated from the collected dataset to be used in the user
study. The data on the display frequency of these pairs and the
corresponding selections made by participants are summarized in
Table 1.

Unmasking Hiring BiasACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
Table 1: Pairwise Competition and Win Counts Between De-
mographic Groups
(a) Total Pairwise Competitions
Group 1Group 2 Indian
FemaleIndian
MaleUS
FemaleUS
Male
Indian Femaleâ€” 521 499 0
Indian Male521 â€” 0 488
US Female499 0 â€” 472
US Male0 488 472 â€”
Total1020 1009 971 960
(b) Number of Wins by Group
WinnerOpponent Indian
FemaleIndian
MaleUS
FemaleUS
Male
Indian Femaleâ€” 272 223 0
Indian Male249 â€” 0 189
US Female276 0 â€” 245
US Male0 299 227 â€”
Note:Each cell represents the number of times the group in the row won a direct
competition against the group in the column.
Table 2a and Table 2b are the results for different demographic
groups. There is a strong significant preference for US-based free-
lancers over their Indian counterparts (p<0.05). While the raw data
suggests a slight preference for female freelancers, this tendency
is not statistically significant (p>0.3). These results are reflected
in the overall winning odds in Table 2b, where both US groups
demonstrate a significant likelihood of winning, while the Indian
Male group is significantly more likely to lose.
Table 2: Freelancer Competition Analysis by Demographic
Groups
(a) Winning Probabilities in Competitions
Win Lose Odds 95% CI P-value
Indian Male US Male0.633 [0.527, 0.759]<0.001âˆ—âˆ—âˆ—
Indian Female US Female0.808 [0.678, 0.964] 0.020âˆ—
Indian Female Indian Male1.092 [0.920, 1.297] 0.335
US Female US Male1.079 [0.901, 1.292] 0.434
(b) Winning Odds Analysis by Demographic Group
Group Odds of Winning 95% CI P-value
Indian Male0.767 [0.678, 0.869]<0.001âˆ—âˆ—âˆ—
Indian Female0.943 [0.835, 1.066] 0.364
US Male1.212 [1.066, 1.375] 0.003âˆ—âˆ—
US Female1.158 [1.020, 1.315] 0.025âˆ—
Note:The P-value tests the null hypothesis that the odds ratio is 1 (a 50/50
probability).
Significance levels: *ð‘<0.05; **ð‘<0.01; ***ð‘<0.001
4.2.2 Leader Decisions.Parallel to the hiring preference analysis,
biases in the perception of leadership qualities among freelancers
are shown. This analysis, based on 828 pairwise comparisons whereparticipants selected the more "leader-like" candidate, also reveals a
significant demographic bias. The results of these competitions are
summarized in Table 3, showing the total number of comparisons
between each demographic pair and counts of how many times
each group is selected as the leader.
Table 3: Pairwise Competitions and Selections for Leadership
Perception
(a) Total Pairwise Competitions
Group 1Group 2 Indian
FemaleIndian
MaleUS White
FemaleUS White
Male
Indian Femaleâ€” 308 315 0
Indian Male308 â€” 0 348
US White Female315 0 â€” 349
US White Male0 348 349 â€”
(b) Number of Times Selected as Leader
WinnerOpponent Indian
FemaleIndian
MaleUS White
FemaleUS White
Male
Indian Femaleâ€” 92 76 0
Indian Male68 â€” 0 74
US White Female147 0 â€” 126
US White Male0 149 96 â€”
Note:Each cell represents the number of times the group in the row was chosen as
the leader.
Table 4 shows our findings on demographic bias from two angles.
Part (a) details the results from direct, head-to-head comparisons,
revealing a strong preference for US candidates over Indian candi-
dates. Part (b) then summarizes the overall performance of each
group, confirming that US candidates were chosen far more often
(Odds > 1), while Indian candidates were chosen less often (Odds <
1). This shows how the biases in individual matchups lead to the
overall group outcomes.
Table 4: Logistic Regression Analysis of Leadership Selection
(a) Winning Odds Ratios in Leadership (Pairwise)
Win Group Lose Group Odds 95% CI P-value
US Male Indian Male2.014 [1.524, 2.661]<0.001***
US Female Indian Female1.934 [1.466, 2.551]<0.001***
US Female US Male1.312 [1.006, 1.712] 0.051
Indian Female Indian Male1.353 [0.989, 1.851] 0.069
Note:The P-value tests the null hypothesis that the odds ratio is 1.
Significance levels: ***ð‘<0.001
(b) Winning Odds in Leadership Selection (Overall)
Group Odds of Winning 95% CI P-value
US White Female1.587 [1.312, 1.921]<0.001***
US White Male1.225 [1.016, 1.477] 0.037*
Indian Female0.781 [0.639, 0.956] 0.019*
Indian Male0.589 [0.479, 0.725]<0.001***
Note:The P-value tests the null hypothesis that the odds ratio is 1.
Significance levels: *ð‘<0.05; ***ð‘<0.001

ACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
Zheng et al.
4.3 Insights with Observational Data
To complement what we found from the user study, we also adopt
traditional methods with scrapping data and analyzing biases in
the post-project phase.
4.3.1 Review Count.To analyze the number of reviews received
by freelancers, negative binomial regression models are employed
to account for the count-based nature of the data. The results of the
analysis are presented in Table 5. Without an interaction term, it is
shown that freelancers from the United States receive significantly
fewer reviews than those from India (IRR = 0.436), while female
freelancers receive slightly more reviews than males (IRR = 1.191).
For further investigation, an interaction is included, as detailed in
Table 5b. A significant interaction effect is found (p = 0.031), which
reveals that the influence of gender on review counts depends on
the freelancerâ€™s country. Specifically, while female freelancers in
the Indian group receive about 24% more reviews than their male
counterparts (IRR = 1.237), female freelancers in the U.S. group
receive approximately 22% fewer reviews compared to U.S. males.
This finding confirms that the effect of perceived gender on this
outcome differs significantly between the two countries.
Table 5: Results for Review Counts
(a) Model without Interaction Term
Variable Coeff. IRR 95% CI p-value
Intercept4.737 114.07 [107.9, 120.6]<0.001***
Female0.175 1.191 [1.055, 1.345] 0.005**
US-0.831 0.436 [0.361, 0.526]<0.001***
Notes:
IRR = Incidence Rate Ratio
Ref. categories: Male; India
**ð‘<0.01; ***ð‘<0.001
(b) Model with Interaction Term
Variable Coeff. IRR 95% CI p-value
Intercept4.729 113.22 [107.1, 119.7]<0.001***
Female0.213 1.237 [1.089, 1.406] 0.001***
US-0.719 0.487 [0.390, 0.608]<0.001***
FemaleÃ—US-0.463 0.629 [0.413, 0.960] 0.031*
Notes:
Ref. categories: Male; India
*ð‘<0.05; ***ð‘<0.001
4.3.2 Ratings.The rating data are observed to be highly left-skewed
because of the high frequency of 5-star reviews. Therefore, for the
logistic regression analysis, the ratings are converted into a binary
variable: â€™1â€™ for receiving a non-5-star rating, and â€™0â€™ for receiving
only 5-star ratings.
The results, presented in Table 6, reveal significant demographic
effects. The initial model without interactions shows that female
freelancers have 51.2% higher odds of receiving a non-5-star rating
compared to their male counterparts (OR = 1.512, p < 0.001). In
contrast, freelancers perceived as being from the United States
have 37.9% lower odds of receiving an imperfect rating compared
to those from India (OR = 0.621, p = 0.019), indicating they are
significantly more likely to receive perfect 5-star scores. The modelwith interaction includes an interaction term, showing that this
interaction is not statistically significant (p = 0.232). This suggests
that the tendency for female freelancers to receive lower ratings is
consistent across both countries in our dataset.
Table 6: Results for Receiving a Non-5-Star Rating
(a) Model without Interaction Term
Variable Odds Ratio (OR) 95% CI p-value
Intercept0.720 [0.644, 0.805]<0.001***
Female1.512 [1.185, 1.930]<0.001***
US0.621 [0.418, 0.923] 0.019*
Notes:
Ref. categories: Male; India
*ð‘<0.05; ***ð‘<0.001
(b) Model with Interaction Term
Variable Odds Ratio (OR) 95% CI p-value
Intercept0.714 [0.637, 0.799]<0.001***
Female1.584 [1.227, 2.045]<0.001***
US0.726 [0.457, 1.152] 0.174
FemaleÃ—US0.583 [0.241, 1.412] 0.232
Notes:
Ref. categories: Male; India
***ð‘<0.001
5 Conclusion
In this work, a novel method of using a Large Language Model with
Retrieval-Augmented Generation to generate datasets for variable-
controlled experiments is employed. In this section, we briefly sum-
marize the key findings obtained through the application of this
new approach.
5.1 Key Findings
From the analysis of user study data, we find:
â€¢In initial hiring selections, U.S. freelancers (of both genders)
are significantly more likely to be chosen than their Indian
counterparts. Within the same country, however, there is no
significant difference in selection rates between genders.
â€¢When assessing leadership qualities, a strong preference for
U.S. candidates emerges. For example, U.S. males are twice
as likely as Indian males to be perceived as leaders. Overall,
both U.S. male and female profiles are significant â€œwinners,â€
being chosen as more leader-like, while Indian male and
female profiles are significant â€œlosers.â€
From the analysis of collected data, we find:
â€¢Freelancers from the United States receive significantly fewer
reviews than their Indian counterparts, while female free-
lancers receive slightly more reviews than males.
â€¢The effect of gender on review counts is contingent on the
country. Specifically, in India, female freelancers receive
approximately 24% more reviews than males, whereas in
the U.S., they receive about 22% fewer reviews than their
male counterparts.
â€¢Female freelancers are 51.2% more likely than males to re-
ceive non-perfect (i.e., non-5-star) ratings. In contrast, U.S.

Unmasking Hiring BiasACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
freelancers are less likely to receive negative feedback and
thus more likely to get perfect scores than their Indian peers.
The interaction effect between gender and country on ratings
was not significant.
Previous studies have proven that demographic factors impact free-
lancer ratings, with a consistent advantage observed for freelancers
who are from the U.S. and for those who are male. Our studyâ€™s find-
ings are consistent with this pattern, providing further confirmation
for this argument. Additionally, our analysis of the pre-project stage
shows that female freelancers are a little bit more likely to be se-
lected. Simultaneously, the strong advantage for U.S. freelancers
persists, even when their profiles are identical to others in terms of
skills, pay, and other qualifications.
5.2 Gender Bias in Different Hiring Stages
The seemingly contradictory findings on gender bias from the Free-
lancer.com data and the user study reveal the complexity of how
bias operates at different stages.
In our experiment, participants viewed anonymous, AI-generated
profiles of similar quality. Their decisions are based solely on first
impressions, without any subsequent collaboration or communi-
cation. This setup cleanly isolates bias at the initial hiring stage.
The finding that gender bias is not significant here suggests that
when all other factors (such as skills and portfolio) are standardized,
individuals may not make irrational, gender-based choices at the
point of hire.
In contrast, the marketplace data allows for the measurement
of evaluation bias, defined as the feedback provided to a freelancer
after project completion. This reflects not just the first impression
of a profile but also the entire project lifecycle, including com-
munication, collaboration, delivery quality, and client satisfaction.
The data, which shows that women receive lower ratings (i.e., are
more likely to receive non-5-star reviews), indicates that clients
may hold stricter, unconscious biases against women during long-
term collaboration and final evaluation. They might judge womenâ€™s
work by a different standard or be more prone to forming negative
impressions during communication.
This paradox reveals a crucial insight: bias against women may
be less pronounced at the hiring stage but more severe during
the collaboration and evaluation phases. It paints a picture where
women may not struggle to get hired, but are more likely to face
unfair judgment in their work.
5.3 Regional Bias in Different Hiring Stages
Unlike gender bias, regional bias is highly significant and consistent
across both of our analyses, pointing to a more deeply entrenched
and pervasive form of prejudice. We propose two potential expla-
nations:
â€¢In-Group Bias & Cultural Proximity:Clients may nat-
urally gravitate towards U.S. freelancers with whom they
share a cultural background, language conventions, and com-
patible time zones.
â€¢Stereotypes of Developed Countries:A common cogni-
tive shortcut or stereotype may equate professionals fromdeveloped nations like the U.S. with higher quality, profes-
sionalism, and reliability. This â€œhalo effectâ€ gives U.S. free-
lancers a significant advantage from the outset, even when
their actual skills are comparable to their Indian counter-
parts.
Regional bias appears to be systemic, permeating the entire pro-
cess from first impressions (selection bias) to post-project reviews
(evaluation bias). Clients not only prefer U.S. freelancers at the
selection stage but also tend to give them higher ratings after the
collaboration is complete.
6 Usage of Generative AI Statement
Generative AI (Google Gemini) was used for two specific purposes:
(1) to generate LaTeX code for table formatting and (2) to assist with
text polishing, including grammar correction and improving sen-
tence clarity. The intellectual content, ideas, and analysis presented
are the original work of the author, who takes full responsibility
for the final version of the text.
References
[1]International Labour Office, editor.World employment and social outlook: trends
2021. ILO flagship report. International Labour Organization, Geneva, 2021.
[2] Independent work: Choice, necessity, and the gig economy | McKinsey.
[3]Aniket Kittur, Jeffrey V. Nickerson, Michael Bernstein, Elizabeth Gerber, Aaron
Shaw, John Zimmerman, Matt Lease, and John Horton. The future of crowd work.
InProceedings of the 2013 conference on Computer supported cooperative work,
CSCW â€™13, pages 1301â€“1318, New York, NY, USA, February 2013. Association for
Computing Machinery.
[4]Aniket Kittur, Boris Smus, Susheel Khamkar, and Robert E. Kraut. CrowdForge:
crowdsourcing complex work. InProceedings of the 24th annual ACM symposium
on User interface software and technology, UIST â€™11, pages 43â€“52, New York, NY,
USA, October 2011. Association for Computing Machinery.
[5]Haocheng Wu. The Future of Work: A Comprehensive Study of the Gig Economy
Beyond Low Labor-Value Added Jobs.Advances in Economics, Management and
Political Sciences, 64:112â€“120, December 2023.
[6]Louis Lippens, Siel Vermeiren, and Stijn Baert. The state of hiring discrimination:
A meta-analysis of (almost) all recent correspondence experiments.European
Economic Review, 151:104315, January 2023.
[7]Esther Kroll, Susanne Veit, and Matthias Ziegler. The Discriminatory Potential of
Modern Recruitment Trendsâ€”A Mixed-Method Study From Germany.Frontiers
in Psychology, 12:634376, October 2021.
[8]Dominik Hangartner, Daniel Kopp, and Michael Siegenthaler. Monitoring hiring
discrimination through online recruitment platforms.Nature, 589(7843):572â€“576,
January 2021. Publisher: Nature Publishing Group.
[9]AnikÃ³ HannÃ¡k, Claudia Wagner, David Garcia, Alan Mislove, Markus Strohmaier,
and Christo Wilson. Bias in Online Freelance Marketplaces: Evidence from
TaskRabbit and Fiverr. InProceedings of the 2017 ACM Conference on Computer
Supported Cooperative Work and Social Computing, pages 1914â€“1933, Portland
Oregon USA, February 2017. ACM.
[10] FoongEureka, VincentNicholas, HechtBrent, and GerberElizabeth M. Women
(Still) Ask For Less.Proceedings of the ACM on Human-Computer Interaction,
November 2018. Publisher: ACMPUB27New York, NY, USA.
[11] Faisal Hoque. How The Rising Gig Economy Is Reshaping Businesses, September
2015.
[12] Mark Graham, Isis Hjorth, and Vili Lehdonvirta. Digital labour and develop-
ment: impacts of global digital labour platforms and the gig economy on worker
livelihoods.Transfer (Brussels, Belgium), 23(2):135â€“162, May 2017.
[13] Inta Mieri n,a and Inese Å  Â¯upule. Rise of remote work across borders: opportunities
and implications for migrant-sending countries.Frontiers in Sociology, 9, May
2024. Publisher: Frontiers.
[14] Ryan Burns. Relational Spaces of Digital Labor. In Johannes GlÃ¼ckler and Robert
Panitz, editors,Knowledge and Digital Technology, pages 185â€“200. Springer Nature
Switzerland, Cham, 2024.
[15] Xue Guo, Jing Gong, and Paul A. Pavlou. On Matching Efficiency in Online
Labor Markets for IT Services: The Role of Project Description.Production and
Operations Management, page 10591478251367511, July 2025. Publisher: SAGE
Publications.
[16] Giuseppe A. Veltri, Francisco LupiÃ¡Ã±ez-Villanueva, Frans Folkvord, Alexandra
Theben, and George Gaskell. The impact of online platform transparency of

ACM Conference on Intelligent User Interfaces â€™2026, Paphos, Cyprus,
Zheng et al.
information on consumersâ€™ choices.Behavioural Public Policy, 7(1):55â€“82, January
2023.
[17] Benjamin Edelman, Michael Luca, and Dan Svirsky. Racial Discrimination in
the Sharing Economy: Evidence from a Field Experiment.American Economic
Journal: Applied Economics, 9(2):1â€“22, April 2017.
[18] Jason Chan and Jing Wang. Hiring Preferences in Online Labor Markets: Evidence
of a Female Hiring Bias.Manage. Sci., 64(7):2973â€“2994, July 2018.
[19] Qianyu Liu, Haoran Jiang, Zihao Pan, Qiushi Han, Zhenhui Peng, and Quan
Li. BiasEye: A Bias-Aware Real-time Interactive Material Screening System
for Impartial Candidate Assessment. InProceedings of the 29th International
Conference on Intelligent User Interfaces, pages 325â€“343, Greenville SC USA,
March 2024. ACM.
[20] Guohou Shan and Liangfei Qiu. Examining the impact of generative ai on usersâ€™
voluntary knowledge contribution: Evidence from a natural experiment on stack
overflow.Information Systems Research, 2025.
[21] Xinzhi Rao, Guohou Shan, and Liangfei Qiu. How generative ai transforms
questioning behavior on q&a platforms: Evidence from a natural experiment
with pilot usage of chatgpt.Available at SSRN 4909905, 2024.
[22] Guohou Shan, Dan Pienta, and Jason Bennet Thatcher. Investigating the relative
impact of generative ai vs. humans on voluntary knowledge contributions. 2024.
[23] Shizhen Jia, Guohou Shan, and Oscar Hengxuan Chi. Leveraging generative ai for
customer complaint resolution: A comparative analysis with human responses.
2024.
[24] Guohou Shan, Shizhen Jia, Liangfei Qiu, and Yunfei Wang. Generative ai vs.
human reviews: Unveiling the impact on online platforms.Human Reviews:Unveiling the Impact on Online Platforms (March 19, 2025), 2025.
[25] Guohou Shan and Shizhen Jia. Generative ai or real users? investigating the
relative impact of generative ai vs. humans on online review quality. 2024.
[26] Ziyi Iggy Zhao, Guohou Shan, and Sunil Wattal. Shortcuts or blind spots? the
impact of search generative experience (sge) on information-searching. 2025.
[27] Guohou Shan, Michael Rivera, Subodha Kumar, and Pawan Anand. The mind
and the machine: How does generative ai usage affect the coding performance of
developers?Northeastern U. Dâ€™Amore-McKim School of Business Research Paper,
(4859137), 2024.
[28] Perttu HÃ¤mÃ¤lÃ¤inen, Mikke Tavast, and Anton Kunnari. Evaluating Large Lan-
guage Models in Generating Synthetic HCI Research Data: a Case Study. In
Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems,
CHI â€™23, pages 1â€“19, New York, NY, USA, April 2023. Association for Computing
Machinery.
[29] Most Common Indian Surnames & Meanings.
[30] Most Common Indian Names & Meanings.
[31] Top Names Over the Last 100 Years.
[32] US Census Bureau. Frequently Occurring Surnames from the 2010 Census.
Section: Government.
[33] Joseph Dâ€™Souza. Freelancing Statistics By Earning, Demographics, Industry,
Social Media and Facts, November 2024.
[34] Freelancer.com Statistics (2025): User Growth, Revenue, Demographics, Top Skills
in Demand, and AI, February 2024. Section: Statistics.
[35] 77 Freelance Statistics & Data (2025), May 2023.