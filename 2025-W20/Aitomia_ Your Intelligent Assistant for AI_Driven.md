# Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations

**Authors**: Jinming Hu, Hassan Nawaz, Yuting Rui, Lijie Chi, Arif Ullah, Pavlo O. Dral

**Published**: 2025-05-13 03:11:41

**PDF URL**: [http://arxiv.org/pdf/2505.08195v1](http://arxiv.org/pdf/2505.08195v1)

## Abstract
We have developed Aitomia - a platform powered by AI to assist in performing
AI-driven atomistic and quantum chemical (QC) simulations. This intelligent
assistant platform is equipped with chatbots and AI agents to help experts and
guide non-experts in setting up and running the atomistic simulations,
monitoring their computation status, analyzing the simulation results, and
summarizing them for the user in text and graphical forms. We achieve these
goals by exploiting fine-tuned open-source large language models (LLMs),
rule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia
leverages the versatility of our MLatom ecosystem for AI-enhanced computational
chemistry. This intelligent assistant is going to be integrated into the
Aitomistic Hub and XACS online computing services, with some functionality
already publicly available as described at http://mlatom.com/aitomia. Aitomia
is expected to lower the barrier to performing atomistic simulations,
accelerating research and development in the relevant fields.

## Full Text


<!-- PDF content starts -->

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 1 of 18  Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations Jinming Hu,1† Hassan Nawaz,1† Yuting Rui,1 Lijie Chi,3 Arif Ullah,4* and  Pavlo O. Dral1,2,3* 1 State Key Laboratory of Physical Chemistry of Solid Surfaces, Department of Chemistry, College of Chemistry and Chemicals Engineering, and Fujian Provincial Key Laboratory of Theoretical and Computational Chemistry, Xiamen University, Xiamen 361005, China. 2 Institute of Physics, Faculty of Physics, Astronomy, and Informatics, Nicolaus Copernicus University in Toruń, ul. Grudziądzka 5, 87-100 Toruń, Poland. 3 Aitomistic, Shenzhen, China. 4 School of Physics and Optoelectronic Engineering, Anhui University, Hefei 230601, Anhui, China. †Co-first authors. Email: arif@ahu.edu.cn (A.U.); dral@xmu.edu.cn (P.O.D.) Abstract We have developed Aitomia – a platform powered by AI to assist in performing AI-driven atomistic and quantum chemical (QC) simulations. This intelligent assistant platform is equipped with chatbots and AI agents to help experts and guide non-experts in setting up and running the atomistic simulations, monitoring their computation status, analyzing the simulation results, and summarizing them for the user in text and graphical forms. We achieve these goals by exploiting fine-tuned open-source large language models (LLMs), rule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia leverages the versatility of our MLatom ecosystem for AI-enhanced computational chemistry. This intelligent assistant is going to be integrated into the Aitomistic Hub and XACS online computing services, with some functionality already publicly available as described at http://mlatom.com/aitomia. Aitomia is expected to lower the barrier to performing atomistic simulations, accelerating research and development in the relevant fields.   

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 2 of 18  Introduction Computational chemistry has played a transformative role in advancing chemical research over the past decades, enabling spectra simulations and interpretation, the elucidation of reaction mechanisms, and generation of training datasets for AI-assisted design and discovery.1-5 The backbone of such atomistic simulations is quantum chemistry (QC) based on the first principles – solving the Schrödinger equation by employing numerous approximated methods balancing speed and accuracy. Artificial intelligence (AI)/machine learning (ML) methods are increasingly employed for AI-driven atomistic simulations too However, the growing sophistication of the computational chemistry tools presents significant challenges for researchers. Proficiency with these tools requires not only familiarity with complex underlying theories and package-specific options but often skills in Linux and access to high-performance computing (HPC) resources. Moreover, simulating realistic chemical processes often necessitates the integration of multiple computational packages, compounding the complexity for users across the chemical sciences. Despite progress in automating computational workflows, two critical barriers remain. First, users must manually configure crucial simulation parameters, often requiring consultation of extensive and technical user manuals. Second, many workflows depend on HPC resources, which are not readily available to non-computational researchers, including experimental chemists and students. Some of the aforementioned issues are alleviated with graphical user interfaces (GUIs) designed for the specific software packages. For example, a popular Gaussian program6 for QC calculations has GaussView as its official GUI that facilitates the creation of input files and analysis of the calculation results. Many other packages, such as Materials Studio and ADF7 were built to provide seamless experiences for computing job preparation, performing and analyzing the computations. Unfortunately, GUIs themselves do not fully solve the above problems as the researchers still might need to learn the options of the GUIs in addition to the options of the software itself, submit the computation jobs in HPC clusters, and seek expert advice. Another useful solution lies in a growing number of website platforms that provide simplified ways to submit and run calculations, which often come with web GUIs, some of the examples are TeraChem,8 and ChemCompute.9 We are also involved in the development of similar platforms, Aitomistic Hub10 and Xiamen Atomistic Computing Suite (XACS),11 which enables the submission of the QC and AI-driven atomistic calculations to the HPC clusters via a web browser. An interesting platform is Chemvox,12 which is available for running calculations based on the speech recognition power of AI, i.e., the researchers can perform basic calculations via voice commands. Another attempt to bring QC calculations to the general users, including students, is the mobile app MoleculAR, which provides the conversion of the 2D handwritten structures into 3D visualization for a better understanding of the molecular structures.13 The platforms mentioned above often provide free HPC resources for basic use, such as education, and are usually convenient options for performing QC and ML simulations, but the users still need to understand the background of the software 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 3 of 18  and supported theoretical methods. These website platforms also provide limited help with the interpretation and analysis of the results. With the success of large language models (LLMs) such as ChatGPT and DeepSeek14 it is natural to ask whether LLMs can provide an ultimate solution for making QC and ML-driven atomistic simulations accessible to a wider researcher base. Although there have been many studies combining LLM with professional chemistry-related fields in recent years,15-17 there is little to none research that utilizes LLM with AI agents to perform AI-driven atomistic and QC calculations, while also providing a detailed interpretation and analysis of the results. One of the recent noteworthy attempts is the AutoSolvateWeb platform18 for submitting computational jobs using an AI agent that guides the user in choosing the calculation parameters and provides explanations for the basic queries. This platform is still limited to submitting jobs to some of the cloud computing services but provides neither the analysis of the obtained results nor any technical discussion on the calculations. This approach resembles a rule-based method to guide the users with rather limited explanations. Consequently, there is a pressing need for a user-friendly platform that reduces technical and computational barriers, enabling a wider audience to leverage computational chemistry tools effectively. 
 Figure 1. The overview of intelligent assistant Aitomia place in AI-driven and QC atomistic simulations, with chatbot interacting with the user, integrating MLatom package for performing AI-enhanced computational chemistry calculations on the Aitomistic Hub and XACS cloud computing services, and providing final calculation results. Here we present Aitomia – a platform powered by an AI assistant to simplify all the stages of the AI-driven atomistic and QC simulations (Figure 1). This platform is equipped with the chatbots, which communicates with the users in their natural language (English at the moment of writing). The chatbots assist the researchers in all the stages from setting up the calculations, providing possible options, automatically performing the simulations, and analyzing their results in an understandable and reusable format. 


Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 4 of 18  Aitomia is leveraging MLatom ecosystem19 that supports a wide array of AI-driven atomistic and QC methods, enabling essential computations such as energy calculations, geometry optimizations, molecular dynamics, thermochemistry, reaction and spectra simulations. We are also integrating Aitomia itself in the Aitomistic Hub and XACS cloud computing services to further democratize access to computational chemistry and augment Aitomia with the convenient GUI and other tools for atomistic simulations. Our platform is expected to enable experts and non-experts alike, experimental researchers, educators, and students to utilize advanced computational chemistry tools, expanding their accessibility and applicability, ultimately accelerating advancements in the relevant fields, such as drug and materials design. Methodology The scope of atomistic simulations Our goal is to design an intelligent assistant capable of performing most of the key computational chemistry tasks with a wide variety of QC methods and state-of-the-art AI atomistic models. This is an ambitious goal which presents a formidable challenge as it requires supporting many different software packages and theoretical methods, both QC and AI-driven ones. Luckily, this can be achieved by integrating our intelligent assistant with the existing MLatom software ecosystem,19 which is particularly suited to addressing this goal because MLatom seamlessly supports both QC and AI-driven atomistic simulations (Figure 2). 
 Figure 2. Aitomia is using MLatom for performing a wide-range of computational chemistry tasks with a many QC and AI atomistic models, overview of which is shown in this figure. Figure is modified from J. Chem. Theory Comput. 2024, 20, 1193–1213 under the CC-BY license. 


Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 5 of 18  MLatom is an open-source software capable of performing such tasks as energy calculations, geometry optimizations, reactions, molecular dynamics, thermochemistry, and spectra simulations. In addition, MLatom has built-in functionality for training, evaluating, and using custom AI models, including complex workflows such as active learning. It also provides many of the state-of-the-art pre-trained universal models, such as the AIQM,20-23 AIMnet,24 ANI,25-28 and OMNI-P series of models,29, 30 many of which approach the coupled-cluster accuracy at a fraction of the computational cost of density functional theory (DFT); OMNI-P2x30 is a unique universal potential also supporting the excited-state calculations. Many of the universal models can be fine-tuned for user-specific tasks. Selection of the LLM models The selection of the LLMs is crucial for the performance of the intelligent assistant. Recent years have witnessed the rapid advancements in AI and large-scale models, leading to the emergence of numerous LLMs, each exhibiting distinct strengths and different overall performance. This complicates the choice of a suitable LLM model. We base our choice on several criteria, such as the model’s general performance, size, and license. Availability of computational resources remains a significant challenge for many research groups aiming to develop and deploy AI-assisted platforms. While some researchers rely on publicly accessible cloud-based infrastructures or paid APIs, such as OpenAI's ChatGPT models, to leverage the computational power required by LLMs, these solutions present notable limitations. Chief among them is the high cost associated with sustained usage, making such services financially burdensome for long-term or large-scale projects. Moreover, data privacy concerns are a critical drawback; utilizing third-party APIs often involves transmitting sensitive data to external servers, thereby exposing proprietary or confidential information to potential vulnerabilities and compliance risks. The Aitomia platform is designed to be highly resource-efficient and user-friendly. It can be seamlessly deployed on consumer-grade GPUs, such as one or two NVIDIA RTX 4090 units, without the need for high-end server infrastructure. Another consideration is that the model must be open source, and the size should be small enough to perform fine-tuning (see the next section) and deploy on the limited hardware available in academic settings. Hence, our choice has fallen on the Qwen31 and distilled DeepSeek14 models. While DeepSeek models are generally better, our initial investigation has been performed with the Qwen-based models and, hence, we have several variants of the Aitomia. Aitomia-F1 is based on the Qwen model, which we fine-tuned. Aitomia-F0 is based on the original deepseek-r1:32b model without fine-tuning, where, the use of ‘0’ indicates zero fine-tuning. We are now working on fine-tuning the DeepSeek models, which will be included in the future upgrades of Aitomia. Model fine-tuning Currently, the LLM models’ knowledge is still lagging the real-time development of the AI atomistic models and QC methods, in addition, LLM’s performance on specialized tasks 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 6 of 18  such as atomistic simulations is subpar. This is particularly true for the smaller versions of LLMs we use in this study. Hence, to enhance the quality of the LLM models, we fine-tune them. For model fine-tuning, the most used approaches are Full Fine-Tuning and Parameter-Efficient Fine-Tuning (PEFT).32, 33 The key difference between the two lies in which parameters are updated and how they are adjusted. Full Fine-Tuning updates all parameters, which allows for greater flexibility and higher performance when the training data is large enough. However, if the training dataset is small, Full Fine-Tuning is prone to overfitting. In addition, full fine-tuning needs a huge computational resource. Among PEFT methods, Low-Rank Adaptation (LoRA, Figure 3a) has gained widespread adoption due to its ability to maintain high performance while significantly reducing computational costs.34, 35 Instead of updating all parameters, LoRA introduced the low-rank matrices to determine which parameters should be updated, allowing the model to learn from new data while keeping the main weights unchanged. This approach helps to reduce the possibility of overfitting, especially when the training dataset is not large enough. Considering our fine-tuning objectives, training dataset size, and hardware constraints, we have used LoRA for our fine-tuning. 
 Figure 3. Techniques we have used to enhance the LLM performance in Aitomia. a) Fine-tuning with LoRA. b) The RAG pipeline: retrieving external knowledge for enhanced generation. Data for fine-tuning the models Fine-tuning requires professional domain data. Hence, for fine-tuning LLM integrated in Aitomia, we have used the extensive documentation of MLatom, containing many tutorials and manuals. This documentation is available online at http://mlatom.com/docs and covers various topics such as data, methods, AI models, simulations, special topics on excited states, manuals for input file, command line interface, and Python APIs. The topics about methods include AIQM and other universal ML models, DFT methods and ensembles36 and semi-empirical methods. ML model training consists of sections about 


Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 7 of 18  MLatom’s use for building ML models and machine learning interatomic potentials as a special but important case, active learning,37 transfer learning,28 Δ-learning,38 and directly learning dynamics.39 The documentation contains numerous entries on simulations, i.e., single-point calculations, geometry optimization, transition state optimization and analysis, frequency and thermochemistry calculations, infrared and Raman spectra (using static40 and dynamics41 approaches), molecular dynamics (MD) including quasi-classical MD, and simulations in periodic boundary conditions. The special topics on excited states include tutorials on creating ML potentials for excited states, simulating absorption and emission spectra (including the ML-nuclear ensemble approach42), performing surface-hopping dynamics43 and active learning44 to the latter, and two-photon absorption spectra.45 The quality of the documentation is ensured by its extensive use in teaching computational chemistry courses at Xiamen University and Nicolaus Copernicus University in Toruń and in numerous workshops, as well as by timely addressing the user feedback and ensuring the reproducibility of the publications documenting the corresponding implementations. Enhancing Model Robustness Through Retrieval-Augmented Generation (RAG) Although after fine-tuning, the model can significantly enhance its ability to learn domain-specific knowledge, the vastness of the relevant knowledge makes it impossible for the model fine-tuning to cover every aspect comprehensively, and the increasing size of datasets can lead to a sharp rise in fine-tuning costs. However, when dealing with data the model has not been trained on, the model tends to hallucinate, which may mislead users and lead to failed simulations. To address these issues and improve the model's performance, we also integrate RAG to improve the model's robustness by providing access to external knowledge, which reduces the model hallucinations and enhances its factual accuracy (Figure 3b). Traditional Naive RAG, while technically the simplest and most feasible approach, incurs unnecessary resources overhead because it performs a retrieval step every time before generating an answer46, 47  Adaptive-RAG presents a promising alternative,48 which we have implemented in Aitomia. When RAG is activated, Aitomia judges whether the question is related to quantum chemistry or AI-driven atomistic simulation-related knowledge, and if it is related, Aitomia retrieves information from the RAG database. In case the retrieved information is judged by Aitomia to be relevant to user query, it generates answers based on the retrieved data. After that Aitomia judges whether the answer is a result of a hallucination, if so – Aitomia regenerates the answer based on the retrieved information, if not – sends the final answer to user. In addition, if the answer is not relevant to the user’s query, Aitomia will rephrase the question without changing its core meaning and retrieve it from the database again. By using this strategy, it only retrieves information for questions relevant to quantum chemistry, thereby reducing the number of retrievals and mitigating the model's tendency to 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 8 of 18  generate hallucinations at the same time. Therefore, we integrate Adaptive-RAG to enhance the robustness of our model. The integration of Adaptive-RAG reduces the probability of model hallucinations and improves the model performance based on user needs. Hard-coded fail-safe It is hard to completely eliminate the failures of the LLM-based agents. Hence, to increase the robustness of our platform, we implemented the fail-safe Aitomia-H1. This agent is rule (logic) based, hard-coding many of the typical workflows: single-point calculations, geometry optimizations, transition state structure optimizations, frequency and thermochemistry, and infrared spectra simulations. In this approach, the chatbot gives the user a choice of available options, and the user can select the required ones by clicking the corresponding buttons. Results and discussion Aitomia serves as a look-up tool for atomistic calculation The step zero of learning how to perform specific types of atomistic simulations by a non-expert is first learning the background knowledge about what are these simulations, how they are performed, and what QC methods or AI models to choose. Before the rise of the LLMs, the only way to learn this was either by self-studying manuals and tutorials or from a human teacher. This severely limits the speed of acquiring knowledge, which might be also of limited access. Aitomia provides a useful chatbot expert in atomistic simulations which can assist the non-experts in providing background information about the available computational approaches. There are no standard benchmarks for such a task, hence, we show two examples of asking MLatom about the computational approaches it supports (Figure 4). 
 Figure 4. Aitomia can serve to provide background information to non-experts about the computational chemistry tasks this platform supports. Here two examples are shown. 


Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 9 of 18  In the first example, Aitomia was asked ‘which universal potential do you recommend me to use for calculations in MLatom?’ This is a very specific question, only the narrow experts can answer. Aitomia satisfactorily answered this question by suggesting two of the universal potentials with very good accuracy and transferability in their application domains: AIQM1 and ANI-2x. Moreover, it identified AIQM1 as the most suitable universal potential for performing simulations in MLatom. It also justifies its recommendation with multiple scientifically grounded arguments. First, AIQM1 exhibits accuracy approximately equal to the couple-cluster gold standard method CCSD(T) for many applications, ensuring reliable and high-fidelity results. Second, Aitomia points out strong transferability of AIQM1 across diverse molecular systems, including large and chemically complex structures, making it highly versatile for general-purpose use. Third, Aitomia provides grounds for its recommendation by saying AIQM1 gives closer benchmark results to the experiment compared to many DFT methods. Afterwards, Aitomia also recommends another universal potential ANI-2x for broader elemental coverage, justifying the recommendation by listing the supported elements (CHNOFClS), but, in the end, it again emphasizes the accuracy factor and gives a final recommendation to use the A1QM1 as the best choice in the MLatom as a universal potential. These recommendations are generally very good. A human expert in this narrow field of the universal potentials might point out other potentials with different advantages and disadvantages, though. Another question was more of a general nature, asking Aitomia, “What is geometry optimization, and how it can be done using mlatom?” (sic!). Here, Aitomia also gave a reasonable answer, explaining what geometry optimization is and that it can be done in MLatom using ML models. It also provided a breakdown of the key points. However, the answer was far from excellent, e.g., it was suggesting “Hessian Calculation” as a required part of the geometry optimizations, while most of the practically used algorithms are gradient-based and do not evaluate Hessians. In addition, geometry optimizations can also be performed with the QC methods in MLatom, not just with ML models. We also tested how robust Aitomia’s responses are to the variations in the user prompts, i.e., by modifying the questions so that their meaning is retained but the phrasing is different. We found that Aitomia is quite robust to different phrasing, giving similar replies, although detailed responses and recommendations Aitomia gives vary. Overall, Aitomia has the potential to be employed in the role of a teaching assistant in computational chemistry courses, at least initially under the supervision of a human teacher, a possibility we are planning to explore soon. The application of a fine-tuned LLM-based platform Beyond providing background information to the users about available simulation tasks, the goal is to use Aitomia to assist in performing the full computational workflows. These workflows are, in principle, available via the seamless integration of MLatom, enabling various types of atomistic simulations. Typically, performing such simulations using MLatom requires users to be familiar with its input structure. To overcome this barrier, we fine-tuned 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 10 of 18  the Qwen-7B LLM on our internally developed MLatom tutorials and integrated this fine-tuned model into Aitomia. When Aitomia is queried to perform a computational chemistry task—a geometry optimization (see schematic example in Figure 5)—the current implementation will use the fine-tuned LLM to guide the user in setting up the calculations, performing them, and delivering the results back to the user. In the example, Aitomia assist the user through constructing the input by asking additional simulation parameters: (1) the initial geometry (e.g., init.xyz), (2) the computational method (e.g., B3LYP/6-31G*), (3) the simulation engine to be used, and (4) the maximum number of optimization steps. Here, the user provided the geometry, went for Aitomia’s suggestions of B3LYP/6-31G*method and the maximum number of optimization steps of 5,000, but omitted specifying the simulation engine. To avoid a potentially wasteful simulation due to the missing information, the fine-tuned LLM, which detected the missing parameter, notified the user of the omission and suggested using the default geomeTRIC engine,49 requesting the user’s confirmation before proceeding. 
 Figure 5. A schematic example of Aitomia’s use of the fine-tuned LLM model in a chatbot assisting in performing geometry optimization with a popular DFT method (B3LYP/6-31G*). The user has uploaded the file with initial xyz coordinates, and Aitomia has sent the user the correct optimized structure, which, for simplicity, is not shown. 


Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 11 of 18  Upon confirmation, the LLM submitted the job to the backend server and returned the simulation results upon completion. We manually verified that the result was correct. Furthermore, if a user wishes to use a different computational method from the one suggested, they may simply substitute the method accordingly in the input. This demonstrates how the fine-tuned LLM facilitates user-friendly, autonomous, and robust execution of quantum chemical simulations within the Aitomia platform. This example shows that fine-tuning of the smaller LLMs can produce an AI assistant for the basic workflows, such as geometry optimization of simple molecules. Invoking fail-safe option and its capabilities Although Aitomia has high flexibility and fine-tuning can greatly improve the model's ability to perform MLatom calculations, due to limited model parameters and incomplete training data, it is inevitable that sometimes it cannot produce completely correct results. In cases, when fine-tuned LLM fails to provide reasonable answers, the users with no knowledge about MLatom calculations, can fall back to the Aitomia-H1 assistant, which is a rule-based fail-safe of our platform. The Aitomia-H1 can perform a series of quantum chemistry simulations such as single point calculation, geometry optimizations, transition state optimizations, frequencies and thermochemistry calculations, and infrared spectrum predictions. Since it is integrated with the Mlatom ecosystem, many QC and ML models are available for use in calculations.  Aitomia would then provide a choice among the common QC approaches, particularly among the semi-empirical methods such as PM7, GFN2 xTB, as well as common DFT functionals such as B3LYP, ωB97X, and basis sets such as 6-31G* and def2-SVP, and common program interfaces such as PySCF as a free open-source version, and Gaussian and ORCA for users with the corresponding license. Of course, users can also specify other custom methods and programs within the scope of our interface support. In addition, due to the integration with the MLatom ecosystem, we also offer many of the latest AI atomistic methods. Figure 6 shows an example of Aiatomia-H1 performing infrared spectrum simulations for H2O, where the user chooses the UAIQM model. 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 12 of 18   Figure 6. Aitomia has a robust implementation of the typical tasks, such as infrared spectra simulations with the UAIQM model. If the user chooses it, Aitomia will provide the relevant buttons corresponding to the available computational settings. While the chat is truncated for clarity, the infrared spectrum is generated by Aitomia with a UAIQM model21 for a real molecule (water) provided by the user. The spectrum was generated within a harmonic approximation, which, with AIQM models provides DFT-quality spectra but with orders-of-magnitude reduced computational cost.40   


Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 13 of 18  Conclusions and outlook We have introduced an intelligent assistant, Aitomia, helping researchers to perform atomistic simulations according to their needs, even without specialized knowledge about the underlying software. It draws on the versatility of the MLatom software ecosystem to enable a very broad range of computational chemistry tasks with both traditional QM (DFT, HF, and post-HF, semi-empirical methods) and AI atomistic models (universal ML interatomic potentials and beyond). Aitomia can assist in performing such typical tasks as geometry optimizations, MD, spectra simulations, and reaction mechanism exploration. In addition, the Aitomia can be used as an expert advisor in performing atomistic simulations. Its ability to analyze the calculation results and answer common QC and ML questions will play a promotional role in helping professionals and non-professionals conduct computational research and analysis in related fields such as drug and materials design. Remarkably, we demonstrated the possibility of creating an intelligent assistant based on small-sized LLMs, which enables its deployment on consumer-grade GPUs, such as one or two NVIDIA RTX 4090 units, without the need for high-end server infrastructure. Its specialization on the above atomistic simulation tasks is imparted by fine-tuning on the dedicated and detailed tutorials and manuals. As such, small models are not expected to always perform without failure, we also implemented a fail-safe by hard-coding representative typical computational workflows. Aitomia can be easily adapted to using larger LLMs to obtain better results. However, there are many reasons why using Aitomia with smaller models might be preferable: it can be deployed locally for fully private data storage, reduce the consumption of computational resources in turn reducing the carbon footprint and financial losses, and might be the only viable option for researchers with limited access to resources. Its integration into Aitomistic Hub and XACS cloud services will further contribute to the democratization of the atomistic simulations. In the future, as better and better LLM models appear, even with reduced size, we can expect rapid improvements in the Aitomia quality.   

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 14 of 18  Technical details All the logic and APIs are implemented using JavaScript, HTML, Python library Fast API, and Uvicorn 0.34.0. Atomia-F1 is based on deepseek-r1:32b LLM model, which is deployed using the command line platform ollama. Aitomia-F2 is fine-tuned LLM integrated with RAG using LANGCHAIN. In this RAG part, we use the Qdrant locally deployed as a vector database that employs approximate Nearest Neighbor algorithms for very fast retrieval of similar vectors. We use RecursiveCharacterTextSplitter to make chunks. In addition, Aitomia-F2 has integrated AI agents into it. All the AI agent connections and communications are coded using the LANGGRAPH. At the core of Aitomia’s computational engine is MLatom, an open-source software package that integrates quantum chemical calculations with AI-enhanced atomistic simulations. MLatom can be easily installed locally via Python’s package manager  (pip install mlatom), enabling researchers to operate the entire platform within their own computing environment. MLatom is based on many third-party programs as described in its documentation, including Gaussian,6 PySCF,6 Orca,50, 51 MNDO,52 xtb,53 dftd4,54 TorchANI,55 mace,56 sGDML,57 PhysNet,58 DeePMD-kit,59 geomeTRIC,49 and ASE60. Many of the state-of-the-art AI atomistic models are available as add-ons to MLatom via Aitomic.61 Platform availability The Aitomia intelligent assistant platform will be accessible as described in http://mlatom.com/aitomia. It is intended to be deployed in Aitomistic Hub10 and XACS11 online computing services, with some basic functionality already available on Aitomistic Hub. Acknowledgments P.O.D. acknowledges funding from the National Natural Science Foundation of China (funding via the Outstanding Youth Scholars (Overseas, 2021) project) and via the Lab project of the State Key Laboratory of Physical Chemistry of Solid Surfaces. A.U. acknowledges funding from the National Natural Science Foundation of China (No. W2433037) and Natural Science Foundation of Anhui Province (No. 2408085QA002). We also thank Aitomistic for financial support and integration of Aitomia in Aitomistic Lab and Hub (aitomistic.xyz).   

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 15 of 18  References (1) Chakraborty, C.;  Bhattacharya, M.;  Pal, S.;  Chatterjee, S.;  Das, A.; Lee, S.-S., Ai-enabled language models (LMs) to large language models (LLMs) and multimodal large language models (MLLMs) in drug discovery and development. Journal of Advanced Research 2025. (2) Cheng, G.-J.;  Zhang, X.;  Chung, L. W.;  Xu, L.; Wu, Y.-D., Computational organic chemistry: bridging theory and experiment in establishing the mechanisms of chemical reactions. Journal of the American Chemical Society 2015, 137, 1706-1725. (3) Kato, T.;  Kusakizako, T.;  Jin, C.;  Zhou, X.;  Ohgaki, R.;  Quan, L.;  Xu, M.;  Okuda, S.;  Kobayashi, K.; Yamashita, K., Structural insights into inhibitory mechanism of human excitatory amino acid transporter EAAT2. Nature Communications 2022, 13, 4714. (4) Ramakrishnan, R.;  Dral, P. O.;  Rupp, M.; Von Lilienfeld, O. A., Quantum chemistry structures and properties of 134 kilo molecules. Scientific data 2014, 1, 1-7. (5) Smith, J. S.;  Isayev, O.; Roitberg, A. E., ANI-1, A data set of 20 million calculated off-equilibrium conformations for organic molecules. Scientific data 2017, 4, 1-8. (6) Frisch, M. J.;  Trucks, G. W.;  Schlegel, H. B.;  Scuseria, G. E.;  Robb, M. A.;  Cheeseman, J. R.;  Scalmani, G.;  Barone, V.;  Petersson, G. A.;  Nakatsuji, H.;  Li, X.;  Caricato, M.;  Marenich, A. V.;  Bloino, J.;  Janesko, B. G.;  Gomperts, R.;  Mennucci, B.;  Hratchian, H. P.;  Ortiz, J. V.;  Izmaylov, A. F.;  Sonnenberg, J. L.;  Williams;  Ding, F.;  Lipparini, F.;  Egidi, F.;  Goings, J.;  Peng, B.;  Petrone, A.;  Henderson, T.;  Ranasinghe, D.;  Zakrzewski, V. G.;  Gao, J.;  Rega, N.;  Zheng, G.;  Liang, W.;  Hada, M.;  Ehara, M.;  Toyota, K.;  Fukuda, R.;  Hasegawa, J.;  Ishida, M.;  Nakajima, T.;  Honda, Y.;  Kitao, O.;  Nakai, H.;  Vreven, T.;  Throssell, K.;  Montgomery Jr., J. A.;  Peralta, J. E.;  Ogliaro, F.;  Bearpark, M. J.;  Heyd, J. J.;  Brothers, E. N.;  Kudin, K. N.;  Staroverov, V. N.;  Keith, T. A.;  Kobayashi, R.;  Normand, J.;  Raghavachari, K.;  Rendell, A. P.;  Burant, J. C.;  Iyengar, S. S.;  Tomasi, J.;  Cossi, M.;  Millam, J. M.;  Klene, M.;  Adamo, C.;  Cammi, R.;  Ochterski, J. W.;  Martin, R. L.;  Morokuma, K.;  Farkas, O.;  Foresman, J. B.; Fox, D. J. Gaussian 16, Rev. A.01, Wallingford, CT, 2016. (7) ADF 2025.1, SCM, Theoretical Chemistry, Vrije Universiteit, Amsterdam, The Netherlands, http://www.scm.com. (8) Seritan, S.;  Thompson, K.; Martínez, T. J., TeraChem Cloud: A high-performance computing service for scalable distributed GPU-accelerated electronic structure calculations. Journal of Chemical Information and Modeling 2020, 60, 2126-2137. (9) Perri, M.; Weber, S., Web-based job submission interface for the GAMESS computational chemistry program. ACS Publications: 2014. (10) Aitomistic Hub, https://www.aitomistic.xyz, Aitomistic, Shenzhen, China: 2025. (11) Xiamen Atomistic Computing Suite (XACS), https://XACScloud.com, Xiamen University: 2022-2025. (12) Raucci, U.;  Pieri, E.;  Weir, H.;  Seritan, S.; Martínez, T. J., ChemVox: voice-controlled quantum chemistry. 2020. (13) Levy, J.;  Chagunda, I. C.;  Iosub, V.;  Leitch, D. C.; McIndoe, J. S., MoleculAR: An augmented reality application for understanding 3D geometry. ACS Publications: 2024. (14) DeepSeek-AI;  Guo, D.;  Yang, D.;  Zhang, H.;  Song, J.;  Zhang, R.;  Xu, R.;  Zhu, Q.;  Ma, S.;  Wang, P.;  Bi, X.;  Zhang, X.;  Yu, X.;  Wu, Y.;  Wu, Z. F.;  Gou, Z.;  Shao, Z.;  Li, Z.;  Gao, Z.;  Liu, A.;  Xue, B.;  Wang, B.;  Wu, B.;  Feng, B.;  Lu, C.;  Zhao, C.;  Deng, C.;  Zhang, C.;  Ruan, C.;  Dai, D.;  Chen, D.;  Ji, D.;  Li, E.;  Lin, F.;  Dai, F.;  Luo, F.;  Hao, G.;  Chen, G.;  Li, G.;  Zhang, H.;  Bao, H.;  Xu, H.;  Wang, H.;  Ding, H.;  Xin, H.;  Gao, H.;  Qu, H.;  Li, H.;  Guo, J.;  Li, J.;  Wang, J.;  Chen, J.;  Yuan, J.;  Qiu, J.;  Li, J.;  Cai, J. L.;  Ni, J.;  Liang, J.;  Chen, J.;  Dong, K.;  Hu, K.;  Gao, K.;  Guan, K.;  Huang, K.;  Yu, K.;  Wang, L.;  Zhang, L.;  Zhao, L.;  Wang, L.;  Zhang, L.;  Xu, L.;  Xia, L.;  Zhang, M.;  Zhang, M.;  Tang, M.;  Li, M.;  Wang, M.;  Li, M.;  Tian, N.;  Huang, P.;  Zhang, P.;  Wang, Q.;  Chen, Q.;  Du, Q.;  Ge, R.;  Zhang, R.;  Pan, R.;  Wang, R.;  Chen, R. J.;  Jin, R. L.;  Chen, R.;  Lu, S.;  Zhou, S.;  Chen, S.;  Ye, S.;  Wang, S.;  Yu, S.;  Zhou, S.;  Pan, S.;  Li, S. S.;  Zhou, S.;  Wu, S.;  Ye, S.;  Yun, T.;  Pei, T.;  Sun, T.;  Wang, T.;  Zeng, W.;  Zhao, W.;  Liu, W.;  Liang, W.;  Gao, W.;  Yu, W.;  Zhang, W.;  Xiao, W. L.;  An, W.;  Liu, X.;  Wang, X.;  Chen, X.;  Nie, X.;  Cheng, X.;  Liu, X.;  Xie, X.;  Liu, X.;  Yang, X.;  Li, X.;  Su, X.;  Lin, X.;  Li, X. Q.;  Jin, X.;  Shen, X.;  Chen, X.;  Sun, X.;  Wang, X.;  Song, X.;  Zhou, X.;  Wang, X.;  Shan, X.;  Li, Y. K.;  Wang, Y. Q.;  Wei, Y. X.;  Zhang, Y.;  Xu, Y.;  Li, Y.;  Zhao, Y.;  Sun, Y.;  Wang, Y.;  Yu, Y.;  Zhang, Y.;  Shi, Y.;  Xiong, Y.;  He, Y.;  

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 16 of 18  Piao, Y.;  Wang, Y.;  Tan, Y.;  Ma, Y.;  Liu, Y.;  Guo, Y.;  Ou, Y.;  Wang, Y.;  Gong, Y.;  Zou, Y.;  He, Y.;  Xiong, Y.;  Luo, Y.;  You, Y.;  Liu, Y.;  Zhou, Y.;  Zhu, Y. X.;  Xu, Y.;  Huang, Y.;  Li, Y.;  Zheng, Y.;  Zhu, Y.;  Ma, Y.;  Tang, Y.;  Zha, Y.;  Yan, Y.;  Ren, Z. Z.;  Ren, Z.;  Sha, Z.;  Fu, Z.;  Xu, Z.;  Xie, Z.;  Zhang, Z.;  Hao, Z.;  Ma, Z.;  Yan, Z.;  Wu, Z.;  Gu, Z.;  Zhu, Z.;  Liu, Z.;  Li, Z.;  Xie, Z.;  Song, Z.;  Pan, Z.;  Huang, Z.;  Xu, Z.;  Zhang, Z.; Zhang, Z., DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning. arXiv:2501.12948v1 [cs.CL] 2025. (15) Zheng, W.;  Li, K.; Fu, P., Adaptive large language model for predicting lithium-ion battery degradation in energy storage systems. Available at SSRN 4910174. (16) Wang, L.;  Chen, X.;  Du, Y.;  Zhou, Y.;  Gao, Y.; Cui, W., CataLM: empowering catalyst design through large language models. International Journal of Machine Learning and Cybernetics 2025, 1-11. (17) Zhang, C.;  Lin, Q.;  Zhu, B.;  Yang, H.;  Lian, X.;  Deng, H.;  Zheng, J.; Liao, K., SynAsk: unleashing the power of large language models in organic synthesis. Chemical Science 2025, 16, 43-56. (18) Gadde, R. S.;  Devaguptam, S.;  Ren, F.;  Mittal, R.;  Dong, L.;  Wang, Y.; Liu, F., Chatbot-assisted quantum chemistry for explicitly solvated molecules. Chemical Science 2025. (19) Dral, P. O.;  Ge, F.;  Hou, Y.-F.;  Zheng, P.;  Chen, Y.;  Barbatti, M.;  Isayev, O.;  Wang, C.;  Xue, B.-X.;  Pinheiro Jr, M.;  Su, Y.;  Dai, Y.;  Chen, Y.;  Zhang, S.;  Zhang, L.;  Ullah, A.;  Zhang, Q.; Ou, Y., MLatom 3: A Platform for Machine Learning-Enhanced Computational Chemistry Simulations and Workflows. J. Chem. Theory Comput. 2024, 20, 1193–1213. (20) Zheng, P.;  Zubatyuk, R.;  Wu, W.;  Isayev, O.; Dral, P. O., Artificial Intelligence-Enhanced Quantum Chemical Method with Broad Applicability. Nat. Commun. 2021, 12, 7022. (21) Chen, Y.;  Hou, Y.-F.;  Isayev, O.; Dral, P. O., Universal and Updatable Artificial Intelligence-Enhanced Quantum Chemical Foundational Models. ChemRxiv (accessed 2024-11-29). Submission date: 2024-06-26. 2024. (22) Zheng, P.;  Yang, W.;  Wu, W.;  Isayev, O.; Dral, P. O., Toward Chemical Accuracy in Predicting Enthalpies of Formation with General-Purpose Data-Driven Methods. J. Phys. Chem. Lett. 2022, 13, 3479–3491. (23) Chen, Y.; Dral, P. O., AIQM2: Organic Reaction Simulations Beyond DFT. ChemRxiv (accessed 2025-04-22). Submission date: 2024-10-08. 2024. (24) Anstine, D.;  Zubatyuk, R.; Isayev, O., AIMNet2: A Neural Network Potential to Meet your Neutral, Charged, Organic, and Elemental-Organic Needs. ChemRxiv 2023. (25) Zhang, S.;  Makoś, M.;  Jadrich, R.;  Kraka, E.;  Barros, K.;  Nebgen, B.;  Tretiak, S.;  Isayev, O.;  Lubbers, N.;  Messerly, R.; Smith, J. S., Exploring the frontiers of condensed-phase chemistry with a general reactive machine learning potential. Nat. Chem. 2024. (26) Smith, J. S.;  Nebgen, B. T.;  Zubatyuk, R.;  Lubbers, N.;  Devereux, C.;  Barros, K.;  Tretiak, S.;  Isayev, O.; Roitberg, A. E., Approaching coupled cluster accuracy with a general-purpose neural network potential through transfer learning. Nat. Commun. 2019, 10, 2903. (27) Devereux, C.;  Smith, J. S.;  Huddleston, K. K.;  Barros, K.;  Zubatyuk, R.;  Isayev, O.; Roitberg, A. E., Extending the Applicability of the ANI Deep Learning Molecular Potential to Sulfur and Halogens. J. Chem. Theory Comput. 2020, 16, 4192–4202. (28) Alavi, S. F.;  Chen, Y.;  Hou, Y.-F.;  Ge, F.;  Zheng, P.; Dral, P. O., ANI-1ccx-gelu Universal Interatomic Potential and Its Fine-Tuning: Toward Accurate and Efficient Anharmonic Vibrational Frequencies. J. Phys. Chem. Lett. 2025, 16, 483–493. (29) Chen, Y.; Dral, P. O., All-in-one foundational models learning across quantum chemical levels. ChemRxiv 2024. (30) Martyka, M.;  Tong, X.-Y.;  Jankowska, J.; Dral, P. O., OMNI-P2x: A Universal Neural Network Potential for Excited-State Simulations. ChemRxiv 2025. (31) Bai, J.;  Bai, S.;  Chu, Y.;  Cui, Z.;  Dang, K.;  Deng, X.;  Fan, Y.;  Ge, W.;  Han, Y.;  Huang, F.;  Hui, B.;  Ji, L.;  Li, M.;  Lin, J.;  Lin, R.;  Liu, D.;  Liu, G.;  Lu, C.;  Lu, K.;  Ma, J.;  Men, R.;  Ren, X.;  Ren, X.;  Tan, C.;  Tan, S.;  Tu, J.;  Wang, P.;  Wang, S.;  Wang, W.;  Wu, S.;  Xu, B.;  Xu, J.;  Yang, A.;  Yang, H.;  Yang, J.;  Yang, S.;  Yao, Y.;  Yu, B.;  Yuan, H.;  Yuan, Z.;  Zhang, J.;  Zhang, X.;  Zhang, Y.;  Zhang, Z.;  Zhou, C.;  Zhou, J.;  Zhou, X.; Zhu, T., Qwen Technical Report. arXiv:2309.16609v1 [cs.CL] 2023. 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 17 of 18  (32) Xu, L.;  Xie, H.;  Qin, S. J.;  Tao, X.; Wang, F. L., Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment. ArXiv 2023, abs/2312.12148. (33) Wan, Z.;  Wang, X.;  Liu, C.;  Alam, S.;  Zheng, Y.;  Liu, J.;  Qu, Z.;  Yan, S.;  Zhu, Y.;  Zhang, Q.;  Chowdhury, M.; Zhang, M., Efficient Large Language Models: A Survey. ArXiv 2023, abs/2312.03863. (34) Hu, J. E.;  Shen, Y.;  Wallis, P.;  Allen-Zhu, Z.;  Li, Y.;  Wang, S.; Chen, W., LoRA: Low-Rank Adaptation of Large Language Models. ArXiv 2021, abs/2106.09685. (35) Ma, W.;  Wu, D.;  Sun, Y.;  Wang, T.;  Liu, S.;  Zhang, J.;  Xue, Y.; Liu, Y., Combining Fine-Tuning and LLM-based Agents for Intuitive Smart Contract Auditing with Justifications. ArXiv 2024, abs/2403.16073. (36) Rui, Y.;  Chen, Y.;  Ivanova, E.;  Kumar, V. B.;  Smiga, S.;  Grabowski, I.; Dral, P. O., The Best DFT Functional Is the Ensemble of Functionals. Adv. Sci. 2024, 11, 2408239. (37) Hou, Y. F.;  Zhang, L.;  Zhang, Q.;  Ge, F.; Dral, P. O., Physics-informed active learning for accelerating quantum chemical simulations. J. Chem. Theory Comput. 2024, 20, 7744–7754. (38) Ramakrishnan, R.;  Dral, P. O.;  Rupp, M.; von Lilienfeld, O. A., Big Data Meets Quantum Chemistry Approximations: The Δ-Machine Learning Approach. J. Chem. Theory Comput. 2015, 11, 2087–2096. (39) Ge, F.;  Zhang, L.;  Hou, Y.-F.;  Chen, Y.;  Ullah, A.; Dral, P. O., Four-Dimensional-Spacetime Atomistic Artificial Intelligence Models. J. Phys. Chem. Lett. 2023, 14, 7732–7743. See also the preprint version at ChemRxiv, https://doi.org/10.26434/chemrxiv-2022-qf75v. (40) Hou, Y.-F.;  Wang, C.; Dral, P. O., Accurate and Affordable Simulation of Molecular Infrared Spectra with AIQM Models. J. Phys. Chem. A 2025, ASAP. (41) Zhang, L.;  Hou, Y.-F.;  Ge, F.; Dral, P. O., Energy-conserving molecular dynamics is not energy conserving. Phys. Chem. Chem. Phys. 2023, 25, 23467–23476. (42) Xue, B.-X.;  Barbatti, M.; Dral, P. O., Machine Learning for Absorption Cross Sections. J. Phys. Chem. A 2020, 124, 7199–7210. (43) Zhang, L.;  Pios, S. V.;  Martyka, M.;  Ge, F.;  Hou, Y. F.;  Chen, Y.;  Chen, L.;  Jankowska, J.;  Barbatti, M.; Dral, P. O., MLatom Software Ecosystem for Surface Hopping Dynamics in Python with Quantum Mechanical and Machine Learning Methods. J. Chem. Theory Comput. 2024, 20, 5043–5057. (44) Martyka, M.;  Zhang, L.;  Ge, F.;  Hou, Y.-F.;  Jankowska, J.;  Barbatti, M.; Dral, P. O., Charting electronic-state manifolds across molecules with multi-state learning and gap-driven dynamics via efficient and robust active learning. npj Comput. Mater. 2024, accepted. (45) Su, Y.;  Dai, Y.;  Zeng, Y.;  Wei, C.;  Chen, Y.;  Ge, F.;  Zheng, P.;  Zhou, D.;  Dral, P. O.; Wang, C., Interpretable Machine Learning of Two‐Photon Absorption. Adv. Sci. 2023, 2204902. (46) Gao, Y.;  Xiong, Y.;  Gao, X.;  Jia, K.;  Pan, J.;  Bi, Y.;  Dai, Y.;  Sun, J.;  Guo, Q.;  Wang, M.; Wang, H., Retrieval-Augmented Generation for Large Language Models: A Survey. ArXiv 2023, abs/2312.10997. (47) Zhao, P.;  Zhang, H.;  Yu, Q.;  Wang, Z.;  Geng, Y.;  Fu, F.;  Yang, L.;  Zhang, W.;  Jiang, J.; Cui, B., Retrieval-Augmented Generation for AI-Generated Content: A Survey. 2024. (48) Jeong, S.;  Baek, J.;  Cho, S.;  Hwang, S. J.; Park, J. C., Adaptive-rag: Learning to adapt retrieval-augmented large language models through question complexity. arXiv preprint arXiv:2403.14403 2024. (49) Wang, L. P.; Song, C., Geometry optimization made simple with translation and rotation coordinates. J. Chem. Phys. 2016, 144, 214108. (50) Neese, F., Software update: the ORCA program system, version 4.0. Wiley Interdiscip. Rev. Comput. Mol. Sci. 2018, 8, e1327. (51) Neese, F., The ORCA program system. Wiley Interdiscip. Rev. Comput. Mol. Sci. 2012, 2, 73–78. (52) Thiel, W., with contributions from M. Beck, S. Billeter, R. Kevorkiants, M. Kolb, A. Koslowski, S. Patchkovskii, A. Turner, E.-U. Wallenborn, W. Weber, L. Spörkel, and P. O. Dral MNDO, development version, Max-Planck-Institut für Kohlenforschung, Mülheim an der Ruhr, 2019. (53) Semiempirical extended tight-binding program package xtb. https://github.com/grimme-lab/xtb  (accessed on Nov. 19, 2022). 

Hu, Nawaz, Rui, Chi, Ullah, Dral Aitomia 08.05.2025 
Page 18 of 18  (54) Caldeweyher, E.;  Ehlert, S.; Grimme, S. DFT-D4, Version 2.5.0, Mulliken Center for Theoretical Chemistry, University of Bonn, 2020. (55) Gao, X.;  Ramezanghorbani, F.;  Isayev, O.;  Smith, J. S.; Roitberg, A. E., TorchANI: A Free and Open Source PyTorch-Based Deep Learning Implementation of the ANI Neural Network Potentials. J. Chem. Inf. Model. 2020, 60, 3408–3415. (56) mace on https://github.com/ACEsuit/mace. (57) Chmiela, S.;  Sauceda, H. E.;  Poltavsky, I.;  Müller, K.-R.; Tkatchenko, A., sGDML: Constructing accurate and data efficient molecular force fields using machine learning. Comput. Phys. Commun. 2019, 240, 38–45. (58) Unke, O. T.; Meuwly, M., PhysNet: A Neural Network for Predicting Energies, Forces, Dipole Moments, and Partial Charges. J. Chem. Theory Comput. 2019, 15, 3678–3693. (59) Wang, H.;  Zhang, L.;  Han, J.; E, W., DeePMD-kit: A deep learning package for many-body potential energy representation and molecular dynamics. Comput. Phys. Commun. 2018, 228, 178–184. (60) Hjorth Larsen, A.;  Jorgen Mortensen, J.;  Blomqvist, J.;  Castelli, I. E.;  Christensen, R.;  Dulak, M.;  Friis, J.;  Groves, M. N.;  Hammer, B.;  Hargus, C.;  Hermes, E. D.;  Jennings, P. C.;  Bjerre Jensen, P.;  Kermode, J.;  Kitchin, J. R.;  Leonhard Kolsbjerg, E.;  Kubal, J.;  Kaasbjerg, K.;  Lysgaard, S.;  Bergmann Maronsson, J.;  Maxson, T.;  Olsen, T.;  Pastewka, L.;  Peterson, A.;  Rostgaard, C.;  Schiotz, J.;  Schutt, O.;  Strange, M.;  Thygesen, K. S.;  Vegge, T.;  Vilhelmsen, L.;  Walter, M.;  Zeng, Z.; Jacobsen, K. W., The atomic simulation environment-a Python library for working with atoms. J. Phys. Condens. Matter. 2017, 29, 273002. (61) Dral, P. O.;  Chen, Y.; Li, J. Aitomic: A package for AI-enhanced atomistic simulations, Aitomistic, Shenzhen, China, http://MLatom.com/aitomic (accessed April 10, 2025), 2025.   