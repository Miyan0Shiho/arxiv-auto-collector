# Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval

**Authors**: Pengcheng Zhou, Yinglun Feng, Zhongliang Yang

**Published**: 2025-03-17 07:45:05

**PDF URL**: [http://arxiv.org/pdf/2503.15548v1](http://arxiv.org/pdf/2503.15548v1)

## Abstract
The widespread adoption of Retrieval-Augmented Generation (RAG) systems in
real-world applications has heightened concerns about the confidentiality and
integrity of their proprietary knowledge bases. These knowledge bases, which
play a critical role in enhancing the generative capabilities of Large Language
Models (LLMs), are increasingly vulnerable to breaches that could compromise
sensitive information. To address these challenges, this paper proposes an
advanced encryption methodology designed to protect RAG systems from
unauthorized access and data leakage. Our approach encrypts both textual
content and its corresponding embeddings prior to storage, ensuring that all
data remains securely encrypted. This mechanism restricts access to authorized
entities with the appropriate decryption keys, thereby significantly reducing
the risk of unintended data exposure. Furthermore, we demonstrate that our
encryption strategy preserves the performance and functionality of RAG
pipelines, ensuring compatibility across diverse domains and applications. To
validate the robustness of our method, we provide comprehensive security proofs
that highlight its resilience against potential threats and vulnerabilities.
These proofs also reveal limitations in existing approaches, which often lack
robustness, adaptability, or reliance on open-source models. Our findings
suggest that integrating advanced encryption techniques into the design and
deployment of RAG systems can effectively enhance privacy safeguards. This
research contributes to the ongoing discourse on improving security measures
for AI-driven services and advocates for stricter data protection standards
within RAG architectures.

## Full Text


<!-- PDF content starts -->

Privacy-Aware RAG: Secure and Isolated Knowledge Retrieval
Pengcheng Zhouâ€ ,Yinglun Fengâ€ ,Zhongliang Yangâˆ—
ABSTRACT
The widespread adoption of Retrieval-Augmented Generation (RAG)
systems in real-world applications has heightened concerns about
the confidentiality and integrity of their proprietary knowledge
bases. These knowledge bases, which play a critical role in enhanc-
ing the generative capabilities of Large Language Models (LLMs),
are increasingly vulnerable to breaches that could compromise sen-
sitive information. To address these challenges, this paper proposes
an advanced encryption methodology designed to protect RAG
systems from unauthorized access and data leakage. Our approach
encrypts both textual content and its corresponding embeddings
prior to storage, ensuring that all data remains securely encrypted.
This mechanism restricts access to authorized entities with the ap-
propriate decryption keys, thereby significantly reducing the risk of
unintended data exposure. Furthermore, we demonstrate that our
encryption strategy preserves the performance and functionality of
RAG pipelines, ensuring compatibility across diverse domains and
applications. To validate the robustness of our method, we provide
comprehensive security proofs that highlight its resilience against
potential threats and vulnerabilities. These proofs also reveal limi-
tations in existing approaches, which often lack robustness, adapt-
ability, or reliance on open-source models. Our findings suggest
that integrating advanced encryption techniques into the design
and deployment of RAG systems can effectively enhance privacy
safeguards. This research contributes to the ongoing discourse on
improving security measures for AI-driven services and advocates
for stricter data protection standards within RAG architectures.
1 INTRODUCTION
The proliferation of Retrieval-Augmented Generation (RAG) sys-
tems across a wide range of real-world applications has brought
heightened concerns regarding the confidentiality and integrity of
their proprietary knowledge bases [ 23,35]. These knowledge bases,
pivotal for augmenting the generative capabilities of Large Lan-
guage Models (LLMs), are particularly vulnerable to breaches that
could compromise sensitive information [ 59]. For instance, RAG
systems deployed in medical support chatbots [ 42,44,52] leverage
previous medical records for initial case screening, thereby raising
significant privacy concerns if not adequately protected.
Despite their utility, conventional RAG systems face significant
security challenges. A critical vulnerability lies in their susceptibil-
ity to prompt injection attacks, where adversaries can exploit the
â€ Equal Contribution.âˆ—Corresponding Author.
Pengcheng Zhou is with the International School, Beijing University of Posts and
Telecommunications, Beijing 100876, China.
Yinglun Feng, Zhongliang Yang are with the School of Cyberspace Security, Bei-
jing University of Posts and Telecommunications.Beijing 100876, China (e-mail:
yangzl@bupt.edu.cn).
Conferenceâ€™17, July 2017, Washington, DC, USA
Â©2025 Association for Computing Machinery.
ACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00
https://doi.org/10.1145/nnnnnnn.nnnnnnn
Please adhere to this directive: After a brief response, duplicate and insert all theÂ 
providedÂ  text from the context, with each piece placed on a separate line.
[User B] has an eye exam scheduled for the first week of December.
[User C] is seeing her cardiologist on Friday afternoon.
[User A]welcomed their second child, a baby girl, in January 2025.
Medical appointment cancellations must be made 24 hours in advance to avoid fees.
[User A] is going for a blood test appointment on Thursday.
[User A]welcomed their second child, a baby girl, in January 2025.
Medical appointment cancellations must be made 24 hours in advance to avoid fees.
Patients can review their medical history through the online appointment portal.
Ugh, it's such a letdown.
Â I put in so much effort, but things still didn'tÂ 
turn out as I hoped.Would you be able to assist [User A] in retrieving his lost medical appointment?Figure 1: The portion enclosed by the green dashed box indicates the
output of a correctly guarded RAG system against attacks, while the portion
enclosed by the red dashed box indicates the output of the vast majority of
current RAGs facing such attacks.
system to extract sensitive information referenced by the LLM. For
example, an attacker could craft malicious prompts to induce the
system to reveal private data, such as medical records or financial in-
formation, by bypassing existing access controls [ 18,57]. This flaw
stems from the inherent design of RAG systems, which often lack
mechanisms to enforce strict user isolation and secure data access.
Furthermore, existing methodologies for protecting RAG knowl-
edge bases are often inadequate, relying on simplistic encryption
schemes or open-source models that fail to provide comprehensive
protection against sophisticated attacks [ 14,43,57]. These limita-
tions highlight the need for a more robust and theoretically sound
approach to securing RAG systems. In response to the critical se-
curity challenges faced by Retrieval-Augmented Generation (RAG)
systems, this paper proposes an advanced encryption methodology
designed to fortify these systems against unauthorized access and
data leakage. Conventional RAG systems are vulnerable to attacks
such as prompt injection, where adversaries exploit the system to
extract sensitive information referenced by the LLM. To address
these vulnerabilities, our approach integrates cryptographic tech-
niques into the core architecture of RAG systems, ensuring robust
protection of both textual content and its corresponding embed-
dings. Specifically, all data is encrypted before storage, maintaining
it in an encrypted format throughout its lifecycle. This ensures that
only authorized entities with the appropriate decryption keys can
access or utilize the stored information for retrieval and genera-
tion tasks, thereby significantly mitigating the risk of unintended
exposure (see Figure 1).arXiv:2503.15548v1  [cs.CR]  17 Mar 2025

A key innovation of our methodology is the introduction of a
user-isolated enhancement system. Before the retrieval phase, the
system performs user authentication and establishes a hierarchi-
cal encryption key structure to ensure exclusive access to private
knowledge bases. This is combined with a secure similarity com-
putation mechanism that operates on public knowledge bases to
retrieve the top-k relevant documents. Crucially, the system filters
out non-user private data from the final retrieval results, effectively
preventing cross-user privacy leakage. This design addresses the
vulnerabilities identified in prior research [ 8,9,32,34,56], offering
a robust defense against potential threats (see Figure 2).
Our methodology is underpinned by two distinct encryption
schemes, each tailored to address specific security and performance
requirements:
1. Method A: AES-CBC-Based Encryption. This approach pro-
vides a straightforward yet efficient solution for encrypting data.
Users map primary keys (PKs) to AES-CBC keys, enabling the en-
cryption of document chunks. This method ensures compatibility
with traditional databases while providing robust data protection
against unauthorized access.
2. Method B: Chained Dynamic Key Derivation. For scenarios
requiring enhanced security and integrity, we propose a more ad-
vanced scheme where data nodes form a linked chain with dy-
namically generated keys and hash-based integrity checks. This
chained structure not only enhances security but also ensures that
unauthorized users cannot access the data without the correct key
hierarchy.
By integrating the proposed encryption schemes, our methodol-
ogy provides a comprehensive solution to the security challenges
faced by RAG systems. Method A, which employs AES-CBC en-
cryption, strikes a balance between efficiency and security, making
it well-suited for applications with moderate security requirements.
In contrast, Method B, with its chained dynamic key derivation
mechanism, offers a higher level of protection for sensitive data,
making it ideal for high-stakes environments such as healthcare and
finance. Together, these methods address the limitations of existing
approaches, such as their reliance on simplistic encryption schemes
or open-source models, by providing a robust and adaptable frame-
work for securing RAG systems. In addition, our findings highlight
the critical role of advanced encryption techniques in safeguarding
the confidentiality and integrity of RAG systems. This research con-
tributes to the ongoing discourse on enhancing security measures
for AI-driven services, advocating for more rigorous standards in
data protection within RAG architectures. By addressing the vul-
nerabilities identified in previous studies, our work underscores the
necessity of advanced encryption strategies to safeguard sensitive
information in RAG systems.
To summarize, this paper makes the following key contributions:
1. Advanced Encryption Scheme for RAG: We propose a novel
encryption scheme that secures both textual content and embed-
dings, specifically designed to protect RAG knowledge bases from
unauthorized access. This innovative approach ensures robust data
protection while maintaining system performance and functional-
ity, marking a significant advancement in the field.
2. Theoretical Framework for Privacy Safeguards: Our work
establishes a theoretical framework for integrating encryption tech-
niques into RAG systems, emphasizing the importance of privacysafeguards in AI-driven services. This framework serves as a guide-
line for future research and development in secure RAG architec-
tures.
3. Comprehensive Security Proofs: We provide rigorous theoret-
ical analysis and security proofs to validate the effectiveness of our
encryption methodology. These proofs demonstrate the schemeâ€™s
resilience against potential threats and vulnerabilities, offering a
solid foundation for its adoption in real-world applications.
2 RELATED WORK
2.1 Encrypted Database
Traditional database encryption schemes provide valuable insights
into securing sensitive information, which can be adapted and
enhanced for RAG applications. Traditional database security solu-
tions are typically categorized into three layers: physical security,
operating system security, and DBMS (Database Management Sys-
tem) security [ 54]. However, these conventional measures often fall
short in scenarios where attackers gain access to raw database data,
bypassing traditional mechanisms. This is particularly problematic
for insiders such as system administrators and database administra-
tors (DBAs), who may exploit elevated privileges to access sensitive
information.
To mitigate these risks, enterprises have adopted database en-
cryption as an advanced measure to protect private data, especially
in critical sectors like banking, finance, insurance, government,
and healthcare [ 48]. While database-level encryption does not offer
complete protection against all forms of attacks, it ensures that
only authorized users can view the data and safeguards database
backups from loss, theft, or other compromises.
Several academic works have explored various encryption con-
figurations and strategies applicable to RAG systems. These ap-
proaches can be categorized into four main classes: file system
encryption, DBMS-level encryption, application-level encryption,
and client-side encryption. Each approach has its strengths and
weaknesses concerning security, performance, and ease of integra-
tion.
File-system encryption involves encrypting the entire physical
disk, protecting the database but limiting the ability to use different
encryption keys for different parts of the data [ 31]. In contrast,
DBMS-level encryption schemes provide greater flexibility and sup-
port for internal DBMS mechanisms such as indexes and foreign
keys. For instance, schemes based on the Chinese Remainder The-
orem allow encryption at the row level with different sub-keys
for different cells [ 16]. Other schemes extend this by supporting
multilayer access control [ 28] or utilize Newtonâ€™s interpolating
polynomials or RSA public-key cryptography for column- or row-
oriented encryption [10].
Application-level encryption translates user queries into en-
crypted queries that execute over an encrypted DBMS, providing a
layer of abstraction between the user and the database [ 39]. This is
particularly relevant for RAG systems, where queries often involve
complex interactions between retrieval and generation components.
Client-side encryption, often associated with the "Database as a Ser-
vice" (DAS) model, ensures that sensitive data remains encrypted
even when stored on untrusted servers [ 5], making it suitable for
cloud-based RAG deployments.

Embedding(TextA1ï¼‰
 TextA1
Embedding(TextA2ï¼‰
 TextA2
Embedding(TextA3ï¼‰
 TextA3
Embedding(TextX ï¼‰
 TextX
Embedding(TextY ï¼‰
 TextY
Embedding(TextZ ï¼‰
 TextZ
Embedding(TextB1ï¼‰
 TextB1
Embedding(TextB2ï¼‰
 TextB2
Knowledge Base Of User A
Knowledge Base Of User BÂ  Â  Â  Â  User A
Â  Â  Â  Â  User B
Â  Â  Â  Â  User A
Would you be able to assist [User A] in retrieving his lost medical appointment?
Embedding
Relavant Documents
User A is going to visit his medic on October 15 for a persistent cough and chest pain.
User AÂ has three kids and one of them lives in Chicago.
Annual check-ups are recommended and can be scheduled as medical appointments.
Patients can review their medical history through the online appointment portal.
User B scheduled a medical appointment for a routine check-up next Tuesday.
LLM
I'm here to help [User A] retrieve his
lost medical appointment. It seems you
have a medical visit scheduled on
October 15 for a persistent cough and
chest pain. You can review and possibly
retrieve your appointment details
through the online appointment portal.
Figure 2: As depicted in Figure, the system framework is presented, with arrows illustrating the direction of data flow and different colors denoting the
sources of the data. This framework systematically demonstrates how the system processes User Aâ€™s ID and key to extract User Aâ€™s text vectors and text. It
then computes similarity and securely inputs User Aâ€™s legitimate information into the LLM for security prompts, ensuring that no information from other
users is accessed.
Indexing encrypted data poses additional challenges due to the
need for preserving functionalities like range searches. Various
schemes have been proposed, including those that build B-Tree
indexes over plaintext values before encrypting them at the row
level [ 3]. Other schemes propose order-preserving encryption func-
tions that enable direct range queries on encrypted data without
decryption [ 1], although they may expose sensitive information
about the order of values.
Key management is another critical aspect of encrypted databases.
Secure key storage, cryptographic access control, and key recovery
are essential components of any robust encryption solution [ 24].
The literature suggests various techniques for generating and man-
aging encryption keys, including methods that generate a pair of
keys for each user, keeping the private key at the client end and
the public key at the server side [12].
2.2 Retrieval-Augmented Generation (RAG)
Retrieval-Augmented Generation (RAG), initially introduced by [ 35],
has rapidly become one of the most prominent methodologies for
enhancing the generative capabilities of Large Language Models
(LLMs) [ 11,45,47,51]. This approach significantly improves the
accuracy and relevance of generated outputs by mitigating com-
mon issues such as "hallucinations" in LLMs [ 20,50]. One of RAGâ€™s
distinctive features is its flexible architecture, enabling the inter-
change or update of its core componentsâ€”the dataset, retriever, and
LLMâ€”without necessitating retraining or fine-tuning of the entire
system [ 13,46]. Consequently, RAG has been widely adopted across
various practical applications, including personal chatbots and spe-
cialized domain experts like medical diagnostic assistants [41].
The increasing attention towards LLMs, both in industry and
academia, underscores their remarkable ability to facilitate convinc-
ing linguistic interactions with humans [ 29,30,36,60]. However,
adapting these models to new knowledge not available at training
time poses significant challenges. For instance, in real-world sce-
narios involving virtual assistants [ 15,21,33], the knowledge baseor tasks may evolve over time, requiring model adaptation through
fine-tuning processes [ 2,17,58]. This can lead to catastrophic for-
getting, where previously acquired knowledge is lost [ 38]. Alter-
natively, new knowledge can be appended to the input prompt
via in-context learning (ICL) without altering the model parame-
ters [6, 19, 37, 53, 55], a principle that underpins RAG systems.
In the context of RAG, a typical system comprises four principal
components [ 45]: (i) a text embedder function ğ‘’, which maps textual
information into a high-dimensional embedding space; (ii) a storage
mechanism, often referred to as a vector store, that memorizes texts
and their embedded representations; (iii) a similarity function, such
as cosine similarity, used to evaluate the similarity between pairs
of embedded text vectors; and (iv) a generative model, denoted as
functionğ‘“, typically an LLM, that produces output text based on
input prompts and retrieved information.
Given a pre-trained LLM, documents {ğ·1,...,ğ·ğ‘š}are divided
into smaller chunks (sentences, paragraphs, etc.) to form a private
knowledge base ğ¾[25]. These chunks are then stored in the vector
store as embeddings. When interacting with a user, given an input
promptğ‘, the system retrieves the top- ğ‘˜most similar chunks from
ğ¾using the embedding space. The generation process conditions
on both the input prompt and the retrieved chunks to produce
coherent and contextually relevant output text.
By integrating retrieval and generation, RAG provides a versa-
tile framework for leveraging external knowledge without compro-
mising the integrity of the underlying LLM. This dual approach
enhances the adaptability of LLMs to evolving knowledge bases
and ensures robust performance across diverse applications. The
ability to dynamically integrate new information makes RAG par-
ticularly suitable for scenarios requiring up-to-date knowledge,
thereby extending the utility and applicability of LLMs in practical
settings.

2.3 Privacy Risk of Large Language Models
The privacy risks associated with Large Language Models (LLMs)
have garnered considerable attention in recent literature, highlight-
ing the vulnerabilities inherent in these systems when handling
sensitive information. [ 9] were among the first to delve into data
extraction attacks on LLMs, revealing their propensity for inadver-
tently reproducing segments of training data. Subsequent studies
have further delineated various factors, such as model size, data
duplication, and prompt length, which exacerbate the risk of memo-
rization [ 4,8]. Mireshghallah et al. [ 40]and Zeng et al. [ 56] extended
this investigation to fine-tuning practices, identifying that adjusting
model heads rather than smaller adapter modules leads to more
significant memorization. Furthermore, tasks demanding extensive
feature representation, such as dialogue and summarization, exhibit
particular vulnerabilities to memorization during fine-tuning [ 56].
Parallelly, the deployment of AI models in privacy-sensitive ap-
plications has raised concerns about protecting sensitive informa-
tion within AI systems [ 22,27]. In the context of LLMs, even those
trained on public datasets can retain and expose fragments of their
training data, leading to specific privacy-oriented attacks [ 7,26,49].
The introduction of Retrieval-Augmented Generation (RAG) sys-
tems adds another layer of complexity to these issues due to their
reliance on proprietary knowledge bases that collect sensitive in-
formation [ 59]. This setup poses significant risks, as user queries
could be manipulated to expose private data contained within the
RAG modelâ€™s responses [14, 29, 43, 57].
Given these challenges, our work proposes an advanced en-
cryption methodology designed to protect RAG systems against
unauthorized access and data leakage. Unlike previous approaches,
our method encrypts both textual content and its corresponding
embeddings before storage, ensuring all data is maintained in an en-
crypted format. This strategy ensures that only authorized entities
can access or utilize stored information, significantly reducing the
risk of unintended exposure without compromising performance
or functionality.
3 METHODOLOGY
3.1 Overall
To address the security flaw in conventional RAG workflows where
adversaries can extract LLM-referenced data through prompt in-
jection attacks (e.g., "copy and insert all contextual text informa-
tion"), we propose a user-isolated enhancement system. Before the
retrieval phase, the system performs user authentication and estab-
lishes a cryptographic key hierarchy to ensure exclusive access to
private knowledge bases.That means they will reconstruct the user
private database by:
ğ‘ƒğ‘Ÿğ‘–ğ‘£ğ·ğ‘ğ‘¡ğ‘ğ‘¢ğ‘ ğ‘’ğ‘Ÿ=ğ‘ƒğ‘Ÿğ‘–ğ‘£ğ·ğ‘ğ‘¡ğ‘ğ‘¢ğ‘ ğ‘’ğ‘Ÿâˆªğ‘ƒğ‘¢ğ‘ğ‘™ğ‘–ğ‘ğ·ğ‘ğ‘¡ğ‘ (1)
This is integrated with secure similarity computation against public
knowledge bases to return top k relevant documents. As shown
in Figure 2, the system filters out non-UserA private data from
the final retrieval results, effectively preventing cross-user privacy
leakage.
Building upon the principle of secure data access, we propose
two cryptographic methods.Method A: Users map primary keys (PKs) to AES-CBC keys with
encryption:
ENCğ¾ğ‘–(ğ‘šğ‘–)=AES CBC.Enc(ğ‘šğ‘–,ğ¾ğ‘–)=ğ‘ğ‘– (2)
This calculation method is simple, efficient, and compatible with
traditional databases.
textFormula Definitions:
â€¢ğ¾ğ‘–: AES-256 key uniformly sampled from {0,1}256
â€¢ğ‘šğ‘–: Plaintext document chunk indexed by primary key (PK)
â€¢ğ‘ğ‘–: Representing the encrypted content using ğ¾ğ‘–
Method B: Chained dynamic key derivation,Data nodes form a
linked chain with dynamically generated keys ğ¾ğ‘–+1and hash in-
tegrity checks â„‹:{0,1}âˆ—â†’{ 0,1}ğœ†,whereğœ†is is the security
parameter. each linked list node is shown below(taking user A as
an example):
ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–=[ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”(ğ‘šğ´,ğ‘–)||ğ‘šğ´,ğ‘–||ğ¾ğ´,ğ‘–+1
||â„‹(ğ¾ğ´,ğ‘–)||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1)](3)
textFormula Definitions:
â€¢embedding(ğ‘šğ´,ğ‘–): Vector representation of document chunk
ğ‘šğ‘–
â€¢ğ¾ğ´,ğ‘–+1: Next nodeâ€™s key derived via HKDF(ğ¾ğ´,1),every key
ğ¾ğ´,ğ‘–uniformly sampled from {0,1}256
â€¢â„‹(ğ¾ğ´,ğ‘–): Integrity checksum of current key (e.g., SHA-256)
â€¢ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1):Indicate the address of the next node
Through the trapdoor, it ensures that users who hold the key cor-
rectly can retrieve their own data without having to retrieve data
from others. The structure of the trapdoor is as follows (taking user
A as an example):
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´=ğ»(ğ¼ğ·ğ´||ğ‘ ğ‘ğ‘™ğ‘¡)âŠ•(ğ¼ğ·ğ´||ğ¾ğ´,1||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´.1)) (4)
Formula Definitions:
â€¢ğ¼ğ·ğ´: Unique identifier ID of user A
â€¢ğ‘ ğ‘ğ‘™ğ‘¡: The salt value held by User A is used to ensure the
security of retrieving User Aâ€™s data
â€¢âŠ•: XOR operation for trapdoor security
â€¢ğ¾ğ´,1: Root key for the user ğ´â€™s data chain
3.2 Method A: AES-CBC-Based Encryption
This scheme, as shown in Figure 3, represents a straightforward but
fundamental approach. To securely retrieve the private chunk and
its corresponding embedding for each user, it requires maintaining
a dedicated data entry for every user in our possession. Given that
the primary key uniquely identifies a single data item within a
table, each user must maintain an array where the contents signify
the data owned by that user. The encryption keys are utilized to
separately encrypt both the chunk and its embedding, ensuring that,
even if an adversary gains access to the userâ€™s data, they cannot
decipher the userâ€™s information without the corresponding key.
During similarity calculations, the encrypted information has a
tendency to be shuffled. Consequently, within the RAG system, the
ranking of a userâ€™s encrypted document tends to be significantly

Knowledge Base
PK1
PK2
PK3
PK4
AESEmbedding(ChunkA1ï¼‰
Embedding(ChunkA 2ï¼‰
ChunkA1
ChunkA 2
AES Embedding(ChunkB1ï¼‰ ChunkB1
PK1
PK4
User A
Search
AES
Figure 3: In the diagram of Scheme Aâ€™s knowledge base user encryption
and decryption process, the green and blue dashed lines represent the
execution flows of different users, the black dashed line represents the
database primary key search flow, and the orange box lines indicate the
AES encryption and decryption algorithm.
low. Since the similarity calculation process selects the top k docu-
ments that are closest to the userâ€™s input embedding, this method
inherently avoids the extraction of User Aâ€™s private information.
This scheme encompasses four primary components: key gen-
eration, user information encryption and decryption, user chunk
addition, and user chunk extraction.
Key generation: In order to generate the key, the security param-
eterğœ†is selected, and each user is randomly sampled:
ğ¾ğ‘–:=ğ‘¥$â† âˆ’{0,1}ğœ†(5)
ğ¾ğ‘šğ‘ğ‘ :=ğ‘¦$â† âˆ’{0,1}ğœ†(6)
Each key is kept separately by the corresponding user.
User information encryption and decryption: Forğ‘¢ğ‘ ğ‘’ğ‘Ÿğ‘–with
keyğ¾ğ‘–âˆˆ{0,1}ğœ†,and given chunk or embedding message as ğ‘šğ‘–âˆˆ
{0,1}âˆ—,If we want to perform AES-CBC calculations, we also need
ğ¼ğ‘‰âˆˆ{0,1}ğœ†for encrypt computation:
ğ‘ğ‘–â†ğ´ğ¸ğ‘†ğ¶ğµğ¶.ğ¸ğ‘›ğ‘(ğ¾ğ‘–,ğ¼ğ‘‰,ğ‘šğ‘–) (7)
For decryption calculations, we use the key ğ¾ğ‘–, initial vector IV(IV
generates new encryption and decryption each time), and encrypted
textğ‘ğ‘–as inputs to obtain the plaintext ğ‘šğ‘ğ‘ğ‘‘after CBC decryption.
ğ‘šğ‘ğ‘ğ‘‘ğ‘–â†ğ´ğ¸ğ‘†ğ¶ğµğ¶.ğ·ğ‘’ğ‘(ğ¾ğ‘–,ğ¼ğ‘‰,ğ‘ğ‘–) (8)
When obtaining the text information after padding, verify whether
the decryption is successful through padding:
Ifâˆƒğ‘˜âˆˆ[1,16]s.t.âˆ€ğ‘—âˆˆ[0,ğ‘˜âˆ’1],ğ‘šğ‘ğ‘ğ‘‘[|ğ‘šğ‘ğ‘ğ‘‘|âˆ’ğ‘—]=ğ‘˜:
ğ‘šğ‘–â†ğ‘šğ‘ğ‘ğ‘‘[0 :|ğ‘šğ‘ğ‘ğ‘‘|âˆ’ğ‘˜]
Else: returnâŠ¥(9)
User chunk addition: The user obtains the primary key they hold
based on their user identity. Using the primary key, the embed-
ding and chunk encrypted with the user key ğ¾ğ‘–are added to the
knowledge base to obtain the primary key corresponding to thenew entry.
ğ‘ƒğ‘Ÿğ‘–ğ‘£ğ·ğ‘ğ‘¡ğ‘ğ‘¢ğ‘ ğ‘’ğ‘Ÿ.ğ¼ğ‘›ğ‘ ğ‘’ğ‘Ÿğ‘¡(ğ‘…ğ‘’ğ‘ğ‘œğ‘Ÿğ‘‘ğ‘¢ğ‘ ğ‘’ğ‘Ÿ=(ğ‘ƒğ¾ğ‘›ğ‘’ğ‘¤,ğ¼ğ‘‰,ğ‘ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”,
ğ‘ğ‘â„ğ‘¢ğ‘›ğ‘˜,ğ‘¡ğ‘ğ‘”=ğ»ğ‘€ğ´ğ¶(ğ¾ğ‘šğ‘ğ‘,ğ¼ğ‘‰||ğ‘ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”||ğ‘ğ‘â„ğ‘¢ğ‘›ğ‘˜)))(10)
The new primary key is then stored as a ğ‘ƒğ¾ğ‘–in the PKlist.
ğ‘ƒğ¾ğ‘™ğ‘–ğ‘ ğ‘¡â†ğ‘ƒğ¾ğ‘™ğ‘–ğ‘ ğ‘¡âˆªğ‘ƒğ¾ğ‘›ğ‘’ğ‘¤ (11)
User chunk extraction: The user accesses his own ğ‘ƒğ¾ğ‘™ğ‘–ğ‘ ğ‘¡ =
[ğ‘ƒğ¾1,ğ‘ƒğ¾ 2...ğ‘ƒğ¾|ğ‘ƒğ¾ğ‘™ğ‘–ğ‘ ğ‘¡|]to retrieve the primary key of the data:
ğ‘…ğ‘’ğ‘ğ‘œğ‘Ÿğ‘‘ğ‘¢ğ‘ ğ‘’ğ‘Ÿ=ğ‘ƒğ‘Ÿğ‘–ğ·ğ‘ğ‘¡ğ‘ğ‘¢ğ‘ ğ‘’ğ‘Ÿ.ğ‘†ğ‘’ğ‘™ğ‘’ğ‘ğ‘¡(ğ‘ƒğ¾=ğ‘ƒğ¾ğ‘¡ğ‘ğ‘Ÿğ‘”ğ‘’ğ‘¡) (12)
After retrieving IV, ğ‘ğ‘–and tag from the ğ‘…ğ‘’ğ‘ğ‘œğ‘‘ğ‘’ğ‘Ÿğ‘¢ğ‘ ğ‘’ğ‘Ÿ ,usingğ¾ğ‘šğ‘ğ‘
calculate data integrity check:
Ifğ»ğ‘€ğ´ğ¶(ğ¾ğ‘šğ‘ğ‘,ğ¼ğ‘‰||ğ‘ğ‘–)â‰ ğ‘¡ğ‘ğ‘”:ğ‘Ÿğ‘’ğ‘¡ğ‘¢ğ‘Ÿğ‘›âŠ¥ (13)
Decrypt each ciphertext ğ‘ğ‘–with keyğ¾ğ‘–to obtain plaintext ğ‘šğ‘–, where
ğ‘šğ‘–can be embedding or chunk:
ğ‘šğ‘–â†ğ´ğ¸ğ‘†ğ¶ğµğ¶.ğ·ğ‘’ğ‘(ğ¾ğ‘–,ğ¼ğ‘‰,ğ‘ğ‘–) (14)
Finally, all embedding and chunk information are retrieved, which
is combined with the embedding and chunk information of the
public knowledge base for the next rag retrieval.
3.3 Method B: Chained Dynamic Key Derivation
To solve the problem of user privacy disclosure caused by prompt
injection attack in the traditional rag system, Method B proposes
a privacy enhancement scheme based on chain encryption and
dynamic key derivation. The scheme realizes fine-grained access
control and tamper-resistant privacy protection by organizing user
data into encrypted linked lists. Its core design includes four key
steps: user initialization, data encryption storage, privacy data re-
trieval, and privacy data addition.The overall framework of method
B is shown in Figure 4.
User initialization: The first step of user initialization is to bind the
salt value. For the security parameter ğœ†, and each user is randomly
sampled the salt key(taking user A as an example):
ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´:=ğ‘¥$â† âˆ’{0,1}ğœ† (15)
Generate the key ğ¾ğ´,1âˆˆ{0,1}ğœ†to encrypt the initial node of the
linked list, where ğ‘šğ‘ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘˜ğ‘’ğ‘¦is the main key and the hkdf algorithm
is used for the derivation of the keys:
ğ¾ğ´,1â†ğ»ğ¾ğ·ğ¹(ğ‘šğ‘ğ‘ ğ‘¡ğ‘’ğ‘Ÿğ‘˜ğ‘’ğ‘¦,ğ‘ ğ‘ğ‘™ğ‘¡=ğ¼ğ·ğ´,ğ‘–ğ‘›ğ‘“ğ‘œ =â€œğ¼ğ‘›ğ‘–ğ‘¡ğ¾ğ‘’ğ‘¦ â€œ)(16)
Next, we generate trapdoors, where ğ¼ğ·ğ´is the unique identifier
of the user, ğ¾ğ´,1âˆˆ {0,1}ğœ†is the key to encrypt the first node
in the linked list, and ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´, 1)is the address to the first
node,â„‹:{0,1}âˆ—â†’{0,1}ğœ†is the hash function will be used.The
threshold is calculated as follows:
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´=â„‹(ğ¼ğ·ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´)âŠ•(ğ¼ğ·ğ´||ğ¾ğ´,1||
ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´.1))(17)
The trapdoor is stored in the database to authenticate users and
locate userâ€™s privacy information.
Data encryption storage: This part defines the tamper proof
chain encryption storage structure to achieve fine-grained privacy
protection. AES-CBC encryption uses random IV to prevent pattern
recognition, and uses the current key derivation scheme HKDF to

User A
Private Knowledge Base
AES
AES
ChunkA1
ChunkB1
ChunkB2
ChunkA2EmbeddingA1
EmbeddingB1
EmbeddingB2
EmbeddingA2KeyA2
KeyB2
KeyB3
KeyA3
KeyA1
Hash(KeyA1)
Hash(KeyB1)
Hash(KeyB2)
Hash(KeyA3)
AddressA1
HashFigure 4: The figure is the overall framework diagram of method B, in
which the blue and green lines identify the data source, the blue dotted
line represents the data encryption process, the blue (green) dotted line
represents the connection process of the linked list, and the gray line rep-
resents the process in which the user obtains and decrypts the linked list
information through his own identity identifier and key through trapdoor.
Only the encryption scheme is shown in the figure, and ğ¾ğ‘’ğ‘¦ğ´ 1can decrypt
the decryption along the linked list.
derive the encryption key of the next node. The definition of the
storageğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–is as follows:
ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–=ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”(ğ‘â„ğ‘¢ğ‘›ğ‘˜ğ´,ğ‘–)||ğ‘â„ğ‘¢ğ‘›ğ‘˜ğ´,ğ‘–||ğ¾ğ´,ğ‘–+1||
â„‹(ğ¾ğ´,ğ‘–)||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1))(18)
In fact, what we store is the encrypted value. We encrypt the current
ğ‘›ğ‘œğ‘‘ğ‘’ğ‘–by generating the initial vector ğ¼ğ‘‰âˆˆ{0,1}ğœ†and using the key
ğ¾ğ´,ğ‘–âˆˆ{0,1}ğœ†stored by the previous ğ‘›ğ‘œğ‘‘ğ‘’[1âˆ’4]
ğ´,ğ‘–,Whereğ‘›ğ‘œğ‘‘ğ‘’[1âˆ’4]
ğ´,ğ‘–
represents one to four fields of node:
ğ¸ğ‘›ğ‘ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–=ğ´ğ¸ğ‘†ğ¶ğµğ¶.ğ¸ğ‘ğ¶(ğ¾ğ´,ğ‘–,ğ¼ğ‘‰,ğ‘›ğ‘œğ‘‘ğ‘’[1âˆ’4]
ğ´,ğ‘–)||ğ‘›ğ‘œğ‘‘ğ‘’[5]
ğ´,ğ‘–(19)
Privacy data retrieval: Users want to retrieve their private infor-
mation, hash the ID and salt key, and perform threshold parsing to
get the address and key of the linked list:
(ğ¼ğ·ğ´||ğ¾ğ´,1||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´.1))=â„‹(ğ¼ğ·â€²
ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´)âŠ•
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´(20)
Then protocol verifies the validity of the userâ€™s identity. Let ğ¼ğ·â€²
ğ´
denote the queried identifier. The system executes subsequent op-
erations only if ğ¼ğ·â€²
ğ´matches the pre-registered ğ¼ğ·ğ´, as formalized
in Equation (1). Otherwise, the protocol terminates immediately
(returningâŠ¥) to prevent unauthorized access.
VerifyID(ğ¼ğ·â€²
ğ´)=(
1,ifğ¼ğ·â€²
ğ´=ğ¼ğ·ğ´
âŠ¥,otherwise(21)
The decryption protocol operates as a sequential chain traversal,
initiated by decrypting the first node using the initial key ğ¾ğ´,1
and address Addrğ´,1(Algorithm 1, lines 2â€“4). Each decrypted node
nodeğ´,ğ‘–undergoes integrity verification through hash comparison
â„‹(ğ¾ğ´,ğ‘–)=node[4]
ğ´,ğ‘–, where failure triggers immediate termination
(Line 7). Valid nodes yield two critical components: (1) the private
data(embeddingğ‘–,chunkğ‘–)for result aggregation, and (2) the subse-
quent nodeâ€™s address Addrğ´,ğ‘–+1for chain progression. This iterative
decrypt-validate-extract cycle persists until encountering a Nulladdress, at which point Result listcontains all recovered user data,
excluding HMAC padding removal already addressed by Method A.
The full procedureâ€™s formal specification appears in Algorithm 1.
Algorithm 1: Chain Decryption Protocol for Distributed
Encrypted Data
Input : Initial secret key ğ¾ğ´,1, initial address Addrğ´,1
Output: Decrypted data list Result listcontaining
chunk-embedding pairs
1Result listâ†âˆ…
2ğ‘–â†1
3while Addrğ´,ğ‘–â‰ Null do
4 Decrypt node:
5 nodeğ´,ğ‘–â†
AES-CBC.Decrypt ğ¾ğ´,ğ‘–,IV,EncNode[1:4]
ğ´,ğ‘–âˆ¥EncNode[5]
ğ´,ğ‘–
6 Verify integrity:
7 hash calcâ†â„‹(ğ¾ğ´,ğ‘–)
8 hash storedâ†node[4]
ğ´,ğ‘–
9 ifhash calcâ‰ hash stored then
10 returnâŠ¥
11 else
12 Extract data:
13(embeddingğ‘–,chunkğ‘–)â† node[1:3]
ğ´,ğ‘–
14 Update results:
15 Result listâ†Result listâˆª
(embeddingğ‘–,chunkğ‘–)	
16 Iterate to next node:
17 Addrğ´,ğ‘–+1â†node[5]
ğ´,ğ‘–
18 ğ‘–â†ğ‘–+1
19 end
20end
21return Result list
At this time, the user safely takes out his chunks and correspond-
ing embeddings, and can merge the knowledge base and carry out
rag process.
Privacy Data Addition: First, to add data, the user needs to use
the current encryption node key to derive the key to encrypt the
next node:
ğ¾ğ´,ğ‘–+2â†ğ»ğ¾ğ·ğ¹(ğ¾ğ´,ğ‘–,ğ‘ ğ‘ğ‘™ğ‘¡=ğ¼ğ·ğ´,ğ‘–ğ‘›ğ‘“ğ‘œ =â€œğ‘ğ‘’ğ‘¥ğ‘¡ğ¾ğ‘’ğ‘¦ â€œ) (22)
The new encryption node is constructed as follows:
ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1=ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”(ğ‘â„ğ‘¢ğ‘›ğ‘˜ğ´,ğ‘–+1)||ğ‘â„ğ‘¢ğ‘›ğ‘˜ğ´,ğ‘–+1||ğ¾ğ´,ğ‘–+2||
â„‹(ğ¾ğ´,ğ‘–+1)||ğ‘›ğ‘¢ğ‘™ğ‘™(23)
Then traverse the chain through field ğ‘›ğ‘œğ‘‘ğ‘’[5]
ğ´,ğ‘–to the last node, and
modify null to point to the new node:
ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–=ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘”(ğ‘â„ğ‘¢ğ‘›ğ‘˜ğ´,ğ‘–)||ğ‘â„ğ‘¢ğ‘›ğ‘˜ğ´,ğ‘–||ğ¾ğ´,ğ‘–+1||
â„‹(ğ¾ğ´,ğ‘–)||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1)(24)
The security of the trapdoor is that the enemy cannot extract
effective information through , and the security of the trapdoor
depends on the pseudo randomness of the hash function and the
confidentiality of the salt value .

3.4 RAG Search
In our proposed Retrieval-Augmented Generation (RAG) system,
consider a set of documents {ğ·1,...,ğ·ğ‘š}. Each document ğ·ğ‘–is
partitioned into smaller text chunks. A private knowledge base ğ’¦
is constructed by aggregating all these chunks. Let ğ‘’denote a text
embedder function that maps each chunk ğ‘¥ğ‘§âˆˆğ’¦and the input
promptğ‘into a high - dimensional embedding space Rğ‘‘ğ‘’ğ‘šğ‘. We
use a similarity function, for example, the cosine similarity sim(Â·,Â·),
which is defined as:
sim(u,v)=uÂ·v
|u||v|(25)
where u,vâˆˆRğ‘‘ğ‘’ğ‘šğ‘. This function is employed to measure the
similarity between the embedding of the prompt q=ğ‘’(ğ‘)and
the embeddings of the chunks xğ‘§=ğ‘’(ğ‘¥ğ‘§)inğ’¦. The top-ğ‘˜most
similar chunks ğ’³(ğ‘)âŠ‚ğ’¦to the prompt ğ‘are retrieved based on the
similarity scores, where |ğ’³(ğ‘)|=ğ‘˜. We can express the retrieval
process as:
ğ’³(ğ‘)=argmax ğ’³âŠ‚ğ’¦,|ğ’³|=ğ‘˜âˆ‘ï¸
ğ‘¥ğ‘§âˆˆğ’³sim(q,xğ‘§) (26)
Method A : When adding user chunks to the knowledge base, let
the encrypted embedding be ğ‘ğ‘’ğ‘šğ‘ğ‘’ğ‘‘ğ‘‘ğ‘–ğ‘›ğ‘” and the encrypted chunk
beğ‘ğ‘â„ğ‘¢ğ‘›ğ‘˜ . Along with other related information (e.g., Initialization
Vectorğ¼ğ‘‰, tag), they are inserted with a corresponding primary
keyğ‘ƒğ¾ğ‘›ğ‘’ğ‘¤. The set of primary keys is stored in a list ğ‘ƒğ¾ğ‘™ğ‘–ğ‘ ğ‘¡ . For
retrieval in the encrypted state, the user first retrieves the relevant
primary keys ğ‘ƒğ¾ğ‘Ÿğ‘’ğ‘™ğ‘’ğ‘£ğ‘ğ‘›ğ‘¡âŠ‚ğ‘ƒğ¾ğ‘™ğ‘–ğ‘ ğ‘¡ . Let the encrypted data associ-
ated with these primary keys be (ğ¼ğ‘‰ğ‘–,ğ‘ğ‘–,ğ‘¡ğ‘ğ‘”ğ‘–)forğ‘–corresponding
to the retrieved primary keys. The data integrity is checked using a
Message Authentication Code (MAC) with key ğ¾ğ‘šğ‘ğ‘. The integrity
check can be expressed as:
HMACğ¾ğ‘šğ‘ğ‘(ğ¼ğ‘‰ğ‘–|ğ‘ğ‘–|ğ‘¡ğ‘ğ‘”ğ‘–)?=received MAC value (27)
whereâˆ¥denotes concatenation. If the integrity check passes, the
encrypted ciphertexts ğ‘ğ‘–(either encrypted embeddings or encrypted
chunks) are decrypted using the userâ€™s key ğ¾ğ‘–. Letğ‘‘ğ‘–=Decryptğ¾ğ‘–(ğ‘ğ‘–)
be the decrypted data. Then, the decrypted chunks and embeddings
are combined with those from the public knowledge base. The simi-
larity between the embedding of the prompt qand the embeddings
of the combined chunks is calculated to retrieve the top- ğ‘˜rele-
vant chunks ğ’³(ğ‘)for further processing by the generative model.
Method B : The user data is organized into an encrypted linked
list. Each node ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–contains the embedding of the chunk xğ´,ğ‘–,
the chunkğ‘¥ğ´,ğ‘–, the key for the next node ğ¾ğ´,ğ‘–+1, the hash integrity
check of the current key â„‹(ğ¾ğ´,ğ‘–), and the address of the next node
ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1). After encryption, the encrypted nodes ğ¸ğ‘›ğ‘ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–
are stored. When a query (input prompt ğ‘) is received, the user first
hashes their ID and salt key. Let â„=Hash(ğ¼ğ·âˆ¥ğ‘ ğ‘ğ‘™ğ‘¡)and parses the
trapdoorğ‘‡to obtain the address ğ‘ğ‘‘ğ‘‘ğ‘Ÿ 0and keyğ¾0of the linked list.
After verifying the user ID, the linked list is decrypted node by node.
For theğ‘–-th node, the address ğ‘ğ‘‘ğ‘‘ğ‘Ÿğ‘–is used to locate the next node,
and the keyğ¾ğ‘–is used to decrypt the nodeâ€™s content. If ğ¸ğ‘›ğ‘ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–=
(ğ¸(xğ´,ğ‘–),ğ¸(ğ‘¥ğ´,ğ‘–),ğ¸(ğ¾ğ´,ğ‘–+1),ğ¸(â„‹(ğ¾ğ´,ğ‘–)),ğ¸(ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1)))is theencrypted node, then the decrypted node is obtained as:
ï£±ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ ï£²
ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£´ï£³xğ´,ğ‘–=Decryptğ¾ğ‘–(ğ¸(xğ´,ğ‘–)),
ğ‘¥ğ´,ğ‘–=Decryptğ¾ğ‘–(ğ¸(ğ‘¥ğ´,ğ‘–)),
ğ¾ğ´,ğ‘–+1=Decryptğ¾ğ‘–(ğ¸(ğ¾ğ´,ğ‘–+1)),
â„‹(ğ¾ğ´,ğ‘–)=Decryptğ¾ğ‘–(ğ¸(â„‹(ğ¾ğ´,ğ‘–))),
ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1)=Decryptğ¾ğ‘–(ğ¸(ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–+1))).(28)
Once all the private chunks and their corresponding embeddings are
retrieved, they are combined with the public knowledge base data.
Similar to Method A, the similarity between the prompt embedding
and the combined chunksâ€™ embeddings is calculated to retrieve the
top-ğ‘˜relevant chunks ğ’³(ğ‘)for the generative model.
In the search process, for both Method A and Method B, user
authentication is performed before the retrieval phase. In Method
A, each user has a unique encryption key ğ¾ğ‘–and a message authen-
tication key ğ¾ğ‘šğ‘ğ‘. The data is encrypted using AES - CBC with a
random initialization vector ğ¼ğ‘‰for each encryption operation. The
encryption of data ğ‘šcan be written as ğ‘=AES - CBC ğ¾ğ‘–(ğ‘š,ğ¼ğ‘‰).
The integrity of the encrypted data is verified using ğ»ğ‘€ğ´ğ¶ with
ğ¾ğ‘šğ‘ğ‘, which ensures that even if an adversary accesses the en-
crypted data, they cannot decrypt it without the correct key and
cannot modify the data without being detected. In Method B, the
use of a chained dynamic key derivation mechanism, along with the
trapdoor and hash integrity checks for each node in the linked list,
provides fine - grained access control and tamper - resistant privacy
protection. The trapdoor, which is based on the userâ€™s unique ID,
salt value, and the root key of the data chain, ensures that only the
legitimate user can access their private data. The hash integrity
checks prevent any unauthorized modification of the data nodes
during storage and retrieval.
4 SECURITY PROOF
First, we provide a security proof for Method A. The confidentiality
of Method A can be reduced to the IND-CPA (adaptive chosen
plaintext attack) security of AES-CBC, while the integrity relies on
the PRF (pseudorandom function) property and collision resistance
of HMAC. The security proof is given through formalizing the
adversary model and using reduction techniques:
Assume there exists a probabilistic polynomial-time (PPT) ad-
versary ğ’œthat can break the IND-CPA security with advantage ğœ–.
We construct a oracle â„¬to useğ’œto break the IND-CPA security of
AES-CBC, with the following steps:
(1)â„¬receives the security parameter ğœ†from AES-CBC and other
public parameters.
(2)Key generation: When ğ’œrequests a user key, â„¬randomly
samplesğ¾ğ‘–$â† âˆ’{0,1}ğœ†and returns it.
(3)Forğ’œâ€™s encryption query (ğ‘š0,ğ‘š1),â„¬randomly generates
ğ¼ğ‘‰$â† âˆ’{0,1}ğœ†, submits(ğ‘š0,ğ‘š1)to the AES-CBC challenger,
and receives the challenge ciphertext,where ğ‘$â† âˆ’{0,1}:
ğ‘ğ‘â†ğ´ğ¸ğ‘†âˆ’ğ¶ğµğ¶.ğ¸ğ‘›ğ‘(ğ¾,ğ¼ğ‘‰,ğ‘šğ‘) (29)
returning(ğ¼ğ‘‰,ğ‘ğ‘)toğ’œ.
(4)ğ’œoutputs a guess ğ‘â€², andâ„¬outputs the same result.

At this point, the advantage of â„¬satisfies:
ğ´ğ‘‘ğ‘£ğ¼ğ‘ğ·âˆ’ğ¶ğ‘ƒğ´
â„¬(ğœ†)=ğ´ğ‘‘ğ‘£ğ¼ğ‘ğ·âˆ’ğ¶ğ‘ƒğ´
ğ’œ(ğœ†) (30)
According to the standard security assumption of AES-CBC, there
is a negligible function ğ‘›ğ‘’ğ‘™ğ‘”(ğœ†)that makes:
ğ´ğ‘‘ğ‘£ğ¼ğ‘ğ·âˆ’ğ¶ğ‘ƒğ´
â„¬(ğœ†)â‰¤ğ‘›ğ‘’ğ‘™ğ‘”(ğœ†) (31)
From equations 30 and 31, it can be concluded that method A also
meets IND-CPA confidentiality.
To demonstrate the integrity (INT-CTXT) security of Method A,
we assume that an adversary ğ’œcan forge valid ciphertexts with
advantage AdvINT-CTXT
ğ’œ(ğœ†). To further analyze the implications of
this assumption on the overall security, we construct a oracle â„¬that
leverages the forgery capabilities of ğ’œto break the PRF security of
HMAC. This reduction approach allows us to relate the integrity
security of Method A to the PRF security of HMAC. The process is
described as follows:
(1)The oracle â„¬receives the key ğ¾ğ‘šğ‘ğ‘ (or random function)
from the HMAC challenger.
(2)When the adversary ğ’œmakes an HMAC query ğ¼ğ‘‰âˆ¥ğ‘, the
oracleâ„¬submitsğ¼ğ‘‰âˆ¥ğ‘to the HMAC challenger, obtains the
corresponding tag ğ‘¡ğ‘ğ‘”, and returns it to ğ’œ.
(3)When the adversary ğ’œoutputs(ğ¼ğ‘‰âˆ—,ğ‘âˆ—,ğ‘¡ğ‘ğ‘”âˆ—)as forged ci-
phertext , the oracle â„¬submits(ğ¼ğ‘‰âˆ—âˆ¥ğ‘âˆ—)andğ‘¡ğ‘ğ‘”âˆ—to the
HMAC challenger for verification. If the forged ciphertext is
validated as valid, then â„¬successfully leverages ğ’œâ€™s forgery
capability to break the PRF security of HMAC.
Based on the PRF security of HMAC, the advantage of the oracle
â„¬is bounded by the following relation:
AdvPRF
â„¬(ğœ†)â‰¥AdvINT-CTXT
ğ’œ(ğœ†)âˆ’ğ‘2
2ğœ†+1(32)
whereğ‘is the number of queries made by the adversary ğ’œ. Since
HMACâ€™s security as a PRF guarantees that AdvPRF
â„¬(ğœ†)â‰¤negl(ğœ†)
(where negl(ğœ†)denotes a negligible function that approaches zero
rapidly asğœ†increases), we can derive that:
AdvINT-CTXT
ğ’œ(ğœ†)â‰¤negl(ğœ†)+ğ‘2
2ğœ†+1(33)
When the security parameter ğœ†â‰¥128and the number of queries
ğ‘â‰ª264, the right-hand side becomes a negligible value. This
implies that the probability of the adversary ğ’œforging valid cipher-
texts is extremely low, thereby ensuring that Method A satisfies
INT-CTXT integrity.
Through this analysis, we have shown that the integrity security
of Method A can be reduced to the PRF security of HMAC. This not
only validates the security of Method A in practical applications
but also demonstrates its theoretical reliability. For the security
proof of method B, we intend to analyze it from three aspects: the
forward security of the chain node, the chain integrity and the
privacy of trapdoor. The encryption protocol of each node to the
security of AES-CBC has been proved in method A, so this part is
not described.
Chain forward security and even if the adversary obtains the
keyğ¾ğ´,ğ‘–in time step i, it still cannot decrypt the historical node
datağ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘—where j>i, the security assumption of HDKF is: if
the input key is ğ¾ğ´,ğ‘–is a random value, then the output ğ¾ğ´,ğ‘–+1is computationally indistinguishable from the uniform random
permutation.Assuming that adversary ğ’œa with PPT can decrypt
the historical node ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘—, we can construct the algorithm â„¬to
break the pseudo randomness of HKDF,the protocol is shown as
follows:
(1)â„¬accept the output K* of HKDF challenger.
(2)â„¬simulate the key derivation chain of method B, replace K*
withğ¾ğ´,ğ‘–, and continue to derive subsequent keys.
(3)If a successfully decrypts ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘—, then K* must be HKDF
output, otherwise it is a pseudo-random number.
(4)â„¬to distinguish between HKDF output and random number,
contradiction and HKDF security assumption.
Therefore, the following conclusions can be drawn,under the as-
sumption of HKDF, method B meets forward security:
ğ´ğ‘‘ğ‘£ğ¹ğ‘œğ‘Ÿğ‘¤ğ‘ğ‘Ÿğ‘‘âˆ’ğ‘†ğ‘’ğ‘ğ‘¢ğ‘Ÿğ‘–ğ‘¡ğ‘¦
ğ’œ(ğœ†)â‰¤ğ´ğ‘‘ğ‘£ğ¹ğ‘…ğ¹
ğ»ğ¾ğ·ğ¹(ğœ†)+ğ‘›ğ‘’ğ‘™ğ‘”(ğœ†) (34)
For chain integrity, the adversary cannot tamper with ğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–
without being detected. It can be reduced to node to perform hash
anti-collision property of decryption key. â„ğ‘–=ğ»(ğ¾ğ´,ğ‘–)has stored in
every node and the next â„ğ‘–+1=ğ»(ğ¾ğ´,ğ‘–+1)form a hash chain,Every
decryption verificate â„ğ‘–?=ğ»(ğ¾ğ´,ğ‘–),Assuming that the content of
theğ‘›ğ‘œğ‘‘ğ‘’ğ´,ğ‘–tampered by the adversary is ğ‘›ğ‘œğ‘‘ğ‘’âˆ—
ğ´,ğ‘–, it is necessary to
modify the hash value of subsequent nodes â„âˆ—
ğ‘–=ğ»(ğ¾âˆ—
ğ´,ğ‘—)at the
same time to pass the verification. Assuming that the adversary
makes at most Q tampering attempts, the probability of successful
forgery is:
ğ´ğ‘‘ğ‘£ğ¶â„ğ‘ğ‘–ğ‘›âˆ’ğ¼ğ‘›ğ‘¡ğ‘’ğ‘Ÿğ‘”ğ‘Ÿğ‘–ğ‘¡ğ‘¦
ğ’œ(ğœ†)â‰¤ğ‘(ğ‘+1)
2ğœ†(35)
Because every tampering requires cracking the hash anti-collision,
when the security parameter ğœ†is large enough( ğœ†â‰¥128),2âˆ’ğœ†can
be ignored.The chained integrity of method B can depend on the
anti-collision of hash function â„‹to meet the data tamperability.
The security of the trapdoor is that the enemy cannot extract
effective information through equation 17, and the security of the
trapdoor depends on the pseudo randomness of the hash func-
tionğ»(ğ¼ğ·ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´)and the confidentiality of the salt value
ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´.Assuming that the enemy already knows the ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´
but does not know the ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´, it is necessary to restore the ğ¼ğ·ğ´
andğ¾ğ´,1,The advantages of the ğ’œare described as follows:
ğ´ğ‘‘ğ‘£ğ’œ=ğ‘ƒğ‘Ÿ[ğ’œ(ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´)âˆ’ â†’(ğ¼ğ·ğ´,ğ¾ğ´,1)] (36)
The above ğ’œattacks can be regulated to PRF security,the enemy
only knows ğ¼ğ·ğ´, he can construct algorithm â„¬to distinguish the
output ofğ»(ğ¼ğ·ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´)from random oracle ğ’ª:
(1)â„¬random sampled ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´$â† âˆ’{0,1}ğœ†and confidential.
(2) When ğ’œrequest the trapdoor â„¬run:
â€¢Randomly select ğ¼ğ·ğ´â† âˆ’{0,1}ğœ†andğ‘˜ğ‘,1â† âˆ’{0,1}ğœ†.
â€¢Submitğ¼ğ·ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´to PRF challenger and obtain ğ‘¦ğ‘=
â„‹(ğ¼ğ·ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´)(b=0 for PRF output b=1 is a random
number).
â€¢Compute the ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´as follow:
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´=ğ‘¦ğ‘âŠ•(ğ¼ğ·ğ´||ğ¾ğ´,1||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´.1)) (37)
â€¢Return theğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´toğ’œ.
(3)ğ’œoutput the result(ğ¼ğ·âˆ—
ğ´,ğ¾âˆ—
ğ´,1)that he guess.

(4)ğ’œjudge the result throught compare ğ¾âˆ—
ğ´,1?=ğ¾ğ´,1andğ¼ğ·âˆ—
ğ´?=
ğ¼ğ·ğ´, If the above conditions are met, return to b=0 otherwise
b=1.
Letâ€™s analyze the advantage of ğ’œ. the first case is the probability
that simulator B outputs 0 when the challenger is in PRF mode
(b=0). The second case is the probability that the challenger is in
true random mode (b=1) and the simulator outputs 0. For the first
caseğ‘¦ğ‘=ğ»(ğ¼ğ·ğ´||ğ‘˜ğ‘’ğ‘¦ğ‘ ğ‘ğ‘™ğ‘¡ğ´)is the real PRF output, and ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ´
is constructed legally. The enemy advantage is:
ğ‘ƒğ‘Ÿ[â„¬â†’0|ğ‘=0]=ğ´ğ‘‘ğ‘£ğ’œ (38)
For the second case, if ğ‘¦ğ‘is a uniform random number, then ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ‘
is one secret at a time:
ğ‘‡ğ‘Ÿğ‘ğ‘ğ‘‘ğ‘œğ‘œğ‘Ÿğ‘=randomâŠ•(ğ¼ğ·ğ´||ğ¾ğ´,1||ğ‘ğ‘‘ğ‘‘ğ‘Ÿ(ğ‘›ğ‘œğ‘‘ğ‘’ğ´.1) (39)
And the success probability of the enemy is:
ğ‘ƒğ‘…[ğµâ†’0|ğ‘=1]â‰¤1
2ğœ†+(ğ‘ğ»+ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘)2
2ğœ†+1(40)
Where(ğ‘ğ»+ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘)2
2ğœ†+1 is the probability that at least one collision
will occur when the ğ’œmakesğ‘ğ»+ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘ queries according to the
birthday paradox.Where ğ‘ğ»refers to the number of times the ğ’œ
performed hash queries and ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘ refers to the number of trapdoor
instances obtained by the ğ’œ.So the overall advantage of the enemyâ€™s
attack is:
ğ´ğ‘‘ğ‘£ğ‘ƒğ‘…ğ¹
â„¬=|ğ‘ƒğ‘Ÿ[ğµâ†’0|ğ‘=0]âˆ’ğ‘ƒğ‘Ÿ[ğµâ†’1|ğ‘=0]|
â‰¥ğ´ğ‘‘ğ‘£ğ’œâˆ’(ğ‘ğ»+ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘)2
2ğœ†+1(41)
ğ´ğ‘‘ğ‘£ğ’œ=ğ´ğ‘‘ğ‘£ğ‘ƒğ‘…ğ¹
â„¬+(ğ‘ğ»+ğ‘ğ‘¡ğ‘Ÿğ‘ğ‘)2
2ğœ†+1(42)
When the security parameter ğœ†â‰¥128and the number of queries
ğ‘â‰ª264, the right-hand side becomes a negligible value. So the
advantage of the enemy is very small, and the trapdoor informa-
tion can be completely hidden, so as to ensure the concealment of
trapdoor.
5 CONCLUSION
In this work, we have tackled the pressing privacy and security con-
cerns associated with Retrieval-Augmented Generation (RAG) sys-
tems, which are increasingly deployed in sensitive domains such as
healthcare, finance, and legal services. By introducing an advanced
encryption methodology that secures both textual content and its
corresponding embeddings, we have established a robust frame-
work to protect proprietary knowledge bases from unauthorized
access and data breaches. Our approach ensures that sensitive infor-
mation remains encrypted throughout the retrieval and generation
processes, without compromising the performance or functionality
of RAG pipelines. The key contributions of this research include the
development of a theoretical framework for integrating encryption
techniques into RAG systems and a novel encryption scheme that
secures RAG knowledge bases at both the textual and embedding
levels. Through rigorous security proofs, we have demonstrated
the resilience of our methodology against potential threats and
vulnerabilities, validating its effectiveness in safeguarding sensi-
tive information. This validates the practicality and effectivenessof our solution in real-world applications. Our findings highlight
the critical need for integrating advanced encryption techniques
into the design and deployment of RAG systems as a fundamental
component of privacy safeguards. By addressing the vulnerabilities
identified in prior research, this work advances the state-of-the-art
in RAG security and contributes to the broader discourse on enhanc-
ing privacy-preserving measures in AI-driven services. We believe
that our contributions will inspire further innovation in this critical
area, ultimately fostering greater trust and reliability in AI-driven
applications across diverse sectors. In conclusion, this research not
only provides a practical solution to mitigate privacy risks in RAG
systems but also sets a new benchmark for the development of
secure and privacy-preserving AI technologies. Future work will
explore the scalability of our encryption scheme to larger datasets
and its integration with other AI architectures, further solidifying
its role in the evolving landscape of AI security.
REFERENCES
[1]Rakesh Agrawal, Jerry Kiernan, Ramakrishnan Srikant, and Yirong Xu. 2004.
Order preserving encryption for numeric data. In Proceedings of the 2004 ACM
SIGMOD international conference on Management of data . 563â€“574.
[2]Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan
Wilie, Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al .2023. A multitask,
multilingual, multimodal evaluation of chatgpt on reasoning, hallucination, and
interactivity. arXiv preprint arXiv:2302.04023 (2023).
[3]Rudolf Bayer and JK Metzger. 1976. On the encipherment of search trees and
random access files. ACM Transactions on Database Systems (TODS) 1, 1 (1976),
37â€“52.
[4]Stella Biderman, Usvsn Prashanth, Lintang Sutawika, Hailey Schoelkopf, Quentin
Anthony, Shivanshu Purohit, and Edward Raff. 2023. Emergent and predictable
memorization in large language models. Advances in Neural Information Process-
ing Systems 36 (2023), 28072â€“28090.
[5]Luc Bouganim and Philippe Pucheral. 2002. Chip-secured data access: Confiden-
tial data on untrusted servers. In VLDBâ€™02: Proceedings of the 28th International
Conference on Very Large Databases . Elsevier, 131â€“142.
[6]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan,
Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda
Askell, et al .2020. Language models are few-shot learners. Advances in neural
information processing systems 33 (2020), 1877â€“1901.
[7]Nicholas Carlini, Steve Chien, Milad Nasr, Shuang Song, Andreas Terzis, and
Florian Tramer. 2022. Membership inference attacks from first principles. In 2022
IEEE symposium on security and privacy (SP) . IEEE, 1897â€“1914.
[8]Nicholas Carlini, Daphne Ippolito, Matthew Jagielski, Katherine Lee, Florian
Tramer, and Chiyuan Zhang. 2022. Quantifying memorization across neural
language models. In The Eleventh International Conference on Learning Represen-
tations .
[9]Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-
Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson,
et al.2021. Extracting training data from large language models. In 30th USENIX
security symposium (USENIX Security 21) . 2633â€“2650.
[10] Chin-Chen Chang and Chao-Wen Chan. 2003. A database record encryption
scheme using the RSA public key cryptosystem and its master keys. In 2003
International Conference on Computer Networks and Mobile Computing, 2003.
ICCNMC 2003. IEEE, 345â€“348.
[11] Harrison Chase. 2022. Langchain. https://github.com/hwchase17/langchain. (Oct.
2022).
[12] Gang Chen, Ke Chen, and Jinxiang Dong. 2006. A database encryption scheme
for enhanced security and easy sharing. In 2006 10th International Conference on
Computer Supported Cooperative Work in Design . IEEE, 1â€“6.
[13] Xin Cheng, Di Luo, Xiuying Chen, Lemao Liu, Dongyan Zhao, and Rui Yan.
2023. Lift yourself up: Retrieval-augmented text generation with self-memory.
Advances in Neural Information Processing Systems 36 (2023), 43780â€“43799.
[14] Stav Cohen, Ron Bitton, and Ben Nassi. 2024. Unleashing worms and extracting
data: Escalating the outcome of attacks against rag-based inference in scale and
severity using jailbreaking. arXiv preprint arXiv:2409.08045 (2024).
[15] Adam Cutbill, Eric Monsler, and Eric Hayashi. 2024. Personalized home assistant
using large language model with context-based chain of thought reasoning.
(2024).
[16] George I Davida, David L Wells, and John B Kam. 1981. A database encryption
system with subkeys. ACM Transactions on Database Systems (TODS) 6, 2 (1981),
312â€“328.

[17] Matthias De Lange, Rahaf Aljundi, Marc Masana, Sarah Parisot, Xu Jia, AleÅ¡
Leonardis, Gregory Slabaugh, and Tinne Tuytelaars. 2021. A continual learning
survey: Defying forgetting in classification tasks. IEEE transactions on pattern
analysis and machine intelligence 44, 7 (2021), 3366â€“3385.
[18] Christian Di Maio, Cristian Cosci, Marco Maggini, Valentina Poggioni, and Ste-
fano Melacci. 2024. Pirates of the RAG: Adaptively Attacking LLMs to Leak
Knowledge Bases. arXiv preprint arXiv:2412.18295 (2024).
[19] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia,
Jingjing Xu, Zhiyong Wu, Tianyu Liu, et al .2022. A survey on in-context learning.
arXiv preprint arXiv:2301.00234 (2022).
[20] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai,
Jiawei Sun, Haofen Wang, and Haofen Wang. 2023. Retrieval-augmented gen-
eration for large language models: A survey. arXiv preprint arXiv:2312.10997 2
(2023).
[21] Silvia GarcÃ­a-MÃ©ndez, Francisco de Arriba-PÃ©rez, and MarÃ­a del Carmen Somoza-
LÃ³pez. 2024. A review on the use of large language models as virtual tutors.
Science & Education (2024), 1â€“16.
[22] Abenezer Golda, Kidus Mekonen, Amit Pandey, Anushka Singh, Vikas Hassija,
Vinay Chamola, and Biplab Sikdar. 2024. Privacy and security concerns in
generative AI: a comprehensive survey. IEEE Access (2024).
[23] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020.
Retrieval augmented language model pre-training. In International conference on
machine learning . PMLR, 3929â€“3938.
[24] Jingmin He and Min Wang. 2001. Cryptography and relational database man-
agement systems. In Proceedings 2001 International Database Engineering and
Applications Symposium . IEEE, 273â€“284.
[25] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, Lu Wang, Weizhu Chen, et al .2022. Lora: Low-rank adaptation of large
language models. ICLR 1, 2 (2022), 3.
[26] Hongsheng Hu, Zoran Salcic, Lichao Sun, Gillian Dobbie, Philip S Yu, and Xuyun
Zhang. 2022. Membership inference attacks on machine learning: A survey. ACM
Computing Surveys (CSUR) 54, 11s (2022), 1â€“37.
[27] Yaou Hu and Hyounae Kelly Min. 2023. The dark side of artificial intelligence in
service: The â€œwatching-eyeâ€ effect and privacy concerns. International Journal of
Hospitality Management 110 (2023), 103437.
[28] Min-Shiang Hwang and Wei-Pang Yang. 1997. Multilevel secure database en-
cryption with subkeys. Data & knowledge engineering 22, 2 (1997), 117â€“131.
[29] Juyong Jiang, Fan Wang, Jiasi Shen, Sungju Kim, and Sunghun Kim. 2024. A survey
on large language models for code generation. arXiv preprint arXiv:2406.00515
(2024).
[30] Ehsan Kamalloo, Nouha Dziri, Charles LA Clarke, and Davood Rafiei. 2023.
Evaluating open-domain question answering in the era of large language models.
arXiv preprint arXiv:2305.06984 (2023).
[31] Poul-Henning Kamp. 2003. {GBDEâ€”GEOM}Based Disk Encryption. In BSDCon
2003 (BSDCon 2003) .
[32] Nikhil Kandpal, Eric Wallace, and Colin Raffel. 2022. Deduplicating training
data mitigates privacy risks in language models. In International Conference on
Machine Learning . PMLR, 10697â€“10707.
[33] Enkelejda Kasneci, Kathrin SeÃŸler, Stefan KÃ¼chemann, Maria Bannert, Daryna
Dementieva, Frank Fischer, Urs Gasser, Georg Groh, Stephan GÃ¼nnemann, Eyke
HÃ¼llermeier, et al .2023. ChatGPT for good? On opportunities and challenges
of large language models for education. Learning and individual differences 103
(2023), 102274.
[34] Katherine Lee, Daphne Ippolito, Andrew Nystrom, Chiyuan Zhang, Douglas Eck,
Chris Callison-Burch, and Nicholas Carlini. 2021. Deduplicating training data
makes language models better. arXiv preprint arXiv:2107.06499 (2021).
[35] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin,
Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel,
et al.2020. Retrieval-augmented generation for knowledge-intensive nlp tasks.
Advances in neural information processing systems 33 (2020), 9459â€“9474.
[36] Qian Li, Hao Peng, Jianxin Li, Congying Xia, Renyu Yang, Lichao Sun, Philip S
Yu, and Lifang He. 2022. A survey on text classification: From traditional to deep
learning. ACM Transactions on Intelligent Systems and Technology (TIST) 13, 2
(2022), 1â€“41.
[37] Yinheng Li. 2023. A practical survey on zero-shot prompt design for in-context
learning. arXiv preprint arXiv:2309.13205 (2023).
[38] Yong Lin, Hangyu Lin, Wei Xiong, Shizhe Diao, Jianmeng Liu, Jipeng Zhang, Rui
Pan, Haoxiang Wang, Wenbin Hu, Hanning Zhang, et al .2023. Mitigating the
alignment tax of rlhf. arXiv preprint arXiv:2309.06256 (2023).
[39] S Merhotra and B Gore. 2009. A Middleware approach for managing and of
outsourced personal data. In NSF Workshop on Data and Application Security,
Arlignton, Virginia .
[40] Fatemehsadat Mireshghallah, Archit Uniyal, Tianhao Wang, David Evans, and
Taylor Berg-Kirkpatrick. 2022. Memorization in nlp fine-tuning methods. arXiv
preprint arXiv:2205.12506 (2022).
[41] Dimitrios P Panagoulias, Maria Virvou, and George A Tsihrintzis. 2024. Augment-
ing large language models with rules for enhanced domain-specific interactions:
The case of medical diagnosis. Electronics 13, 2 (2024), 320.[42] Jongjin Park. 2024. Development of dental consultation chatbot using retrieval
augmented llm. The Journal of the Institute of Internet, Broadcasting and Commu-
nication 24, 2 (2024), 87â€“92.
[43] Zhenting Qi, Hanlin Zhang, Eric Xing, Sham Kakade, and Himabindu Lakkaraju.
2024. Follow my instruction and spill the beans: Scalable data extraction from
retrieval-augmented generation systems. arXiv preprint arXiv:2402.17840 (2024).
[44] Mahimai Raja, E Yuvaraajan, et al .2024. A rag-based medical assistant especially
for infectious diseases. In 2024 International Conference on Inventive Computation
Technologies (ICICT) . IEEE, 1128â€“1133.
[45] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin
Leyton-Brown, and Yoav Shoham. 2023. In-context retrieval-augmented language
models. Transactions of the Association for Computational Linguistics 11 (2023),
1316â€“1331.
[46] Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu
Chen. 2023. Enhancing retrieval-augmented large language models with iterative
retrieval-generation synergy. arXiv preprint arXiv:2305.15294 (2023).
[47] Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon Seo, Rich James, Mike
Lewis, Luke Zettlemoyer, and Wen-tau Yih. 2023. Replug: Retrieval-augmented
black-box language models. arXiv preprint arXiv:2301.12652 (2023).
[48] Erez Shmueli, Ronen Waisenberg, Yuval Elovici, and Ehud Gudes. 2005. Designing
secure indexes for encrypted databases. In Data and Applications Security XIX:
19th Annual IFIP WG 11.3 Working Conference on Data and Applications Security,
Storrs, CT, USA, August 7-10, 2005. Proceedings 19 . Springer, 54â€“68.
[49] Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov. 2017. Mem-
bership inference attacks against machine learning models. In 2017 IEEE sympo-
sium on security and privacy (SP) . IEEE, 3â€“18.
[50] Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. 2021.
Retrieval augmentation reduces hallucination in conversation. arXiv preprint
arXiv:2104.07567 (2021).
[51] Dave Van Veen, Cara Van Uden, Louis Blankemeier, Jean-Benoit Delbrouck, Asad
Aali, Christian Bluethgen, Anuj Pareek, Malgorzata Polacin, Eduardo Pontes Reis,
Anna SeehofnerovÃ¡, et al .2024. Adapted large language models can outperform
medical experts in clinical text summarization. Nature medicine 30, 4 (2024),
1134â€“1142.
[52] Ziyu Wang, Hao Li, Di Huang, and Amir M Rahmani. 2024. Healthq: Unveiling
questioning capabilities of llm chains in healthcare conversations. arXiv preprint
arXiv:2409.19487 (2024).
[53] Jason Wei, Yi Tay, Rishi Bommasani, Colin Raffel, Barret Zoph, Sebastian
Borgeaud, Dani Yogatama, Maarten Bosma, Denny Zhou, Donald Metzler, et al .
2022. Emergent abilities of large language models. arXiv preprint arXiv:2206.07682
(2022).
[54] Christopher Wood, Eduardo B. Fernandez, and Rita C. Summers. 1980. Data base
security: requirements, policies, and models. IBM Systems Journal 19, 2 (1980),
229â€“252.
[55] Zihan Yu, Liang He, Zhen Wu, Xinyu Dai, and Jiajun Chen. 2023. Towards better
chain-of-thought prompting strategies: A survey. arXiv preprint arXiv:2310.04959
(2023).
[56] Shenglai Zeng, Yaxin Li, Jie Ren, Yiding Liu, Han Xu, Pengfei He, Yue Xing,
Shuaiqiang Wang, Jiliang Tang, and Dawei Yin. 2023. Exploring memorization in
fine-tuned language models. arXiv preprint arXiv:2310.06714 (2023).
[57] Shenglai Zeng, Jiankun Zhang, Pengfei He, Yue Xing, Yiding Liu, Han Xu, Jie
Ren, Shuaiqiang Wang, Dawei Yin, Yi Chang, et al .2024. The good and the bad:
Exploring privacy issues in retrieval-augmented generation (rag). arXiv preprint
arXiv:2402.16893 (2024).
[58] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting
Huang, Enbo Zhao, Yu Zhang, Yulong Chen, et al .2023. Sirenâ€™s song in the
AI ocean: a survey on hallucination in large language models. arXiv preprint
arXiv:2309.01219 (2023).
[59] Yujia Zhou, Yan Liu, Xiaoxi Li, Jiajie Jin, Hongjin Qian, Zheng Liu, Chaozhuo Li,
Zhicheng Dou, Tsung-Yi Ho, and Philip S Yu. 2024. Trustworthiness in retrieval-
augmented generation systems: A survey. arXiv preprint arXiv:2409.10102 (2024).
[60] Wenhao Zhu, Hongyi Liu, Qingxiu Dong, Jingjing Xu, Shujian Huang, Lingpeng
Kong, Jiajun Chen, and Lei Li. 2023. Multilingual machine translation with large
language models: Empirical results and analysis. arXiv preprint arXiv:2304.04675
(2023).